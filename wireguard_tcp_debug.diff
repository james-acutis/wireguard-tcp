diff --git a/wireguard-linux/drivers/net/wireguard/allowedips.c b/wireguard-linux/drivers/net/wireguard/allowedips.c
index 0ba714ca5185..3bc0531cf605 100644
--- a/wireguard-linux/drivers/net/wireguard/allowedips.c
+++ b/wireguard-linux/drivers/net/wireguard/allowedips.c
@@ -12,17 +12,20 @@ static struct kmem_cache *node_cache;
 
 static void swap_endian(u8 *dst, const u8 *src, u8 bits)
 {
+	printk(KERN_INFO "Entering swap_endian(dst=%p, src=%p, bits=%u)\n", dst, src, bits);
 	if (bits == 32) {
 		*(u32 *)dst = be32_to_cpu(*(const __be32 *)src);
 	} else if (bits == 128) {
 		((u64 *)dst)[0] = be64_to_cpu(((const __be64 *)src)[0]);
 		((u64 *)dst)[1] = be64_to_cpu(((const __be64 *)src)[1]);
 	}
+	printk(KERN_INFO "Exiting swap_endian\n");
 }
 
 static void copy_and_assign_cidr(struct allowedips_node *node, const u8 *src,
 				 u8 cidr, u8 bits)
 {
+	printk(KERN_INFO "Entering copy_and_assign_cidr(node=%p, src=%p, cidr=%u, bits=%u)\n", node, src, cidr, bits);
 	node->cidr = cidr;
 	node->bit_at_a = cidr / 8U;
 #ifdef __LITTLE_ENDIAN
@@ -31,30 +34,39 @@ static void copy_and_assign_cidr(struct allowedips_node *node, const u8 *src,
 	node->bit_at_b = 7U - (cidr % 8U);
 	node->bitlen = bits;
 	memcpy(node->bits, src, bits / 8U);
+	printk(KERN_INFO "Exiting copy_and_assign_cidr\n");
 }
 
 static inline u8 choose(struct allowedips_node *node, const u8 *key)
 {
-	return (key[node->bit_at_a] >> node->bit_at_b) & 1;
+	printk(KERN_INFO "Entering choose(node=%p, key=%p)\n", node, key);
+	u8 result = (key[node->bit_at_a] >> node->bit_at_b) & 1;
+	printk(KERN_INFO "Exiting choose with result=%u\n", result);
+	return result;
 }
 
 static void push_rcu(struct allowedips_node **stack,
 		     struct allowedips_node __rcu *p, unsigned int *len)
 {
+	printk(KERN_INFO "Entering push_rcu(stack=%p, p=%p, len=%u)\n", stack, p, *len);
 	if (rcu_access_pointer(p)) {
 		if (WARN_ON(IS_ENABLED(DEBUG) && *len >= MAX_ALLOWEDIPS_DEPTH))
 			return;
 		stack[(*len)++] = rcu_dereference_raw(p);
 	}
+	printk(KERN_INFO "Exiting push_rcu\n");
 }
 
 static void node_free_rcu(struct rcu_head *rcu)
 {
+	printk(KERN_INFO "Entering node_free_rcu(rcu=%p)\n", rcu);
 	kmem_cache_free(node_cache, container_of(rcu, struct allowedips_node, rcu));
+	printk(KERN_INFO "Exiting node_free_rcu\n");
 }
 
 static void root_free_rcu(struct rcu_head *rcu)
 {
+	printk(KERN_INFO "Entering root_free_rcu(rcu=%p)\n", rcu);
 	struct allowedips_node *node, *stack[MAX_ALLOWEDIPS_DEPTH] = {
 		container_of(rcu, struct allowedips_node, rcu) };
 	unsigned int len = 1;
@@ -64,10 +76,12 @@ static void root_free_rcu(struct rcu_head *rcu)
 		push_rcu(stack, node->bit[1], &len);
 		kmem_cache_free(node_cache, node);
 	}
+	printk(KERN_INFO "Exiting root_free_rcu\n");
 }
 
 static void root_remove_peer_lists(struct allowedips_node *root)
 {
+	printk(KERN_INFO "Entering root_remove_peer_lists(root=%p)\n", root);
 	struct allowedips_node *node, *stack[MAX_ALLOWEDIPS_DEPTH] = { root };
 	unsigned int len = 1;
 
@@ -77,40 +91,53 @@ static void root_remove_peer_lists(struct allowedips_node *root)
 		if (rcu_access_pointer(node->peer))
 			list_del(&node->peer_list);
 	}
+	printk(KERN_INFO "Exiting root_remove_peer_lists\n");
 }
 
 static unsigned int fls128(u64 a, u64 b)
 {
-	return a ? fls64(a) + 64U : fls64(b);
+	printk(KERN_INFO "Entering fls128(a=%llu, b=%llu)\n", a, b);
+	unsigned int result = a ? fls64(a) + 64U : fls64(b);
+	printk(KERN_INFO "Exiting fls128 with result=%u\n", result);
+	return result;
 }
 
 static u8 common_bits(const struct allowedips_node *node, const u8 *key,
 		      u8 bits)
 {
+	printk(KERN_INFO "Entering common_bits(node=%p, key=%p, bits=%u)\n", node, key, bits);
+	u8 result;
 	if (bits == 32)
-		return 32U - fls(*(const u32 *)node->bits ^ *(const u32 *)key);
+		result = 32U - fls(*(const u32 *)node->bits ^ *(const u32 *)key);
 	else if (bits == 128)
-		return 128U - fls128(
+		result = 128U - fls128(
 			*(const u64 *)&node->bits[0] ^ *(const u64 *)&key[0],
 			*(const u64 *)&node->bits[8] ^ *(const u64 *)&key[8]);
-	return 0;
+	else
+		result = 0;
+	printk(KERN_INFO "Exiting common_bits with result=%u\n", result);
+	return result;
 }
 
 static bool prefix_matches(const struct allowedips_node *node, const u8 *key,
 			   u8 bits)
 {
+	printk(KERN_INFO "Entering prefix_matches(node=%p, key=%p, bits=%u)\n", node, key, bits);
 	/* This could be much faster if it actually just compared the common
 	 * bits properly, by precomputing a mask bswap(~0 << (32 - cidr)), and
 	 * the rest, but it turns out that common_bits is already super fast on
 	 * modern processors, even taking into account the unfortunate bswap.
 	 * So, we just inline it like this instead.
 	 */
-	return common_bits(node, key, bits) >= node->cidr;
+	bool result = common_bits(node, key, bits) >= node->cidr;
+	printk(KERN_INFO "Exiting prefix_matches with result=%d\n", result);
+	return result;
 }
 
 static struct allowedips_node *find_node(struct allowedips_node *trie, u8 bits,
 					 const u8 *key)
 {
+	printk(KERN_INFO "Entering find_node(trie=%p, bits=%u, key=%p)\n", trie, bits, key);
 	struct allowedips_node *node = trie, *found = NULL;
 
 	while (node && prefix_matches(node, key, bits)) {
@@ -120,13 +147,17 @@ static struct allowedips_node *find_node(struct allowedips_node *trie, u8 bits,
 			break;
 		node = rcu_dereference_bh(node->bit[choose(node, key)]);
 	}
+	printk(KERN_INFO "Exiting find_node with found=%p\n", found);
 	return found;
 }
 
+
+#ifdef ORIGINAL
 /* Returns a strong reference to a peer */
 static struct wg_peer *lookup(struct allowedips_node __rcu *root, u8 bits,
 			      const void *be_ip)
 {
+	printk(KERN_INFO "Entering lookup(root=%p, bits=%u, be_ip=%p)\n", root, bits, be_ip);
 	/* Aligned so it can be passed to fls/fls64 */
 	u8 ip[16] __aligned(__alignof(u64));
 	struct allowedips_node *node;
@@ -143,13 +174,63 @@ static struct wg_peer *lookup(struct allowedips_node __rcu *root, u8 bits,
 			goto retry;
 	}
 	rcu_read_unlock_bh();
+	printk(KERN_INFO "Exiting lookup with peer=%p\n", peer);
 	return peer;
 }
+#endif // ORIGINAL
+
+/* Returns a strong reference to a peer */
+static struct wg_peer *lookup(struct allowedips_node __rcu *root, u8 bits,
+                              const void *be_ip)
+{
+    u8 ip[16] __aligned(__alignof(u64));
+    struct allowedips_node *node;
+    struct wg_peer *peer = NULL;
+
+    /* Defensive check for null pointers */
+    if (!root || !be_ip) {
+        printk(KERN_ERR "lookup: Invalid arguments: root=%p, be_ip=%p\n", root, be_ip);
+        return NULL;
+    }
+
+    swap_endian(ip, be_ip, bits);
+
+    rcu_read_lock_bh();
+retry:
+    node = rcu_dereference_bh(root);
+    if (!node) {
+        printk(KERN_ERR "lookup: root dereferenced to NULL\n");
+        rcu_read_unlock_bh();
+        return NULL;
+    }
+
+    node = find_node(node, bits, ip);
+    if (node) {
+        peer = rcu_dereference_bh(node->peer);
+        if (!peer) {
+            printk(KERN_WARNING "lookup: node->peer dereferenced to NULL, retrying\n");
+            goto retry;
+        }
+        peer = wg_peer_get_maybe_zero(peer);
+        if (!peer) {
+            printk(KERN_WARNING "lookup: wg_peer_get_maybe_zero returned NULL, retrying\n");
+            goto retry;
+        }
+    } else {
+        printk(KERN_INFO "lookup: find_node returned NULL, no matching peer found\n");
+    }
+
+    rcu_read_unlock_bh();
+    printk(KERN_INFO "Exiting lookup with peer=%p\n", peer);
+    return peer;
+}
+
 
 static bool node_placement(struct allowedips_node __rcu *trie, const u8 *key,
 			   u8 cidr, u8 bits, struct allowedips_node **rnode,
 			   struct mutex *lock)
 {
+	printk(KERN_INFO "Entering node_placement(trie=%p, key=%p, cidr=%u, bits=%u, rnode=%p, lock=%p)\n", trie, key, cidr, bits, rnode, lock);
 	struct allowedips_node *node = rcu_dereference_protected(trie, lockdep_is_held(lock));
 	struct allowedips_node *parent = NULL;
 	bool exact = false;
@@ -163,24 +244,30 @@ static bool node_placement(struct allowedips_node __rcu *trie, const u8 *key,
 		node = rcu_dereference_protected(parent->bit[choose(parent, key)], lockdep_is_held(lock));
 	}
 	*rnode = parent;
+	printk(KERN_INFO "Exiting node_placement with exact=%d\n", exact);
 	return exact;
 }
 
 static inline void connect_node(struct allowedips_node __rcu **parent, u8 bit, struct allowedips_node *node)
 {
+	printk(KERN_INFO "Entering connect_node(parent=%p, bit=%u, node=%p)\n", parent, bit, node);
 	node->parent_bit_packed = (unsigned long)parent | bit;
 	rcu_assign_pointer(*parent, node);
+	printk(KERN_INFO "Exiting connect_node\n");
 }
 
 static inline void choose_and_connect_node(struct allowedips_node *parent, struct allowedips_node *node)
 {
+	printk(KERN_INFO "Entering choose_and_connect_node(parent=%p, node=%p)\n", parent, node);
 	u8 bit = choose(parent, node->bits);
 	connect_node(&parent->bit[bit], bit, node);
+	printk(KERN_INFO "Exiting choose_and_connect_node\n");
 }
 
 static int add(struct allowedips_node __rcu **trie, u8 bits, const u8 *key,
 	       u8 cidr, struct wg_peer *peer, struct mutex *lock)
 {
+	printk(KERN_INFO "Entering add(trie=%p, bits=%u, key=%p, cidr=%u, peer=%p, lock=%p)\n", trie, bits, key, cidr, peer, lock);
 	struct allowedips_node *node, *parent, *down, *newnode;
 
 	if (unlikely(cidr > bits || !peer))
@@ -194,11 +281,13 @@ static int add(struct allowedips_node __rcu **trie, u8 bits, const u8 *key,
 		list_add_tail(&node->peer_list, &peer->allowedips_list);
 		copy_and_assign_cidr(node, key, cidr, bits);
 		connect_node(trie, 2, node);
+		printk(KERN_INFO "Exiting add with return 0\n");
 		return 0;
 	}
 	if (node_placement(*trie, key, cidr, bits, &node, lock)) {
 		rcu_assign_pointer(node->peer, peer);
 		list_move_tail(&node->peer_list, &peer->allowedips_list);
+		printk(KERN_INFO "Exiting add with return 0\n");
 		return 0;
 	}
 
@@ -216,6 +305,7 @@ static int add(struct allowedips_node __rcu **trie, u8 bits, const u8 *key,
 		down = rcu_dereference_protected(node->bit[bit], lockdep_is_held(lock));
 		if (!down) {
 			connect_node(&node->bit[bit], bit, newnode);
+			printk(KERN_INFO "Exiting add with return 0\n");
 			return 0;
 		}
 	}
@@ -228,6 +318,7 @@ static int add(struct allowedips_node __rcu **trie, u8 bits, const u8 *key,
 			connect_node(trie, 2, newnode);
 		else
 			choose_and_connect_node(parent, newnode);
+		printk(KERN_INFO "Exiting add with return 0\n");
 		return 0;
 	}
 
@@ -246,17 +337,21 @@ static int add(struct allowedips_node __rcu **trie, u8 bits, const u8 *key,
 		connect_node(trie, 2, node);
 	else
 		choose_and_connect_node(parent, node);
+	printk(KERN_INFO "Exiting add with return 0\n");
 	return 0;
 }
 
 void wg_allowedips_init(struct allowedips *table)
 {
+	printk(KERN_INFO "Entering wg_allowedips_init(table=%p)\n", table);
 	table->root4 = table->root6 = NULL;
 	table->seq = 1;
+	printk(KERN_INFO "Exiting wg_allowedips_init\n");
 }
 
 void wg_allowedips_free(struct allowedips *table, struct mutex *lock)
 {
+	printk(KERN_INFO "Entering wg_allowedips_free(table=%p, lock=%p)\n", table, lock);
 	struct allowedips_node __rcu *old4 = table->root4, *old6 = table->root6;
 
 	++table->seq;
@@ -276,33 +371,41 @@ void wg_allowedips_free(struct allowedips *table, struct mutex *lock)
 		root_remove_peer_lists(node);
 		call_rcu(&node->rcu, root_free_rcu);
 	}
+	printk(KERN_INFO "Exiting wg_allowedips_free\n");
 }
 
 int wg_allowedips_insert_v4(struct allowedips *table, const struct in_addr *ip,
 			    u8 cidr, struct wg_peer *peer, struct mutex *lock)
 {
+	printk(KERN_INFO "Entering wg_allowedips_insert_v4(table=%p, ip=%p, cidr=%u, peer=%p, lock=%p)\n", table, ip, cidr, peer, lock);
 	/* Aligned so it can be passed to fls */
 	u8 key[4] __aligned(__alignof(u32));
 
 	++table->seq;
 	swap_endian(key, (const u8 *)ip, 32);
-	return add(&table->root4, 32, key, cidr, peer, lock);
+	int result = add(&table->root4, 32, key, cidr, peer, lock);
+	printk(KERN_INFO "Exiting wg_allowedips_insert_v4 with result=%d\n", result);
+	return result;
 }
 
 int wg_allowedips_insert_v6(struct allowedips *table, const struct in6_addr *ip,
 			    u8 cidr, struct wg_peer *peer, struct mutex *lock)
 {
+	printk(KERN_INFO "Entering wg_allowedips_insert_v6(table=%p, ip=%p, cidr=%u, peer=%p, lock=%p)\n", table, ip, cidr, peer, lock);
 	/* Aligned so it can be passed to fls64 */
 	u8 key[16] __aligned(__alignof(u64));
 
 	++table->seq;
 	swap_endian(key, (const u8 *)ip, 128);
-	return add(&table->root6, 128, key, cidr, peer, lock);
+	int result = add(&table->root6, 128, key, cidr, peer, lock);
+	printk(KERN_INFO "Exiting wg_allowedips_insert_v6 with result=%d\n", result);
+	return result;
 }
 
 void wg_allowedips_remove_by_peer(struct allowedips *table,
 				  struct wg_peer *peer, struct mutex *lock)
 {
+	printk(KERN_INFO "Entering wg_allowedips_remove_by_peer(table=%p, peer=%p, lock=%p)\n", table, peer, lock);
 	struct allowedips_node *node, *child, **parent_bit, *parent, *tmp;
 	bool free_parent;
 
@@ -338,10 +441,12 @@ void wg_allowedips_remove_by_peer(struct allowedips *table,
 		*(struct allowedips_node **)(parent->parent_bit_packed & ~3UL) = child;
 		call_rcu(&parent->rcu, node_free_rcu);
 	}
+	printk(KERN_INFO "Exiting wg_allowedips_remove_by_peer\n");
 }
 
 int wg_allowedips_read_node(struct allowedips_node *node, u8 ip[16], u8 *cidr)
 {
+	printk(KERN_INFO "Entering wg_allowedips_read_node(node=%p, ip=%p, cidr=%p)\n", node, ip, cidr);
 	const unsigned int cidr_bytes = DIV_ROUND_UP(node->cidr, 8U);
 	swap_endian(ip, node->bits, node->bitlen);
 	memset(ip + cidr_bytes, 0, node->bitlen / 8U - cidr_bytes);
@@ -349,41 +454,58 @@ int wg_allowedips_read_node(struct allowedips_node *node, u8 ip[16], u8 *cidr)
 		ip[cidr_bytes - 1U] &= ~0U << (-node->cidr % 8U);
 
 	*cidr = node->cidr;
-	return node->bitlen == 32 ? AF_INET : AF_INET6;
+	int result = node->bitlen == 32 ? AF_INET : AF_INET6;
+	printk(KERN_INFO "Exiting wg_allowedips_read_node with result=%d\n", result);
+	return result;
 }
 
 /* Returns a strong reference to a peer */
 struct wg_peer *wg_allowedips_lookup_dst(struct allowedips *table,
 					 struct sk_buff *skb)
 {
+	printk(KERN_INFO "Entering wg_allowedips_lookup_dst(table=%p, skb=%p)\n", table, skb);
+	struct wg_peer *result;
 	if (skb->protocol == htons(ETH_P_IP))
-		return lookup(table->root4, 32, &ip_hdr(skb)->daddr);
+		result = lookup(table->root4, 32, &ip_hdr(skb)->daddr);
 	else if (skb->protocol == htons(ETH_P_IPV6))
-		return lookup(table->root6, 128, &ipv6_hdr(skb)->daddr);
-	return NULL;
+		result = lookup(table->root6, 128, &ipv6_hdr(skb)->daddr);
+	else
+		result = NULL;
+	printk(KERN_INFO "Exiting wg_allowedips_lookup_dst with result=%p\n", result);
+	return result;
 }
 
 /* Returns a strong reference to a peer */
 struct wg_peer *wg_allowedips_lookup_src(struct allowedips *table,
 					 struct sk_buff *skb)
 {
+	printk(KERN_INFO "Entering wg_allowedips_lookup_src(table=%p, skb=%p)\n", table, skb);
+	struct wg_peer *result;
 	if (skb->protocol == htons(ETH_P_IP))
-		return lookup(table->root4, 32, &ip_hdr(skb)->saddr);
+		result = lookup(table->root4, 32, &ip_hdr(skb)->saddr);
 	else if (skb->protocol == htons(ETH_P_IPV6))
-		return lookup(table->root6, 128, &ipv6_hdr(skb)->saddr);
-	return NULL;
+		result = lookup(table->root6, 128, &ipv6_hdr(skb)->saddr);
+	else
+		result = NULL;
+	printk(KERN_INFO "Exiting wg_allowedips_lookup_src with result=%p\n", result);
+	return result;
 }
 
 int __init wg_allowedips_slab_init(void)
 {
+	printk(KERN_INFO "Entering wg_allowedips_slab_init()\n");
 	node_cache = KMEM_CACHE(allowedips_node, 0);
-	return node_cache ? 0 : -ENOMEM;
+	int result = node_cache ? 0 : -ENOMEM;
+	printk(KERN_INFO "Exiting wg_allowedips_slab_init with result=%d\n", result);
+	return result;
 }
 
 void wg_allowedips_slab_uninit(void)
 {
+	printk(KERN_INFO "Entering wg_allowedips_slab_uninit()\n");
 	rcu_barrier();
 	kmem_cache_destroy(node_cache);
+	printk(KERN_INFO "Exiting wg_allowedips_slab_uninit\n");
 }
 
 #include "selftest/allowedips.c"
diff --git a/wireguard-linux/drivers/net/wireguard/cookie.c b/wireguard-linux/drivers/net/wireguard/cookie.c
index f89581b5e8cb..9bacf587404e 100644
--- a/wireguard-linux/drivers/net/wireguard/cookie.c
+++ b/wireguard-linux/drivers/net/wireguard/cookie.c
@@ -19,10 +19,12 @@
 void wg_cookie_checker_init(struct cookie_checker *checker,
 			    struct wg_device *wg)
 {
+	printk(KERN_INFO "Entering: wg_cookie_checker_init with checker=%p, wg=%p\n", checker, wg);
 	init_rwsem(&checker->secret_lock);
 	checker->secret_birthdate = ktime_get_coarse_boottime_ns();
 	get_random_bytes(checker->secret, NOISE_HASH_LEN);
 	checker->device = wg;
+	printk(KERN_INFO "Exiting: wg_cookie_checker_init\n");
 }
 
 enum { COOKIE_KEY_LABEL_LEN = 8 };
@@ -33,17 +35,20 @@ static void precompute_key(u8 key[NOISE_SYMMETRIC_KEY_LEN],
 			   const u8 pubkey[NOISE_PUBLIC_KEY_LEN],
 			   const u8 label[COOKIE_KEY_LABEL_LEN])
 {
+	printk(KERN_INFO "Entering: precompute_key with key=%p, pubkey=%p, label=%p\n", key, pubkey, label);
 	struct blake2s_state blake;
 
 	blake2s_init(&blake, NOISE_SYMMETRIC_KEY_LEN);
 	blake2s_update(&blake, label, COOKIE_KEY_LABEL_LEN);
 	blake2s_update(&blake, pubkey, NOISE_PUBLIC_KEY_LEN);
 	blake2s_final(&blake, key);
+	printk(KERN_INFO "Exiting: precompute_key\n");
 }
 
 /* Must hold peer->handshake.static_identity->lock */
 void wg_cookie_checker_precompute_device_keys(struct cookie_checker *checker)
 {
+	printk(KERN_INFO "Entering: wg_cookie_checker_precompute_device_keys with checker=%p\n", checker);
 	if (likely(checker->device->static_identity.has_identity)) {
 		precompute_key(checker->cookie_encryption_key,
 			       checker->device->static_identity.static_public,
@@ -56,41 +61,76 @@ void wg_cookie_checker_precompute_device_keys(struct cookie_checker *checker)
 		       NOISE_SYMMETRIC_KEY_LEN);
 		memset(checker->message_mac1_key, 0, NOISE_SYMMETRIC_KEY_LEN);
 	}
+	printk(KERN_INFO "Exiting: wg_cookie_checker_precompute_device_keys\n");
 }
 
 void wg_cookie_checker_precompute_peer_keys(struct wg_peer *peer)
 {
+	printk(KERN_INFO "Entering: wg_cookie_checker_precompute_peer_keys with peer=%p\n", peer);
 	precompute_key(peer->latest_cookie.cookie_decryption_key,
 		       peer->handshake.remote_static, cookie_key_label);
 	precompute_key(peer->latest_cookie.message_mac1_key,
 		       peer->handshake.remote_static, mac1_key_label);
+	printk(KERN_INFO "Exiting: wg_cookie_checker_precompute_peer_keys\n");
 }
 
 void wg_cookie_init(struct cookie *cookie)
 {
+	printk(KERN_INFO "Entering: wg_cookie_init with cookie=%p\n", cookie);
 	memset(cookie, 0, sizeof(*cookie));
 	init_rwsem(&cookie->lock);
+	printk(KERN_INFO "Exiting: wg_cookie_init\n");
 }
 
+#ifdef ORIGINAL
 static void compute_mac1(u8 mac1[COOKIE_LEN], const void *message, size_t len,
 			 const u8 key[NOISE_SYMMETRIC_KEY_LEN])
 {
+	printk(KERN_INFO "Entering: compute_mac1 with mac1=%p, message=%p, len=%zu, key=%p\n", mac1, message, len, key);
 	len = len - sizeof(struct message_macs) +
 	      offsetof(struct message_macs, mac1);
 	blake2s(mac1, message, key, COOKIE_LEN, len, NOISE_SYMMETRIC_KEY_LEN);
+	printk(KERN_INFO "Exiting: compute_mac1\n");
+}
+#endif
+
+static void compute_mac1(u8 mac1[COOKIE_LEN], const void *message, size_t len,
+                         const u8 key[NOISE_SYMMETRIC_KEY_LEN])
+{
+    printk(KERN_INFO "Entering: compute_mac1 with mac1=%p, message=%p, len=%zu, key=%p\n", mac1, message, len, key);
+
+    // Adjust the length as per the original logic
+    len = len - sizeof(struct message_macs) +
+          offsetof(struct message_macs, mac1);
+
+    // Perform the MAC computation
+    blake2s(mac1, message, key, COOKIE_LEN, len, NOISE_SYMMETRIC_KEY_LEN);
+
+    // Print out diagnostics
+    printk(KERN_INFO "WG: Key used for MAC1 computation: %*phN\n", 
+           NOISE_SYMMETRIC_KEY_LEN, key);
+    printk(KERN_INFO "WG: Message used for MAC1 computation (first 32 bytes): %*phN\n", 
+           (int)min(len, 32UL), message);
+    printk(KERN_INFO "WG: Computed MAC1: %*phN\n", 
+           COOKIE_LEN, mac1);
+
+    printk(KERN_INFO "Exiting: compute_mac1\n");
 }
 
 static void compute_mac2(u8 mac2[COOKIE_LEN], const void *message, size_t len,
 			 const u8 cookie[COOKIE_LEN])
 {
+	printk(KERN_INFO "Entering: compute_mac2 with mac2=%p, message=%p, len=%zu, cookie=%p\n", mac2, message, len, cookie);
 	len = len - sizeof(struct message_macs) +
 	      offsetof(struct message_macs, mac2);
 	blake2s(mac2, message, cookie, COOKIE_LEN, len, COOKIE_LEN);
+	printk(KERN_INFO "Exiting: compute_mac2\n");
 }
 
 static void make_cookie(u8 cookie[COOKIE_LEN], struct sk_buff *skb,
 			struct cookie_checker *checker)
 {
+	printk(KERN_INFO "Entering: make_cookie with cookie=%p, skb=%p, checker=%p\n", cookie, skb, checker);
 	struct blake2s_state state;
 
 	if (wg_birthdate_has_expired(checker->secret_birthdate,
@@ -114,48 +154,74 @@ static void make_cookie(u8 cookie[COOKIE_LEN], struct sk_buff *skb,
 	blake2s_final(&state, cookie);
 
 	up_read(&checker->secret_lock);
+	printk(KERN_INFO "Exiting: make_cookie\n");
 }
 
 enum cookie_mac_state wg_cookie_validate_packet(struct cookie_checker *checker,
 						struct sk_buff *skb,
 						bool check_cookie)
 {
-	struct message_macs *macs = (struct message_macs *)
-		(skb->data + skb->len - sizeof(*macs));
+	printk(KERN_INFO "Entering: wg_cookie_validate_packet with checker=%p, skb=%p, check_cookie=%d\n", checker, skb, check_cookie);
+
+	struct message_macs *macs = (struct message_macs *)(skb->data + skb->len - sizeof(*macs));
 	enum cookie_mac_state ret;
 	u8 computed_mac[COOKIE_LEN];
 	u8 cookie[COOKIE_LEN];
 
+	printk(KERN_INFO "Initial packet length: %u, MACs location: %p\n", skb->len, macs);
+	printk(KERN_INFO "MAC1 from packet: %*phN\n", COOKIE_LEN, macs->mac1);
+	printk(KERN_INFO "MAC2 from packet: %*phN\n", COOKIE_LEN, macs->mac2);
+
 	ret = INVALID_MAC;
-	compute_mac1(computed_mac, skb->data, skb->len,
-		     checker->message_mac1_key);
-	if (crypto_memneq(computed_mac, macs->mac1, COOKIE_LEN))
+
+	// Compute MAC1 and compare
+	compute_mac1(computed_mac, skb->data, skb->len, checker->message_mac1_key);
+	printk(KERN_INFO "Computed MAC1: %*phN\n", COOKIE_LEN, computed_mac);
+
+	if (crypto_memneq(computed_mac, macs->mac1, COOKIE_LEN)) {
+		printk(KERN_ERR "MAC1 validation failed.\n");
 		goto out;
+	}
 
 	ret = VALID_MAC_BUT_NO_COOKIE;
+	printk(KERN_INFO "MAC1 validated successfully.\n");
 
 	if (!check_cookie)
 		goto out;
 
+	// Generate cookie and compute MAC2
 	make_cookie(cookie, skb, checker);
+	printk(KERN_INFO "Generated cookie: %*phN\n", COOKIE_LEN, cookie);
 
 	compute_mac2(computed_mac, skb->data, skb->len, cookie);
-	if (crypto_memneq(computed_mac, macs->mac2, COOKIE_LEN))
+	printk(KERN_INFO "Computed MAC2: %*phN\n", COOKIE_LEN, computed_mac);
+
+	if (crypto_memneq(computed_mac, macs->mac2, COOKIE_LEN)) {
+		printk(KERN_ERR "MAC2 validation failed.\n");
 		goto out;
+	}
 
 	ret = VALID_MAC_WITH_COOKIE_BUT_RATELIMITED;
-	if (!wg_ratelimiter_allow(skb, dev_net(checker->device->dev)))
+	printk(KERN_INFO "MAC2 validated successfully.\n");
+
+	// Rate limiting check
+	if (!wg_ratelimiter_allow(skb, dev_net(checker->device->dev))) {
+		printk(KERN_INFO "Packet rate-limited.\n");
 		goto out;
+	}
 
 	ret = VALID_MAC_WITH_COOKIE;
+	printk(KERN_INFO "Packet passed all validations.\n");
 
 out:
+	printk(KERN_INFO "Exiting: wg_cookie_validate_packet with state=%d\n", ret);
 	return ret;
 }
 
 void wg_cookie_add_mac_to_packet(void *message, size_t len,
 				 struct wg_peer *peer)
 {
+	printk(KERN_INFO "Entering: wg_cookie_add_mac_to_packet with message=%p, len=%zu, peer=%p\n", message, len, peer);
 	struct message_macs *macs = (struct message_macs *)
 		((u8 *)message + len - sizeof(*macs));
 
@@ -175,12 +241,14 @@ void wg_cookie_add_mac_to_packet(void *message, size_t len,
 	else
 		memset(macs->mac2, 0, COOKIE_LEN);
 	up_read(&peer->latest_cookie.lock);
+	printk(KERN_INFO "Exiting: wg_cookie_add_mac_to_packet\n");
 }
 
 void wg_cookie_message_create(struct message_handshake_cookie *dst,
 			      struct sk_buff *skb, __le32 index,
 			      struct cookie_checker *checker)
 {
+	printk(KERN_INFO "Entering: wg_cookie_message_create with dst=%p, skb=%p, index=%u, checker=%p\n", dst, skb, index, checker);
 	struct message_macs *macs = (struct message_macs *)
 		((u8 *)skb->data + skb->len - sizeof(*macs));
 	u8 cookie[COOKIE_LEN];
@@ -193,11 +261,13 @@ void wg_cookie_message_create(struct message_handshake_cookie *dst,
 	xchacha20poly1305_encrypt(dst->encrypted_cookie, cookie, COOKIE_LEN,
 				  macs->mac1, COOKIE_LEN, dst->nonce,
 				  checker->cookie_encryption_key);
+	printk(KERN_INFO "Exiting: wg_cookie_message_create\n");
 }
 
 void wg_cookie_message_consume(struct message_handshake_cookie *src,
 			       struct wg_device *wg)
 {
+	printk(KERN_INFO "Entering: wg_cookie_message_consume with src=%p, wg=%p\n", src, wg);
 	struct wg_peer *peer = NULL;
 	u8 cookie[COOKIE_LEN];
 	bool ret;
@@ -233,4 +303,5 @@ void wg_cookie_message_consume(struct message_handshake_cookie *src,
 
 out:
 	wg_peer_put(peer);
+	printk(KERN_INFO "Exiting: wg_cookie_message_consume\n");
 }
diff --git a/wireguard-linux/drivers/net/wireguard/device.c b/wireguard-linux/drivers/net/wireguard/device.c
index deb9636b0ecf..3a1077ad1fb7 100644
--- a/wireguard-linux/drivers/net/wireguard/device.c
+++ b/wireguard-linux/drivers/net/wireguard/device.c
@@ -19,6 +19,8 @@
 #include <linux/if_arp.h>
 #include <linux/icmp.h>
 #include <linux/suspend.h>
+#include <linux/spinlock.h>
+#include <linux/wireguard.h>
 #include <net/dst_metadata.h>
 #include <net/gso.h>
 #include <net/icmp.h>
@@ -26,6 +28,11 @@
 #include <net/ip_tunnels.h>
 #include <net/addrconf.h>
 
+#define WG_TRANSPORT_UDP	0
+#define WG_TRANSPORT_TCP	1
+
+void wg_tcp_listener_socket_release(struct wg_device *wg);
+
 static LIST_HEAD(device_list);
 
 static int wg_open(struct net_device *dev)
@@ -34,7 +41,9 @@ static int wg_open(struct net_device *dev)
 	struct inet6_dev *dev_v6 = __in6_dev_get(dev);
 	struct wg_device *wg = netdev_priv(dev);
 	struct wg_peer *peer;
-	int ret;
+	int ret = 0;
+
+	printk(KERN_INFO "Entering wg_open: dev=%p\n", dev);
 
 	if (dev_v4) {
 		/* At some point we might put this check near the ip_rt_send_
@@ -47,10 +56,17 @@ static int wg_open(struct net_device *dev)
 	if (dev_v6)
 		dev_v6->cnf.addr_gen_mode = IN6_ADDR_GEN_MODE_NONE;
 
-	mutex_lock(&wg->device_update_lock);
+	
+	wg->listener_active = false;
+	if (wg->transport == WG_TRANSPORT_TCP) {
+		ret = wg_tcp_listener_socket_init(wg, wg->incoming_port);
+		if (ret < 0)
+			goto out;
+	}
 	ret = wg_socket_init(wg, wg->incoming_port);
 	if (ret < 0)
-		goto out;
+		 goto out;
+	mutex_lock(&wg->device_update_lock);
 	list_for_each_entry(peer, &wg->peer_list, peer_list) {
 		wg_packet_send_staged_packets(peer);
 		if (peer->persistent_keepalive_interval)
@@ -58,6 +74,7 @@ static int wg_open(struct net_device *dev)
 	}
 out:
 	mutex_unlock(&wg->device_update_lock);
+	printk(KERN_INFO "Exiting wg_open: dev=%p, ret=%d\n", dev, ret);
 	return ret;
 }
 
@@ -66,16 +83,22 @@ static int wg_pm_notification(struct notifier_block *nb, unsigned long action, v
 	struct wg_device *wg;
 	struct wg_peer *peer;
 
+	printk(KERN_INFO "Entering wg_pm_notification: nb=%p, action=%lu, data=%p\n", nb, action, data);
+
 	/* If the machine is constantly suspending and resuming, as part of
 	 * its normal operation rather than as a somewhat rare event, then we
 	 * don't actually want to clear keys.
 	 */
 	if (IS_ENABLED(CONFIG_PM_AUTOSLEEP) ||
-	    IS_ENABLED(CONFIG_PM_USERSPACE_AUTOSLEEP))
+	    IS_ENABLED(CONFIG_PM_USERSPACE_AUTOSLEEP)) {
+		printk(KERN_INFO "Exiting wg_pm_notification (no action): nb=%p, action=%lu, data=%p\n", nb, action, data);
 		return 0;
+	}
 
-	if (action != PM_HIBERNATION_PREPARE && action != PM_SUSPEND_PREPARE)
+	if (action != PM_HIBERNATION_PREPARE && action != PM_SUSPEND_PREPARE) {
+		printk(KERN_INFO "Exiting wg_pm_notification (no action): nb=%p, action=%lu, data=%p\n", nb, action, data);
 		return 0;
+	}
 
 	rtnl_lock();
 	list_for_each_entry(wg, &device_list, device_list) {
@@ -89,6 +112,7 @@ static int wg_pm_notification(struct notifier_block *nb, unsigned long action, v
 	}
 	rtnl_unlock();
 	rcu_barrier();
+	printk(KERN_INFO "Exiting wg_pm_notification: nb=%p, action=%lu, data=%p\n", nb, action, data);
 	return 0;
 }
 
@@ -99,6 +123,8 @@ static int wg_vm_notification(struct notifier_block *nb, unsigned long action, v
 	struct wg_device *wg;
 	struct wg_peer *peer;
 
+	printk(KERN_INFO "Entering wg_vm_notification: nb=%p, action=%lu, data=%p\n", nb, action, data);
+
 	rtnl_lock();
 	list_for_each_entry(wg, &device_list, device_list) {
 		mutex_lock(&wg->device_update_lock);
@@ -107,6 +133,7 @@ static int wg_vm_notification(struct notifier_block *nb, unsigned long action, v
 		mutex_unlock(&wg->device_update_lock);
 	}
 	rtnl_unlock();
+	printk(KERN_INFO "Exiting wg_vm_notification: nb=%p, action=%lu, data=%p\n", nb, action, data);
 	return 0;
 }
 
@@ -118,6 +145,8 @@ static int wg_stop(struct net_device *dev)
 	struct wg_peer *peer;
 	struct sk_buff *skb;
 
+	printk(KERN_INFO "Entering wg_stop: dev=%p\n", dev);
+
 	mutex_lock(&wg->device_update_lock);
 	list_for_each_entry(peer, &wg->peer_list, peer_list) {
 		wg_packet_purge_staged_packets(peer);
@@ -129,8 +158,23 @@ static int wg_stop(struct net_device *dev)
 	mutex_unlock(&wg->device_update_lock);
 	while ((skb = ptr_ring_consume(&wg->handshake_queue.ring)) != NULL)
 		kfree_skb(skb);
+
 	atomic_set(&wg->handshake_queue_len, 0);
+
+	// Cancel the delayed work and wait for it to finish
+	cancel_delayed_work_sync(&wg->tcp_cleanup_work);
+
+	// Clear the tcp_cleanup_scheduled flag
+	spin_lock_bh(&wg->tcp_cleanup_lock);
+	wg->tcp_cleanup_scheduled = false;
+	spin_unlock_bh(&wg->tcp_cleanup_lock);
+
+	if (wg->transport == WG_TRANSPORT_TCP)
+		wg_tcp_listener_socket_release(wg);
+	
 	wg_socket_reinit(wg, NULL, NULL);
+
+	printk(KERN_INFO "Exiting wg_stop: dev=%p\n", dev);
 	return 0;
 }
 
@@ -144,6 +188,8 @@ static netdev_tx_t wg_xmit(struct sk_buff *skb, struct net_device *dev)
 	u32 mtu;
 	int ret;
 
+	printk(KERN_INFO "Entering wg_xmit: skb=%p, dev=%p\n", skb, dev);
+
 	if (unlikely(!wg_check_packet_protocol(skb))) {
 		ret = -EPROTONOSUPPORT;
 		net_dbg_ratelimited("%s: Invalid IP packet\n", dev->name);
@@ -218,6 +264,7 @@ static netdev_tx_t wg_xmit(struct sk_buff *skb, struct net_device *dev)
 	wg_packet_send_staged_packets(peer);
 
 	wg_peer_put(peer);
+	printk(KERN_INFO "Exiting wg_xmit: skb=%p, dev=%p\n", skb, dev);
 	return NETDEV_TX_OK;
 
 err_peer:
@@ -230,6 +277,7 @@ static netdev_tx_t wg_xmit(struct sk_buff *skb, struct net_device *dev)
 err:
 	DEV_STATS_INC(dev, tx_errors);
 	kfree_skb(skb);
+	printk(KERN_INFO "Exiting wg_xmit with error: skb=%p, dev=%p, ret=%d\n", skb, dev, ret);
 	return ret;
 }
 
@@ -244,6 +292,8 @@ static void wg_destruct(struct net_device *dev)
 {
 	struct wg_device *wg = netdev_priv(dev);
 
+	printk(KERN_INFO "Entering wg_destruct: dev=%p\n", dev);
+
 	rtnl_lock();
 	list_del(&wg->device_list);
 	rtnl_unlock();
@@ -265,10 +315,13 @@ static void wg_destruct(struct net_device *dev)
 	free_percpu(dev->tstats);
 	kvfree(wg->index_hashtable);
 	kvfree(wg->peer_hashtable);
+	wg_destruct_tcp_connection_list(wg);
 	mutex_unlock(&wg->device_update_lock);
 
 	pr_debug("%s: Interface destroyed\n", dev->name);
 	free_netdev(dev);
+
+	printk(KERN_INFO "Exiting wg_destruct: dev=%p\n", dev);
 }
 
 static const struct device_type device_type = { .name = KBUILD_MODNAME };
@@ -282,11 +335,13 @@ static void wg_setup(struct net_device *dev)
 	const int overhead = MESSAGE_MINIMUM_LENGTH + sizeof(struct udphdr) +
 			     max(sizeof(struct ipv6hdr), sizeof(struct iphdr));
 
+	printk(KERN_INFO "Entering wg_setup: dev=%p\n", dev);
+
 	dev->netdev_ops = &netdev_ops;
 	dev->header_ops = &ip_tunnel_header_ops;
 	dev->hard_header_len = 0;
 	dev->addr_len = 0;
-	dev->needed_headroom = DATA_PACKET_HEAD_ROOM;
+	dev->needed_headroom = DATA_PACKET_HEAD_ROOM + (wg->transport ? WG_TCP_ENCAP_HDR_LEN : 0);
 	dev->needed_tailroom = noise_encrypted_len(MESSAGE_PADDING_MULTIPLE);
 	dev->type = ARPHRD_NONE;
 	dev->flags = IFF_POINTOPOINT | IFF_NOARP;
@@ -296,7 +351,8 @@ static void wg_setup(struct net_device *dev)
 	dev->hw_features |= WG_NETDEV_FEATURES;
 	dev->hw_enc_features |= WG_NETDEV_FEATURES;
 	dev->mtu = ETH_DATA_LEN - overhead;
-	dev->max_mtu = round_down(INT_MAX, MESSAGE_PADDING_MULTIPLE) - overhead;
+	dev->max_mtu = round_down(INT_MAX, MESSAGE_PADDING_MULTIPLE) - overhead -
+	               (wg->transport == WG_TRANSPORT_TCP ? WG_TCP_ENCAP_HDR_LEN : 0);
 
 	SET_NETDEV_DEVTYPE(dev, &device_type);
 
@@ -305,6 +361,8 @@ static void wg_setup(struct net_device *dev)
 
 	memset(wg, 0, sizeof(*wg));
 	wg->dev = dev;
+
+	printk(KERN_INFO "Exiting wg_setup: dev=%p\n", dev);
 }
 
 static int wg_newlink(struct net *src_net, struct net_device *dev,
@@ -314,6 +372,8 @@ static int wg_newlink(struct net *src_net, struct net_device *dev,
 	struct wg_device *wg = netdev_priv(dev);
 	int ret = -ENOMEM;
 
+	printk(KERN_INFO "Entering wg_newlink: src_net=%p, dev=%p, tb=%p, data=%p, extack=%p\n", src_net, dev, tb, data, extack);
+
 	rcu_assign_pointer(wg->creating_net, src_net);
 	init_rwsem(&wg->static_identity.lock);
 	mutex_init(&wg->socket_update_lock);
@@ -322,6 +382,12 @@ static int wg_newlink(struct net *src_net, struct net_device *dev,
 	wg_cookie_checker_init(&wg->cookie_checker, wg);
 	INIT_LIST_HEAD(&wg->peer_list);
 	wg->device_update_gen = 1;
+	// Initialize the tcp_cleanup_scheduled flag and spinlock
+	wg->tcp_cleanup_scheduled = false;
+	spin_lock_init(&wg->tcp_cleanup_lock);
+
+	// Initialize the work for tcp_cleanup_worker
+	INIT_DELAYED_WORK(&wg->tcp_cleanup_work, wg_tcp_cleanup_worker);
 
 	wg->peer_hashtable = wg_pubkey_hashtable_alloc();
 	if (!wg->peer_hashtable)
@@ -375,12 +441,21 @@ static int wg_newlink(struct net *src_net, struct net_device *dev,
 
 	list_add(&wg->device_list, &device_list);
 
+	wg->incoming_port = WG_INCOMING_PORT;
+
+	INIT_LIST_HEAD(&wg->tcp_connection_list);
+	spin_lock_init(&wg->tcp_connection_list_lock);
+	wg->tcp_socket4_ready = false;
+	wg->tcp_socket6_ready = false;
+
 	/* We wait until the end to assign priv_destructor, so that
 	 * register_netdevice doesn't call it for us if it fails.
 	 */
 	dev->priv_destructor = wg_destruct;
 
 	pr_debug("%s: Interface created\n", dev->name);
+
+	printk(KERN_INFO "Exiting wg_newlink: src_net=%p, dev=%p, ret=%d\n", src_net, dev, ret);
 	return ret;
 
 err_uninit_ratelimiter:
@@ -403,6 +478,7 @@ static int wg_newlink(struct net *src_net, struct net_device *dev,
 	kvfree(wg->index_hashtable);
 err_free_peer_hashtable:
 	kvfree(wg->peer_hashtable);
+	printk(KERN_INFO "Exiting wg_newlink with error: src_net=%p, dev=%p, ret=%d\n", src_net, dev, ret);
 	return ret;
 }
 
@@ -418,6 +494,8 @@ static void wg_netns_pre_exit(struct net *net)
 	struct wg_device *wg;
 	struct wg_peer *peer;
 
+	printk(KERN_INFO "Entering wg_netns_pre_exit: net=%p\n", net);
+
 	rtnl_lock();
 	list_for_each_entry(wg, &device_list, device_list) {
 		if (rcu_access_pointer(wg->creating_net) == net) {
@@ -432,6 +510,8 @@ static void wg_netns_pre_exit(struct net *net)
 		}
 	}
 	rtnl_unlock();
+
+	printk(KERN_INFO "Exiting wg_netns_pre_exit: net=%p\n", net);
 }
 
 static struct pernet_operations pernet_ops = {
@@ -442,9 +522,11 @@ int __init wg_device_init(void)
 {
 	int ret;
 
+	printk(KERN_INFO "Entering wg_device_init\n");
+
 	ret = register_pm_notifier(&pm_notifier);
 	if (ret)
-		return ret;
+		goto error;
 
 	ret = register_random_vmfork_notifier(&vm_notifier);
 	if (ret)
@@ -458,6 +540,7 @@ int __init wg_device_init(void)
 	if (ret)
 		goto error_pernet;
 
+	printk(KERN_INFO "Exiting wg_device_init: ret=0\n");
 	return 0;
 
 error_pernet:
@@ -466,14 +549,20 @@ int __init wg_device_init(void)
 	unregister_random_vmfork_notifier(&vm_notifier);
 error_pm:
 	unregister_pm_notifier(&pm_notifier);
+error:
+	printk(KERN_INFO "Exiting wg_device_init with error: ret=%d\n", ret);
 	return ret;
 }
 
 void wg_device_uninit(void)
 {
+	printk(KERN_INFO "Entering wg_device_uninit\n");
+
 	rtnl_link_unregister(&link_ops);
 	unregister_pernet_device(&pernet_ops);
 	unregister_random_vmfork_notifier(&vm_notifier);
 	unregister_pm_notifier(&pm_notifier);
 	rcu_barrier();
+
+	printk(KERN_INFO "Exiting wg_device_uninit\n");
 }
diff --git a/wireguard-linux/drivers/net/wireguard/device.h b/wireguard-linux/drivers/net/wireguard/device.h
index 43c7cebbf50b..3640df915fee 100644
--- a/wireguard-linux/drivers/net/wireguard/device.h
+++ b/wireguard-linux/drivers/net/wireguard/device.h
@@ -11,12 +11,17 @@
 #include "peerlookup.h"
 #include "cookie.h"
 
+
 #include <linux/types.h>
 #include <linux/netdevice.h>
 #include <linux/workqueue.h>
+#include <linux/ktime.h>
 #include <linux/mutex.h>
 #include <linux/net.h>
 #include <linux/ptr_ring.h>
+#include <linux/spinlock.h>
+
+#define WG_INCOMING_PORT 51820
 
 struct wg_device;
 
@@ -37,10 +42,27 @@ struct prev_queue {
 	atomic_t count;
 };
 
+struct endpoint {
+	union {
+		struct sockaddr addr;
+		struct sockaddr_in addr4;
+		struct sockaddr_in6 addr6;
+	};
+	union {
+		struct {
+			struct in_addr src4;
+			/* Essentially the same as addr6->scope_id */
+			int src_if4;
+		};
+		struct in6_addr src6;
+	};
+};
+
 struct wg_device {
 	struct net_device *dev;
 	struct crypt_queue encrypt_queue, decrypt_queue, handshake_queue;
-	struct sock __rcu *sock4, *sock6;
+	struct sock __rcu *sock4, *sock6; // UDP listening sockets
+	struct socket __rcu *tcp_listen_socket4, *tcp_listen_socket6; // TCP listening sockets
 	struct net __rcu *creating_net;
 	struct noise_static_identity static_identity;
 	struct workqueue_struct *packet_crypt_wq,*handshake_receive_wq, *handshake_send_wq;
@@ -49,11 +71,21 @@ struct wg_device {
 	struct index_hashtable *index_hashtable;
 	struct allowedips peer_allowedips;
 	struct mutex device_update_lock, socket_update_lock;
-	struct list_head device_list, peer_list;
+	struct endpoint device_endpoint;
+	struct list_head device_list, peer_list, tcp_connection_list;
+	struct task_struct *tcp_listener4_thread, *tcp_listener6_thread;
+	struct delayed_work tcp_cleanup_work;
+        spinlock_t tcp_cleanup_lock; // Add a spinlock to protect the flag
+	bool tcp_cleanup_scheduled;
+	bool tcp_socket4_ready;
+	bool tcp_socket6_ready;
+	bool listener_active;
+	spinlock_t tcp_connection_list_lock;
 	atomic_t handshake_queue_len;
 	unsigned int num_peers, device_update_gen;
 	u32 fwmark;
 	u16 incoming_port;
+	u8 transport;
 };
 
 int wg_device_init(void);
diff --git a/wireguard-linux/drivers/net/wireguard/main.c b/wireguard-linux/drivers/net/wireguard/main.c
index ee4da9ab8013..3f335fae03d5 100644
--- a/wireguard-linux/drivers/net/wireguard/main.c
+++ b/wireguard-linux/drivers/net/wireguard/main.c
@@ -9,6 +9,7 @@
 #include "queueing.h"
 #include "ratelimiter.h"
 #include "netlink.h"
+#include "socket.h"
 
 #include <uapi/linux/wireguard.h>
 
@@ -17,37 +18,127 @@
 #include <linux/genetlink.h>
 #include <net/rtnetlink.h>
 
+#include <linux/netdevice.h>  // Required for net_device
+#include <linux/inetdevice.h> // Required for inetdev processing
+
+// Global structure to hold default network interface information
+struct default_interface_info {
+	struct net_device *dev;   	// Default network interface
+	__be32 ipv4_address;      	// IPv4 address of the default interface
+	struct in6_addr ipv6_address;	// IPv6 address of the default interface
+	bool ipv4_available;		// Flag indicating if IPv4 is available
+	bool ipv6_available;		// Flag indicating if IPv6 is available
+};
+
+struct default_interface_info default_iface_info;
+
+#include <net/route.h>			// Required for routing table access
+#include <net/ip_fib.h>			// Required for FIB (Forwarding Information Base) access
+
+void lookup_default_interface(void)
+{
+	// Use the initial network namespace
+	struct net *net = &init_net;
+	struct flowi4 fl4 = {
+		// Using 8.8.8.8 as a dummy external destination
+		.daddr = htonl(0x08080808),
+	};
+	struct rtable *rt = ip_route_output_key(net, &fl4);
+
+	if (!rt) {
+		printk(KERN_ERR "Failed to find the default route\n");
+		return;
+	}
+
+	// Get the main interface used for routing
+	struct net_device *main_dev = rt->dst.dev;
+
+	if (!main_dev) {
+		printk(KERN_ERR "Failed to find the main network interface\n");
+		ip_rt_put(rt);
+		return;
+	}
+
+	default_iface_info.dev = main_dev;
+
+	// Retrieve the IPv4 address
+	struct in_device *in_dev = __in_dev_get_rtnl(main_dev);
+	struct in_ifaddr *ifa = NULL;
+
+	if (in_dev) {
+		for (ifa = in_dev->ifa_list; ifa; ifa = ifa->ifa_next) {
+			if (ifa->ifa_scope == RT_SCOPE_UNIVERSE) {
+				default_iface_info.ipv4_address = ifa->ifa_address;
+				default_iface_info.ipv4_available = true;
+				printk(KERN_INFO "Default IPv4 interface: %s, IP: %pI4\n",
+				        main_dev->name, &ifa->ifa_address);
+				break;
+			}
+		}
+	}
+
+	// Retrieve the IPv6 address
+	struct inet6_dev *in6_dev = __in6_dev_get(main_dev);
+	struct inet6_ifaddr *ifa6 = NULL;
+
+	if (in6_dev) {
+		list_for_each_entry(ifa6, &in6_dev->addr_list, if_list) {
+			if (ifa6->scope == RT_SCOPE_UNIVERSE) {
+				default_iface_info.ipv6_address = ifa6->addr;
+				default_iface_info.ipv6_available = true;
+				printk(KERN_INFO "Default IPv6 interface: %s, IP: %pI6\n",
+				       main_dev->name, &ifa6->addr);
+				break;
+			}
+		}
+	}
+
+	// Clean up routing table reference
+	ip_rt_put(rt);
+}
+
 static int __init wg_mod_init(void)
 {
 	int ret;
 
+	printk(KERN_INFO "Entering: wg_mod_init\n");
+
 	ret = wg_allowedips_slab_init();
+	printk(KERN_INFO "wg_mod_init: wg_allowedips_slab_init() = %d\n", ret);
 	if (ret < 0)
 		goto err_allowedips;
 
 #ifdef DEBUG
 	ret = -ENOTRECOVERABLE;
-	if (!wg_allowedips_selftest() || !wg_packet_counter_selftest() ||
-	    !wg_ratelimiter_selftest())
+	if (!wg_allowedips_selftest() || !wg_packet_counter_selftest() || !wg_ratelimiter_selftest()) {
+		printk(KERN_INFO "wg_mod_init: Self-test failed\n");
 		goto err_peer;
+	}
 #endif
 	wg_noise_init();
+	printk(KERN_INFO "wg_mod_init: wg_noise_init() completed\n");
 
 	ret = wg_peer_init();
+	printk(KERN_INFO "wg_mod_init: wg_peer_init() = %d\n", ret);
 	if (ret < 0)
 		goto err_peer;
 
 	ret = wg_device_init();
+	printk(KERN_INFO "wg_mod_init: wg_device_init() = %d\n", ret);
 	if (ret < 0)
 		goto err_device;
 
 	ret = wg_genetlink_init();
+	printk(KERN_INFO "wg_mod_init: wg_genetlink_init() = %d\n", ret);
 	if (ret < 0)
 		goto err_netlink;
 
 	pr_info("WireGuard " WIREGUARD_VERSION " loaded. See www.wireguard.com for information.\n");
 	pr_info("Copyright (C) 2015-2019 Jason A. Donenfeld <Jason@zx2c4.com>. All Rights Reserved.\n");
 
+	lookup_default_interface();
+	
+	printk(KERN_INFO "Exiting: wg_mod_init\n");
 	return 0;
 
 err_netlink:
@@ -57,15 +148,27 @@ static int __init wg_mod_init(void)
 err_peer:
 	wg_allowedips_slab_uninit();
 err_allowedips:
+	printk(KERN_INFO "Exiting with error: wg_mod_init, ret = %d\n", ret);
 	return ret;
 }
 
 static void __exit wg_mod_exit(void)
 {
+	printk(KERN_INFO "Entering: wg_mod_exit\n");
+
 	wg_genetlink_uninit();
+	printk(KERN_INFO "wg_mod_exit: wg_genetlink_uninit() completed\n");
+
 	wg_device_uninit();
+	printk(KERN_INFO "wg_mod_exit: wg_device_uninit() completed\n");
+
 	wg_peer_uninit();
+	printk(KERN_INFO "wg_mod_exit: wg_peer_uninit() completed\n");
+
 	wg_allowedips_slab_uninit();
+	printk(KERN_INFO "wg_mod_exit: wg_allowedips_slab_uninit() completed\n");
+
+	printk(KERN_INFO "Exiting: wg_mod_exit\n");
 }
 
 module_init(wg_mod_init);
diff --git a/wireguard-linux/drivers/net/wireguard/netlink.c b/wireguard-linux/drivers/net/wireguard/netlink.c
index e220d761b1f2..fa9c73e69466 100644
--- a/wireguard-linux/drivers/net/wireguard/netlink.c
+++ b/wireguard-linux/drivers/net/wireguard/netlink.c
@@ -13,10 +13,15 @@
 #include <uapi/linux/wireguard.h>
 
 #include <linux/if.h>
+#include <linux/version.h>
 #include <net/genetlink.h>
+#include <net/netlink.h>
 #include <net/sock.h>
+#include <crypto/algapi.h>
 #include <crypto/utils.h>
 
+void wg_tcp_listener_socket_release(struct wg_device *wg);
+
 static struct genl_family genl_family;
 
 static const struct nla_policy device_policy[WGDEVICE_A_MAX + 1] = {
@@ -27,7 +32,8 @@ static const struct nla_policy device_policy[WGDEVICE_A_MAX + 1] = {
 	[WGDEVICE_A_FLAGS]		= { .type = NLA_U32 },
 	[WGDEVICE_A_LISTEN_PORT]	= { .type = NLA_U16 },
 	[WGDEVICE_A_FWMARK]		= { .type = NLA_U32 },
-	[WGDEVICE_A_PEERS]		= { .type = NLA_NESTED }
+	[WGDEVICE_A_PEERS]		= { .type = NLA_NESTED },
+	[WGDEVICE_A_TRANSPORT]		= { .type = NLA_U8 }
 };
 
 static const struct nla_policy peer_policy[WGPEER_A_MAX + 1] = {
@@ -49,19 +55,300 @@ static const struct nla_policy allowedip_policy[WGALLOWEDIP_A_MAX + 1] = {
 	[WGALLOWEDIP_A_CIDR_MASK]	= { .type = NLA_U8 }
 };
 
-static struct wg_device *lookup_interface(struct nlattr **attrs,
-					  struct sk_buff *skb)
+
+#ifdef DIAGNOSTIC
+// Diagnostic functions for decoding netlink attributes and messages
+
+// Function to print the libmnl formatted netlink message header
+static void wg_print_netlink_header_libmnl(const struct nlmsghdr *nlh)
+{
+    printk(KERN_INFO "----------------\t------------------\n");
+    printk(KERN_INFO "|  %.010u  |\t| message length |\n", nlh->nlmsg_len);
+    printk(KERN_INFO "| %.05u | %c%c%c%c |\t|  type | flags  |\n",
+           nlh->nlmsg_type,
+           nlh->nlmsg_flags & NLM_F_REQUEST ? 'R' : '-',
+           nlh->nlmsg_flags & NLM_F_MULTI ? 'M' : '-',
+           nlh->nlmsg_flags & NLM_F_ACK ? 'A' : '-',
+           nlh->nlmsg_flags & NLM_F_ECHO ? 'E' : '-');
+    printk(KERN_INFO "|  %.010u  |\t| sequence number|\n", nlh->nlmsg_seq);
+    printk(KERN_INFO "|  %.010u  |\t|     port ID    |\n", nlh->nlmsg_pid);
+    printk(KERN_INFO "----------------\t------------------\n");
+}
+
+// Function to print the libmnl formatted netlink message payload
+static void wg_print_netlink_payload_libmnl(const struct nlmsghdr *nlh, size_t extra_header_size)
+{
+    unsigned int i;
+    int rem = 0;
+
+    for (i = sizeof(struct nlmsghdr); i < nlh->nlmsg_len; i += 4) {
+        char *b = (char *)nlh;
+        struct nlattr *attr = (struct nlattr *)(b + i);
+
+        if (nlh->nlmsg_type < NLMSG_MIN_TYPE) {
+            printk(KERN_INFO "| %.2x %.2x %.2x %.2x  |\t",
+                   0xff & b[i], 0xff & b[i + 1],
+                   0xff & b[i + 2], 0xff & b[i + 3]);
+            printk(KERN_INFO "|                |\n");
+        } else if (extra_header_size > 0) {
+            extra_header_size -= 4;
+            printk(KERN_INFO "| %.2x %.2x %.2x %.2x  |\t",
+                   0xff & b[i], 0xff & b[i + 1],
+                   0xff & b[i + 2], 0xff & b[i + 3]);
+            printk(KERN_INFO "|  extra header  |\n");
+        } else if (rem == 0 && (attr->nla_type & NLA_TYPE_MASK) != 0) {
+            printk(KERN_INFO "|%.5u|%c%c|%.5u|\t",
+                   attr->nla_len,
+                   attr->nla_type & NLA_F_NESTED ? 'N' : '-',
+                   attr->nla_type & NLA_F_NET_BYTEORDER ? 'B' : '-',
+                   attr->nla_type & NLA_TYPE_MASK);
+            printk(KERN_INFO "|len |flags| type|\n");
+
+            if (!(attr->nla_type & NLA_F_NESTED)) {
+                rem = NLA_ALIGN(attr->nla_len) - sizeof(struct nlattr);
+            }
+        } else if (rem > 0) {
+            rem -= 4;
+            printk(KERN_INFO "| %.2x %.2x %.2x %.2x  |\t",
+                   0xff & b[i], 0xff & b[i + 1],
+                   0xff & b[i + 2], 0xff & b[i + 3]);
+            printk(KERN_INFO "|      data      |");
+            printk(KERN_INFO "\t %c %c %c %c\n",
+                   isprint(b[i]) ? b[i] : ' ',
+                   isprint(b[i + 1]) ? b[i + 1] : ' ',
+                   isprint(b[i + 2]) ? b[i + 2] : ' ',
+                   isprint(b[i + 3]) ? b[i + 3] : ' ');
+        }
+    }
+    printk(KERN_INFO "----------------\t------------------\n");
+}
+
+// Print the netlink message using libmnl format
+static void wg_print_netlink_message_libmnl(const struct nlmsghdr *nlh)
+{
+    wg_print_netlink_header_libmnl(nlh);
+    wg_print_netlink_payload_libmnl(nlh, 0);
+}
+
+// Routine to parse and print flags with verbose values
+static void wg_print_flags_verbose(uint32_t flags)
+{
+    printk(KERN_INFO "Flags: 0x%08x (", flags);
+    if (flags & NLM_F_REQUEST) printk(KERN_INFO "REQUEST ");
+    if (flags & NLM_F_MULTI) printk(KERN_INFO "MULTI ");
+    if (flags & NLM_F_ACK) printk(KERN_INFO "ACK ");
+    if (flags & NLM_F_ECHO) printk(KERN_INFO "ECHO ");
+    if (flags & NLM_F_REPLACE) printk(KERN_INFO "REPLACE ");
+    if (flags & NLM_F_EXCL) printk(KERN_INFO "EXCL ");
+    if (flags & NLM_F_CREATE) printk(KERN_INFO "CREATE ");
+    if (flags & NLM_F_APPEND) printk(KERN_INFO "APPEND ");
+    printk(KERN_INFO ")\n");
+}
+
+// Routine to parse and print peer flags with verbose labels
+static void wg_print_peer_flags_verbose(uint32_t flags)
+{
+    printk(KERN_INFO "Peer Flags: 0x%08x (", flags);
+    if (flags & WGPEER_F_REMOVE_ME) printk(KERN_INFO "REMOVE_ME ");
+    if (flags & WGPEER_F_REPLACE_ALLOWEDIPS) printk(KERN_INFO "REPLACE_ALLOWEDIPS ");
+    if (flags & WGPEER_F_UPDATE_ONLY) printk(KERN_INFO "UPDATE_ONLY ");
+    printk(KERN_INFO ")\n");
+}
+
+// Functions to print the allowed IP attributes
+static void wg_print_allowedip_attr(const struct nlattr *attr)
+{
+    int type = nla_type(attr);
+
+    switch (type) {
+    case WGALLOWEDIP_A_FAMILY:
+        printk(KERN_INFO "WGALLOWEDIP_A_FAMILY: %u\n", nla_get_u16(attr));
+        break;
+    case WGALLOWEDIP_A_IPADDR:
+        printk(KERN_INFO "WGALLOWEDIP_A_IPADDR: %pI6\n", nla_data(attr));
+        break;
+    case WGALLOWEDIP_A_CIDR_MASK:
+        printk(KERN_INFO "WGALLOWEDIP_A_CIDR_MASK: %u\n", nla_get_u8(attr));
+        break;
+    default:
+        printk(KERN_INFO "Unknown Allowed IP Attribute Type: %d\n", type);
+        break;
+    }
+}
+
+static void wg_print_peer_allowedips(const struct nlattr *attr)
+{
+    struct nlattr *nested_attr;
+    int rem;
+
+    nla_for_each_nested(nested_attr, attr, rem) {
+        wg_print_allowedip_attr(nested_attr);
+    }
+}
+
+// Functions to print the peer attributes
+static void wg_print_peer_attr(const struct nlattr *attr)
+{
+    int type = nla_type(attr);
+
+    switch (type) {
+    case WGPEER_A_PUBLIC_KEY:
+        printk(KERN_INFO "WGPEER_A_PUBLIC_KEY: %*phN\n", nla_len(attr), nla_data(attr));
+        break;
+    case WGPEER_A_PRESHARED_KEY:
+        printk(KERN_INFO "WGPEER_A_PRESHARED_KEY: %*phN\n", nla_len(attr), nla_data(attr));
+        break;
+    case WGPEER_A_FLAGS:
+        printk(KERN_INFO "WGPEER_A_FLAGS: %u\n", nla_get_u32(attr));
+        wg_print_peer_flags_verbose(nla_get_u32(attr));
+        break;
+    case WGPEER_A_ENDPOINT:
+        printk(KERN_INFO "WGPEER_A_ENDPOINT: %pIS\n", nla_data(attr));
+        break;
+    case WGPEER_A_PERSISTENT_KEEPALIVE_INTERVAL:
+        printk(KERN_INFO "WGPEER_A_PERSISTENT_KEEPALIVE_INTERVAL: %u\n", nla_get_u16(attr));
+        break;
+    case WGPEER_A_LAST_HANDSHAKE_TIME: {
+        const struct __kernel_timespec *ts = nla_data(attr);
+        printk(KERN_INFO "WGPEER_A_LAST_HANDSHAKE_TIME: %lld.%.9ld\n",
+               (long long)ts->tv_sec, ts->tv_nsec);
+        break;
+    }
+    case WGPEER_A_RX_BYTES:
+        printk(KERN_INFO "WGPEER_A_RX_BYTES: %llu\n", (unsigned long long)nla_get_u64(attr));
+        break;
+    case WGPEER_A_TX_BYTES:
+        printk(KERN_INFO "WGPEER_A_TX_BYTES: %llu\n", (unsigned long long)nla_get_u64(attr));
+        break;
+    case WGPEER_A_ALLOWEDIPS:
+        printk(KERN_INFO "WGPEER_A_ALLOWEDIPS (Nested Attributes):\n");
+        wg_print_peer_allowedips(attr);
+        break;
+    default:
+        printk(KERN_INFO "Unknown Peer Attribute Type: %d\n", type);
+        break;
+    }
+}
+
+// Functions to print the device attributes
+static void wg_print_device_peers(const struct nlattr *attr)
+{
+    struct nlattr *nested_attr;
+    int rem;
+
+    nla_for_each_nested(nested_attr, attr, rem) {
+        wg_print_peer_attr(nested_attr);
+    }
+}
+
+static void wg_print_device_attr(const struct nlattr *attr)
+{
+    int type = nla_type(attr);
+
+    switch (type) {
+    case WGDEVICE_A_IFINDEX:
+        printk(KERN_INFO "WGDEVICE_A_IFINDEX: %u\n", nla_get_u32(attr));
+        break;
+    case WGDEVICE_A_IFNAME:
+        printk(KERN_INFO "WGDEVICE_A_IFNAME: %s\n", nla_data(attr));
+        break;
+    case WGDEVICE_A_PRIVATE_KEY:
+        printk(KERN_INFO "WGDEVICE_A_PRIVATE_KEY: %*phN\n", nla_len(attr), nla_data(attr));
+        break;
+    case WGDEVICE_A_PUBLIC_KEY:
+        printk(KERN_INFO "WGDEVICE_A_PUBLIC_KEY: %*phN\n", nla_len(attr), nla_data(attr));
+        break;
+    case WGDEVICE_A_FLAGS:
+        printk(KERN_INFO "WGDEVICE_A_FLAGS: %u\n", nla_get_u32(attr));
+        break;
+    case WGDEVICE_A_LISTEN_PORT:
+        printk(KERN_INFO "WGDEVICE_A_LISTEN_PORT: %u\n", nla_get_u16(attr));
+        break;
+    case WGDEVICE_A_FWMARK:
+        printk(KERN_INFO "WGDEVICE_A_FWMARK: %u\n", nla_get_u32(attr));
+        break;
+    case WGDEVICE_A_PEERS:
+        printk(KERN_INFO "WGDEVICE_A_PEERS (Nested Attributes):\n");
+        wg_print_device_peers(attr);
+        break;
+    case WGDEVICE_A_TRANSPORT:
+        printk(KERN_INFO "WGDEVICE_A_TRANSPORT: %u\n", nla_get_u8(attr));
+        break;
+    default:
+        printk(KERN_INFO "Unknown Device Attribute Type: %d\n", type);
+        break;
+    }
+}
+
+static void wg_print_netlink_message_verbose(const struct nlmsghdr *nlh)
+{
+    struct nlattr *attr;
+    int rem;
+
+    printk(KERN_INFO "Verbose Netlink Message:\n");
+    printk(KERN_INFO "  nlmsg_len: %u\n", nlh->nlmsg_len);
+    printk(KERN_INFO "  nlmsg_type: %u\n", nlh->nlmsg_type);
+
+    // Print command
+    switch (nlh->nlmsg_type) {
+    case WG_CMD_GET_DEVICE:
+        printk(KERN_INFO "  Command: WG_CMD_GET_DEVICE\n");
+        break;
+    case WG_CMD_SET_DEVICE:
+        printk(KERN_INFO "  Command: WG_CMD_SET_DEVICE\n");
+        break;
+    default:
+        printk(KERN_INFO "  Unknown Command: %u\n", nlh->nlmsg_type);
+        break;
+    }
+
+    wg_print_flags_verbose(nlh->nlmsg_flags);
+    printk(KERN_INFO "  nlmsg_seq: %u\n", nlh->nlmsg_seq);
+    printk(KERN_INFO "  nlmsg_pid: %u\n", nlh->nlmsg_pid);
+    printk(KERN_INFO "Attributes:\n");
+
+    nla_for_each_attr(attr, nlmsg_data(nlh), nlmsg_len(nlh) - NLMSG_HDRLEN, rem) {
+        switch (nlh->nlmsg_type) {
+        case WG_CMD_GET_DEVICE:
+        case WG_CMD_SET_DEVICE:
+            wg_print_device_attr(attr);
+            break;
+        default:
+            printk(KERN_INFO "Unknown Netlink Message Type: %u\n", nlh->nlmsg_type);
+            break;
+        }
+    }
+
+    printk(KERN_INFO "Hex Dump of Netlink Message:\n");
+    printk(KERN_INFO "%*phN\n", nlh->nlmsg_len, nlh);
+}
+
+// Add a function to print the entire buffer of netlink messages
+static void wg_print_netlink_buffer(const void *buf, size_t len)
+{
+    const struct nlmsghdr *nlh = buf;
+
+    while (nlh && NLMSG_OK(nlh, len)) {
+        wg_print_netlink_message_verbose(nlh);
+        wg_print_netlink_message_libmnl(nlh);
+        nlh = NLMSG_NEXT(nlh, len);
+    }
+}
+
+#endif // DIAGNOSTIC
+
+static struct wg_device *lookup_interface(struct nlattr **attrs, struct sk_buff *skb)
 {
 	struct net_device *dev = NULL;
 
+	printk(KERN_INFO "Entering lookup_interface: attrs = %p, skb = %p\n", attrs, skb);
+
 	if (!attrs[WGDEVICE_A_IFINDEX] == !attrs[WGDEVICE_A_IFNAME])
 		return ERR_PTR(-EBADR);
 	if (attrs[WGDEVICE_A_IFINDEX])
-		dev = dev_get_by_index(sock_net(skb->sk),
-				       nla_get_u32(attrs[WGDEVICE_A_IFINDEX]));
+		dev = dev_get_by_index(sock_net(skb->sk), nla_get_u32(attrs[WGDEVICE_A_IFINDEX]));
 	else if (attrs[WGDEVICE_A_IFNAME])
-		dev = dev_get_by_name(sock_net(skb->sk),
-				      nla_data(attrs[WGDEVICE_A_IFNAME]));
+		dev = dev_get_by_name(sock_net(skb->sk), nla_data(attrs[WGDEVICE_A_IFNAME]));
 	if (!dev)
 		return ERR_PTR(-ENODEV);
 	if (!dev->rtnl_link_ops || !dev->rtnl_link_ops->kind ||
@@ -69,27 +356,33 @@ static struct wg_device *lookup_interface(struct nlattr **attrs,
 		dev_put(dev);
 		return ERR_PTR(-EOPNOTSUPP);
 	}
+
+	printk(KERN_INFO "Exiting lookup_interface\n");
+
 	return netdev_priv(dev);
 }
 
-static int get_allowedips(struct sk_buff *skb, const u8 *ip, u8 cidr,
-			  int family)
+static int get_allowedips(struct sk_buff *skb, const u8 *ip, u8 cidr, int family)
 {
 	struct nlattr *allowedip_nest;
 
+	printk(KERN_INFO "Entering get_allowedips: skb = %p, ip = %p, cidr = %u, family = %d\n", skb, ip, cidr, family);
+
 	allowedip_nest = nla_nest_start(skb, 0);
 	if (!allowedip_nest)
 		return -EMSGSIZE;
 
 	if (nla_put_u8(skb, WGALLOWEDIP_A_CIDR_MASK, cidr) ||
 	    nla_put_u16(skb, WGALLOWEDIP_A_FAMILY, family) ||
-	    nla_put(skb, WGALLOWEDIP_A_IPADDR, family == AF_INET6 ?
-		    sizeof(struct in6_addr) : sizeof(struct in_addr), ip)) {
+	    nla_put(skb, WGALLOWEDIP_A_IPADDR, family == AF_INET6 ? sizeof(struct in6_addr) : sizeof(struct in_addr), ip)) {
 		nla_nest_cancel(skb, allowedip_nest);
 		return -EMSGSIZE;
 	}
 
 	nla_nest_end(skb, allowedip_nest);
+
+	printk(KERN_INFO "Exiting get_allowedips\n");
+
 	return 0;
 }
 
@@ -102,20 +395,19 @@ struct dump_ctx {
 
 #define DUMP_CTX(cb) ((struct dump_ctx *)(cb)->args)
 
-static int
-get_peer(struct wg_peer *peer, struct sk_buff *skb, struct dump_ctx *ctx)
+static int get_peer(struct wg_peer *peer, struct sk_buff *skb, struct dump_ctx *ctx)
 {
-
 	struct nlattr *allowedips_nest, *peer_nest = nla_nest_start(skb, 0);
 	struct allowedips_node *allowedips_node = ctx->next_allowedip;
 	bool fail;
 
+	printk(KERN_INFO "Entering get_peer: peer = %p, skb = %p, ctx = %p\n", peer, skb, ctx);
+
 	if (!peer_nest)
 		return -EMSGSIZE;
 
 	down_read(&peer->handshake.lock);
-	fail = nla_put(skb, WGPEER_A_PUBLIC_KEY, NOISE_PUBLIC_KEY_LEN,
-		       peer->handshake.remote_static);
+	fail = nla_put(skb, WGPEER_A_PUBLIC_KEY, NOISE_PUBLIC_KEY_LEN, peer->handshake.remote_static);
 	up_read(&peer->handshake.lock);
 	if (fail)
 		goto err;
@@ -127,39 +419,27 @@ get_peer(struct wg_peer *peer, struct sk_buff *skb, struct dump_ctx *ctx)
 		};
 
 		down_read(&peer->handshake.lock);
-		fail = nla_put(skb, WGPEER_A_PRESHARED_KEY,
-			       NOISE_SYMMETRIC_KEY_LEN,
-			       peer->handshake.preshared_key);
+		fail = nla_put(skb, WGPEER_A_PRESHARED_KEY, NOISE_SYMMETRIC_KEY_LEN, peer->handshake.preshared_key);
 		up_read(&peer->handshake.lock);
 		if (fail)
 			goto err;
 
-		if (nla_put(skb, WGPEER_A_LAST_HANDSHAKE_TIME,
-			    sizeof(last_handshake), &last_handshake) ||
-		    nla_put_u16(skb, WGPEER_A_PERSISTENT_KEEPALIVE_INTERVAL,
-				peer->persistent_keepalive_interval) ||
-		    nla_put_u64_64bit(skb, WGPEER_A_TX_BYTES, peer->tx_bytes,
-				      WGPEER_A_UNSPEC) ||
-		    nla_put_u64_64bit(skb, WGPEER_A_RX_BYTES, peer->rx_bytes,
-				      WGPEER_A_UNSPEC) ||
+		if (nla_put(skb, WGPEER_A_LAST_HANDSHAKE_TIME, sizeof(last_handshake), &last_handshake) ||
+		    nla_put_u16(skb, WGPEER_A_PERSISTENT_KEEPALIVE_INTERVAL, peer->persistent_keepalive_interval) ||
+		    nla_put_u64_64bit(skb, WGPEER_A_TX_BYTES, peer->tx_bytes, WGPEER_A_UNSPEC) ||
+		    nla_put_u64_64bit(skb, WGPEER_A_RX_BYTES, peer->rx_bytes, WGPEER_A_UNSPEC) ||
 		    nla_put_u32(skb, WGPEER_A_PROTOCOL_VERSION, 1))
 			goto err;
 
 		read_lock_bh(&peer->endpoint_lock);
 		if (peer->endpoint.addr.sa_family == AF_INET)
-			fail = nla_put(skb, WGPEER_A_ENDPOINT,
-				       sizeof(peer->endpoint.addr4),
-				       &peer->endpoint.addr4);
+			fail = nla_put(skb, WGPEER_A_ENDPOINT, sizeof(peer->endpoint.addr4), &peer->endpoint.addr4);
 		else if (peer->endpoint.addr.sa_family == AF_INET6)
-			fail = nla_put(skb, WGPEER_A_ENDPOINT,
-				       sizeof(peer->endpoint.addr6),
-				       &peer->endpoint.addr6);
+			fail = nla_put(skb, WGPEER_A_ENDPOINT, sizeof(peer->endpoint.addr6), &peer->endpoint.addr6);
 		read_unlock_bh(&peer->endpoint_lock);
 		if (fail)
 			goto err;
-		allowedips_node =
-			list_first_entry_or_null(&peer->allowedips_list,
-					struct allowedips_node, peer_list);
+		allowedips_node = list_first_entry_or_null(&peer->allowedips_list, struct allowedips_node, peer_list);
 	}
 	if (!allowedips_node)
 		goto no_allowedips;
@@ -172,9 +452,8 @@ get_peer(struct wg_peer *peer, struct sk_buff *skb, struct dump_ctx *ctx)
 	if (!allowedips_nest)
 		goto err;
 
-	list_for_each_entry_from(allowedips_node, &peer->allowedips_list,
-				 peer_list) {
-		u8 cidr, ip[16] __aligned(__alignof(u64));
+	list_for_each_entry_from(allowedips_node, &peer->allowedips_list, peer_list) {
+		u8 cidr, ip[16] __aligned(__alignof__(u64));
 		int family;
 
 		family = wg_allowedips_read_node(allowedips_node, ip, &cidr);
@@ -190,6 +469,9 @@ get_peer(struct wg_peer *peer, struct sk_buff *skb, struct dump_ctx *ctx)
 	nla_nest_end(skb, peer_nest);
 	ctx->next_allowedip = NULL;
 	ctx->allowedips_seq = 0;
+
+	printk(KERN_INFO "Exiting get_peer\n");
+
 	return 0;
 err:
 	nla_nest_cancel(skb, peer_nest);
@@ -200,10 +482,19 @@ static int wg_get_device_start(struct netlink_callback *cb)
 {
 	struct wg_device *wg;
 
+	printk(KERN_INFO "Entering wg_get_device_start: cb = %p\n", cb);
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(6,6,0)
 	wg = lookup_interface(genl_info_dump(cb)->attrs, cb->skb);
+#else
+	wg = lookup_interface(genl_dumpit_info(cb)->attrs, cb->skb);
+#endif
 	if (IS_ERR(wg))
 		return PTR_ERR(wg);
 	DUMP_CTX(cb)->wg = wg;
+
+	printk(KERN_INFO "Exiting wg_get_device_start\n");
+
 	return 0;
 }
 
@@ -217,33 +508,30 @@ static int wg_get_device_dump(struct sk_buff *skb, struct netlink_callback *cb)
 	bool done = true;
 	void *hdr;
 
+	printk(KERN_INFO "Entering wg_get_device_dump: skb = %p, cb = %p\n", skb, cb);
+
 	rtnl_lock();
 	mutex_lock(&wg->device_update_lock);
 	cb->seq = wg->device_update_gen;
 	next_peer_cursor = ctx->next_peer;
 
-	hdr = genlmsg_put(skb, NETLINK_CB(cb->skb).portid, cb->nlh->nlmsg_seq,
-			  &genl_family, NLM_F_MULTI, WG_CMD_GET_DEVICE);
+	hdr = genlmsg_put(skb, NETLINK_CB(cb->skb).portid, cb->nlh->nlmsg_seq, &genl_family, NLM_F_MULTI, WG_CMD_GET_DEVICE);
 	if (!hdr)
 		goto out;
 	genl_dump_check_consistent(cb, hdr);
 
 	if (!ctx->next_peer) {
-		if (nla_put_u16(skb, WGDEVICE_A_LISTEN_PORT,
-				wg->incoming_port) ||
+		if (nla_put_u16(skb, WGDEVICE_A_LISTEN_PORT, wg->incoming_port) ||
 		    nla_put_u32(skb, WGDEVICE_A_FWMARK, wg->fwmark) ||
 		    nla_put_u32(skb, WGDEVICE_A_IFINDEX, wg->dev->ifindex) ||
-		    nla_put_string(skb, WGDEVICE_A_IFNAME, wg->dev->name))
+		    nla_put_string(skb, WGDEVICE_A_IFNAME, wg->dev->name) ||
+		    nla_put_u8(skb, WGDEVICE_A_TRANSPORT, wg->transport))
 			goto out;
 
 		down_read(&wg->static_identity.lock);
 		if (wg->static_identity.has_identity) {
-			if (nla_put(skb, WGDEVICE_A_PRIVATE_KEY,
-				    NOISE_PUBLIC_KEY_LEN,
-				    wg->static_identity.static_private) ||
-			    nla_put(skb, WGDEVICE_A_PUBLIC_KEY,
-				    NOISE_PUBLIC_KEY_LEN,
-				    wg->static_identity.static_public)) {
+			if (nla_put(skb, WGDEVICE_A_PRIVATE_KEY, NOISE_PUBLIC_KEY_LEN, wg->static_identity.static_private) ||
+			    nla_put(skb, WGDEVICE_A_PUBLIC_KEY, NOISE_PUBLIC_KEY_LEN, wg->static_identity.static_public)) {
 				up_read(&wg->static_identity.lock);
 				goto out;
 			}
@@ -254,6 +542,7 @@ static int wg_get_device_dump(struct sk_buff *skb, struct netlink_callback *cb)
 	peers_nest = nla_nest_start(skb, WGDEVICE_A_PEERS);
 	if (!peers_nest)
 		goto out;
+
 	ret = 0;
 	/* If the last cursor was removed via list_del_init in peer_remove, then
 	 * we just treat this the same as there being no more peers left. The
@@ -290,9 +579,15 @@ static int wg_get_device_dump(struct sk_buff *skb, struct netlink_callback *cb)
 	genlmsg_end(skb, hdr);
 	if (done) {
 		ctx->next_peer = NULL;
+
+		printk(KERN_INFO "Exiting wg_get_device_dump\n");
+
 		return 0;
 	}
 	ctx->next_peer = next_peer_cursor;
+
+	printk(KERN_INFO "Exiting wg_get_device_dump\n");
+
 	return skb->len;
 
 	/* At this point, we can't really deal ourselves with safely zeroing out
@@ -305,15 +600,23 @@ static int wg_get_device_done(struct netlink_callback *cb)
 {
 	struct dump_ctx *ctx = DUMP_CTX(cb);
 
+	printk(KERN_INFO "Entering wg_get_device_done: cb = %p\n", cb);
+
 	if (ctx->wg)
 		dev_put(ctx->wg->dev);
 	wg_peer_put(ctx->next_peer);
+
+	printk(KERN_INFO "Exiting wg_get_device_done\n");
+
 	return 0;
 }
 
 static int set_port(struct wg_device *wg, u16 port)
 {
 	struct wg_peer *peer;
+	int rett, retu;
+	
+	printk(KERN_INFO "Entering set_port: wg = %p, port = %u\n", wg, port);
 
 	if (wg->incoming_port == port)
 		return 0;
@@ -323,7 +626,18 @@ static int set_port(struct wg_device *wg, u16 port)
 		wg->incoming_port = port;
 		return 0;
 	}
-	return wg_socket_init(wg, port);
+
+	if (wg->transport == WG_TRANSPORT_TCP) {
+		/* Release the existing listening sockets and stop the associated threads */
+		wg_tcp_listener_socket_release(wg);
+		/* Reestablish the listening socket and associated threads */
+		rett = wg_tcp_listener_socket_init(wg, port);
+	} 
+        retu = wg_socket_init(wg, port);
+        /* Check if either rett or retu is negative and return an error code if so */
+//        if (rett < 0 || retu < 0)
+//                return -1;
+        return retu;	
 }
 
 static int set_allowedip(struct wg_peer *peer, struct nlattr **attrs)
@@ -332,6 +646,8 @@ static int set_allowedip(struct wg_peer *peer, struct nlattr **attrs)
 	u16 family;
 	u8 cidr;
 
+	printk(KERN_INFO "Entering set_allowedip: peer = %p, attrs = %p\n", peer, attrs);
+
 	if (!attrs[WGALLOWEDIP_A_FAMILY] || !attrs[WGALLOWEDIP_A_IPADDR] ||
 	    !attrs[WGALLOWEDIP_A_CIDR_MASK])
 		return ret;
@@ -340,16 +656,12 @@ static int set_allowedip(struct wg_peer *peer, struct nlattr **attrs)
 
 	if (family == AF_INET && cidr <= 32 &&
 	    nla_len(attrs[WGALLOWEDIP_A_IPADDR]) == sizeof(struct in_addr))
-		ret = wg_allowedips_insert_v4(
-			&peer->device->peer_allowedips,
-			nla_data(attrs[WGALLOWEDIP_A_IPADDR]), cidr, peer,
-			&peer->device->device_update_lock);
+		ret = wg_allowedips_insert_v4(&peer->device->peer_allowedips, nla_data(attrs[WGALLOWEDIP_A_IPADDR]), cidr, peer, &peer->device->device_update_lock);
 	else if (family == AF_INET6 && cidr <= 128 &&
 		 nla_len(attrs[WGALLOWEDIP_A_IPADDR]) == sizeof(struct in6_addr))
-		ret = wg_allowedips_insert_v6(
-			&peer->device->peer_allowedips,
-			nla_data(attrs[WGALLOWEDIP_A_IPADDR]), cidr, peer,
-			&peer->device->device_update_lock);
+		ret = wg_allowedips_insert_v6(&peer->device->peer_allowedips, nla_data(attrs[WGALLOWEDIP_A_IPADDR]), cidr, peer, &peer->device->device_update_lock);
+
+//	printk(KERN_INFO "Exiting set_allowedip\n");
 
 	return ret;
 }
@@ -361,6 +673,8 @@ static int set_peer(struct wg_device *wg, struct nlattr **attrs)
 	u32 flags = 0;
 	int ret;
 
+	printk(KERN_INFO "Entering set_peer: wg = %p, attrs = %p\n", wg, attrs);
+
 	ret = -EINVAL;
 	if (attrs[WGPEER_A_PUBLIC_KEY] &&
 	    nla_len(attrs[WGPEER_A_PUBLIC_KEY]) == NOISE_PUBLIC_KEY_LEN)
@@ -383,8 +697,7 @@ static int set_peer(struct wg_device *wg, struct nlattr **attrs)
 			goto out;
 	}
 
-	peer = wg_pubkey_hashtable_lookup(wg->peer_hashtable,
-					  nla_data(attrs[WGPEER_A_PUBLIC_KEY]));
+	peer = wg_pubkey_hashtable_lookup(wg->peer_hashtable, nla_data(attrs[WGPEER_A_PUBLIC_KEY]));
 	ret = 0;
 	if (!peer) { /* Peer doesn't exist yet. Add a new one. */
 		if (flags & (WGPEER_F_REMOVE_ME | WGPEER_F_UPDATE_ONLY))
@@ -395,9 +708,7 @@ static int set_peer(struct wg_device *wg, struct nlattr **attrs)
 
 		down_read(&wg->static_identity.lock);
 		if (wg->static_identity.has_identity &&
-		    !memcmp(nla_data(attrs[WGPEER_A_PUBLIC_KEY]),
-			    wg->static_identity.static_public,
-			    NOISE_PUBLIC_KEY_LEN)) {
+		    !memcmp(nla_data(attrs[WGPEER_A_PUBLIC_KEY]), wg->static_identity.static_public, NOISE_PUBLIC_KEY_LEN)) {
 			/* We silently ignore peers that have the same public
 			 * key as the device. The reason we do it silently is
 			 * that we'd like for people to be able to reuse the
@@ -428,8 +739,7 @@ static int set_peer(struct wg_device *wg, struct nlattr **attrs)
 
 	if (preshared_key) {
 		down_write(&peer->handshake.lock);
-		memcpy(&peer->handshake.preshared_key, preshared_key,
-		       NOISE_SYMMETRIC_KEY_LEN);
+		memcpy(&peer->handshake.preshared_key, preshared_key, NOISE_SYMMETRIC_KEY_LEN);
 		up_write(&peer->handshake.lock);
 	}
 
@@ -448,16 +758,14 @@ static int set_peer(struct wg_device *wg, struct nlattr **attrs)
 	}
 
 	if (flags & WGPEER_F_REPLACE_ALLOWEDIPS)
-		wg_allowedips_remove_by_peer(&wg->peer_allowedips, peer,
-					     &wg->device_update_lock);
+		wg_allowedips_remove_by_peer(&wg->peer_allowedips, peer, &wg->device_update_lock);
 
 	if (attrs[WGPEER_A_ALLOWEDIPS]) {
 		struct nlattr *attr, *allowedip[WGALLOWEDIP_A_MAX + 1];
 		int rem;
 
 		nla_for_each_nested(attr, attrs[WGPEER_A_ALLOWEDIPS], rem) {
-			ret = nla_parse_nested(allowedip, WGALLOWEDIP_A_MAX,
-					       attr, allowedip_policy, NULL);
+			ret = nla_parse_nested(allowedip, WGALLOWEDIP_A_MAX, attr, allowedip_policy, NULL);
 			if (ret < 0)
 				goto out;
 			ret = set_allowedip(peer, allowedip);
@@ -467,12 +775,8 @@ static int set_peer(struct wg_device *wg, struct nlattr **attrs)
 	}
 
 	if (attrs[WGPEER_A_PERSISTENT_KEEPALIVE_INTERVAL]) {
-		const u16 persistent_keepalive_interval = nla_get_u16(
-				attrs[WGPEER_A_PERSISTENT_KEEPALIVE_INTERVAL]);
-		const bool send_keepalive =
-			!peer->persistent_keepalive_interval &&
-			persistent_keepalive_interval &&
-			netif_running(wg->dev);
+		const u16 persistent_keepalive_interval = nla_get_u16(attrs[WGPEER_A_PERSISTENT_KEEPALIVE_INTERVAL]);
+		const bool send_keepalive = !peer->persistent_keepalive_interval && persistent_keepalive_interval && netif_running(wg->dev);
 
 		peer->persistent_keepalive_interval = persistent_keepalive_interval;
 		if (send_keepalive)
@@ -485,27 +789,40 @@ static int set_peer(struct wg_device *wg, struct nlattr **attrs)
 out:
 	wg_peer_put(peer);
 	if (attrs[WGPEER_A_PRESHARED_KEY])
-		memzero_explicit(nla_data(attrs[WGPEER_A_PRESHARED_KEY]),
-				 nla_len(attrs[WGPEER_A_PRESHARED_KEY]));
+		memzero_explicit(nla_data(attrs[WGPEER_A_PRESHARED_KEY]), nla_len(attrs[WGPEER_A_PRESHARED_KEY]));
+
+//	printk(KERN_INFO "Exiting set_peer\n");
+
 	return ret;
 }
 
 static int wg_set_device(struct sk_buff *skb, struct genl_info *info)
 {
-	struct wg_device *wg = lookup_interface(info->attrs, skb);
+	struct wg_device *wg;
 	u32 flags = 0;
 	int ret;
 
+	printk(KERN_INFO "Entering wg_set_device: skb = %p, info = %p\n", skb, info);
+
+#ifdef DIAGNOSTC	
+	// Decode and print the netlink message received
+	wg_print_netlink_buffer(skb, skb->len);
+#endif
+	
+	wg = lookup_interface(info->attrs, skb);
 	if (IS_ERR(wg)) {
 		ret = PTR_ERR(wg);
+		printk(KERN_INFO "Error in lookup_interface: %d\n", ret);
 		goto out_nodev;
 	}
 
 	rtnl_lock();
 	mutex_lock(&wg->device_update_lock);
 
-	if (info->attrs[WGDEVICE_A_FLAGS])
+	if (info->attrs[WGDEVICE_A_FLAGS]) {
 		flags = nla_get_u32(info->attrs[WGDEVICE_A_FLAGS]);
+//		printk(KERN_INFO "Parsed WGDEVICE_A_FLAGS: %u\n", flags);
+	}
 	ret = -EOPNOTSUPP;
 	if (flags & ~__WGDEVICE_F_ALL)
 		goto out;
@@ -516,48 +833,51 @@ static int wg_set_device(struct sk_buff *skb, struct genl_info *info)
 		net = rcu_dereference(wg->creating_net);
 		ret = !net || !ns_capable(net->user_ns, CAP_NET_ADMIN) ? -EPERM : 0;
 		rcu_read_unlock();
-		if (ret)
+		if (ret) {
+			printk(KERN_INFO "Permission error for NET_ADMIN capability: %d\n", ret);
 			goto out;
+		}
 	}
 
 	++wg->device_update_gen;
 
 	if (info->attrs[WGDEVICE_A_FWMARK]) {
 		struct wg_peer *peer;
-
 		wg->fwmark = nla_get_u32(info->attrs[WGDEVICE_A_FWMARK]);
+//		printk(KERN_INFO "Parsed WGDEVICE_A_FWMARK: %u\n", wg->fwmark);
 		list_for_each_entry(peer, &wg->peer_list, peer_list)
 			wg_socket_clear_peer_endpoint_src(peer);
 	}
 
 	if (info->attrs[WGDEVICE_A_LISTEN_PORT]) {
-		ret = set_port(wg,
-			nla_get_u16(info->attrs[WGDEVICE_A_LISTEN_PORT]));
+		ret = set_port(wg, nla_get_u16(info->attrs[WGDEVICE_A_LISTEN_PORT]));
+//		printk(KERN_INFO "Parsed WGDEVICE_A_LISTEN_PORT: %u, result: %d\n", nla_get_u16(info->attrs[WGDEVICE_A_LISTEN_PORT]), ret);
 		if (ret)
 			goto out;
 	}
 
-	if (flags & WGDEVICE_F_REPLACE_PEERS)
+	if (flags & WGDEVICE_F_REPLACE_PEERS) {
+//		printk(KERN_INFO "Replacing all peers\n");
 		wg_peer_remove_all(wg);
+	}
 
 	if (info->attrs[WGDEVICE_A_PRIVATE_KEY] &&
-	    nla_len(info->attrs[WGDEVICE_A_PRIVATE_KEY]) ==
-		    NOISE_PUBLIC_KEY_LEN) {
+	    nla_len(info->attrs[WGDEVICE_A_PRIVATE_KEY]) == NOISE_PUBLIC_KEY_LEN) {
 		u8 *private_key = nla_data(info->attrs[WGDEVICE_A_PRIVATE_KEY]);
 		u8 public_key[NOISE_PUBLIC_KEY_LEN];
 		struct wg_peer *peer, *temp;
 		bool send_staged_packets;
 
-		if (!crypto_memneq(wg->static_identity.static_private,
-				   private_key, NOISE_PUBLIC_KEY_LEN))
+//		printk(KERN_INFO "Parsed WGDEVICE_A_PRIVATE_KEY\n");
+
+		if (!crypto_memneq(wg->static_identity.static_private, private_key, NOISE_PUBLIC_KEY_LEN))
 			goto skip_set_private_key;
 
 		/* We remove before setting, to prevent race, which means doing
 		 * two 25519-genpub ops.
 		 */
 		if (curve25519_generate_public(public_key, private_key)) {
-			peer = wg_pubkey_hashtable_lookup(wg->peer_hashtable,
-							  public_key);
+			peer = wg_pubkey_hashtable_lookup(wg->peer_hashtable, public_key);
 			if (peer) {
 				wg_peer_put(peer);
 				wg_peer_remove(peer);
@@ -578,20 +898,32 @@ static int wg_set_device(struct sk_buff *skb, struct genl_info *info)
 		}
 		up_write(&wg->static_identity.lock);
 	}
-skip_set_private_key:
 
+	if (info->attrs[WGDEVICE_A_TRANSPORT]) {
+		u8 transport = nla_get_u8(info->attrs[WGDEVICE_A_TRANSPORT]);
+		wg->transport = transport;
+//		printk(KERN_INFO "Parsed WGDEVICE_A_TRANSPORT: %u\n", wg->transport);
+//		pr_debug("WireGuard: Setting device %p transport mode to %u\n", wg, transport);
+	}
+
+skip_set_private_key:
 	if (info->attrs[WGDEVICE_A_PEERS]) {
 		struct nlattr *attr, *peer[WGPEER_A_MAX + 1];
 		int rem;
 
+//		printk(KERN_INFO "Processing WGDEVICE_A_PEERS\n");
+
 		nla_for_each_nested(attr, info->attrs[WGDEVICE_A_PEERS], rem) {
-			ret = nla_parse_nested(peer, WGPEER_A_MAX, attr,
-					       peer_policy, NULL);
-			if (ret < 0)
+			ret = nla_parse_nested(peer, WGPEER_A_MAX, attr, peer_policy, NULL);
+			if (ret < 0) {
+				printk(KERN_INFO "Error parsing nested peer attributes: %d\n", ret);
 				goto out;
+			}
 			ret = set_peer(wg, peer);
-			if (ret < 0)
+			if (ret < 0) {
+				printk(KERN_INFO "Error setting peer: %d\n", ret);
 				goto out;
+			}
 		}
 	}
 	ret = 0;
@@ -602,8 +934,10 @@ static int wg_set_device(struct sk_buff *skb, struct genl_info *info)
 	dev_put(wg->dev);
 out_nodev:
 	if (info->attrs[WGDEVICE_A_PRIVATE_KEY])
-		memzero_explicit(nla_data(info->attrs[WGDEVICE_A_PRIVATE_KEY]),
-				 nla_len(info->attrs[WGDEVICE_A_PRIVATE_KEY]));
+		memzero_explicit(nla_data(info->attrs[WGDEVICE_A_PRIVATE_KEY]), nla_len(info->attrs[WGDEVICE_A_PRIVATE_KEY]));
+
+	printk(KERN_INFO "Exiting wg_set_device\n");
+
 	return ret;
 }
 
@@ -614,7 +948,8 @@ static const struct genl_ops genl_ops[] = {
 		.dumpit = wg_get_device_dump,
 		.done = wg_get_device_done,
 		.flags = GENL_UNS_ADMIN_PERM
-	}, {
+	},
+	{
 		.cmd = WG_CMD_SET_DEVICE,
 		.doit = wg_set_device,
 		.flags = GENL_UNS_ADMIN_PERM
@@ -635,10 +970,20 @@ static struct genl_family genl_family __ro_after_init = {
 
 int __init wg_genetlink_init(void)
 {
-	return genl_register_family(&genl_family);
+	printk(KERN_INFO "Entering wg_genetlink_init\n");
+
+	int ret = genl_register_family(&genl_family);
+
+	printk(KERN_INFO "Exiting wg_genetlink_init\n");
+
+	return ret;
 }
 
 void __exit wg_genetlink_uninit(void)
 {
+	printk(KERN_INFO "Entering wg_genetlink_uninit\n");
+
 	genl_unregister_family(&genl_family);
+
+	printk(KERN_INFO "Exiting wg_genetlink_uninit\n");
 }
diff --git a/wireguard-linux/drivers/net/wireguard/noise.c b/wireguard-linux/drivers/net/wireguard/noise.c
index ea3047b1b3e3..1d34ded5565a 100644
--- a/wireguard-linux/drivers/net/wireguard/noise.c
+++ b/wireguard-linux/drivers/net/wireguard/noise.c
@@ -17,6 +17,35 @@
 #include <linux/highmem.h>
 #include <crypto/utils.h>
 
+
+
+static void base64_encode(char *out, const u8 *in, size_t len)
+{
+    static const char base64_table[] =
+        "ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/";
+    static const int mod_table[] = {0, 2, 1};  // Used for padding calculations
+
+    size_t i, j;
+    for (i = 0, j = 0; i < len;) {
+        u32 octet_a = i < len ? in[i++] : 0;
+        u32 octet_b = i < len ? in[i++] : 0;
+        u32 octet_c = i < len ? in[i++] : 0;
+
+        u32 triple = (octet_a << 16) + (octet_b << 8) + octet_c;
+
+        out[j++] = base64_table[(triple >> 3 * 6) & 0x3F];
+        out[j++] = base64_table[(triple >> 2 * 6) & 0x3F];
+        out[j++] = base64_table[(triple >> 1 * 6) & 0x3F];
+        out[j++] = base64_table[(triple >> 0 * 6) & 0x3F];
+    }
+
+    // Handle padding
+    for (int k = 0; k < mod_table[len % 3]; k++)
+        out[j - 1 - k] = '=';
+    out[j] = '\0';  // Null-terminate the output string
+}
+
+
 /* This implements Noise_IKpsk2:
  *
  * <- s
@@ -33,308 +62,411 @@ static atomic64_t keypair_counter = ATOMIC64_INIT(0);
 
 void __init wg_noise_init(void)
 {
-	struct blake2s_state blake;
+    printk(KERN_INFO "Entering wg_noise_init\n");
 
-	blake2s(handshake_init_chaining_key, handshake_name, NULL,
-		NOISE_HASH_LEN, sizeof(handshake_name), 0);
-	blake2s_init(&blake, NOISE_HASH_LEN);
-	blake2s_update(&blake, handshake_init_chaining_key, NOISE_HASH_LEN);
-	blake2s_update(&blake, identifier_name, sizeof(identifier_name));
-	blake2s_final(&blake, handshake_init_hash);
+    struct blake2s_state blake;
+
+    blake2s(handshake_init_chaining_key, handshake_name, NULL,
+            NOISE_HASH_LEN, sizeof(handshake_name), 0);
+    blake2s_init(&blake, NOISE_HASH_LEN);
+    blake2s_update(&blake, handshake_init_chaining_key, NOISE_HASH_LEN);
+    blake2s_update(&blake, identifier_name, sizeof(identifier_name));
+    blake2s_final(&blake, handshake_init_hash);
+
+    printk(KERN_INFO "Exiting wg_noise_init\n");
 }
 
 /* Must hold peer->handshake.static_identity->lock */
 void wg_noise_precompute_static_static(struct wg_peer *peer)
 {
-	down_write(&peer->handshake.lock);
-	if (!peer->handshake.static_identity->has_identity ||
-	    !curve25519(peer->handshake.precomputed_static_static,
-			peer->handshake.static_identity->static_private,
-			peer->handshake.remote_static))
-		memset(peer->handshake.precomputed_static_static, 0,
-		       NOISE_PUBLIC_KEY_LEN);
-	up_write(&peer->handshake.lock);
+    printk(KERN_INFO "Entering wg_noise_precompute_static_static with peer: %p\n", peer);
+
+    down_write(&peer->handshake.lock);
+    if (!peer->handshake.static_identity->has_identity ||
+        !curve25519(peer->handshake.precomputed_static_static,
+                    peer->handshake.static_identity->static_private,
+                    peer->handshake.remote_static))
+        memset(peer->handshake.precomputed_static_static, 0,
+               NOISE_PUBLIC_KEY_LEN);
+    up_write(&peer->handshake.lock);
+
+    printk(KERN_INFO "Exiting wg_noise_precompute_static_static with peer: %p\n", peer);
 }
 
 void wg_noise_handshake_init(struct noise_handshake *handshake,
-			     struct noise_static_identity *static_identity,
-			     const u8 peer_public_key[NOISE_PUBLIC_KEY_LEN],
-			     const u8 peer_preshared_key[NOISE_SYMMETRIC_KEY_LEN],
-			     struct wg_peer *peer)
+                             struct noise_static_identity *static_identity,
+                             const u8 peer_public_key[NOISE_PUBLIC_KEY_LEN],
+                             const u8 peer_preshared_key[NOISE_SYMMETRIC_KEY_LEN],
+                             struct wg_peer *peer)
 {
+	printk(KERN_INFO "Entering wg_noise_handshake_init with handshake: %p, static_identity: %p, peer_public_key: %p, peer_preshared_key: %p, peer: %p\n",
+		handshake, static_identity, peer_public_key, peer_preshared_key, peer);
+
 	memset(handshake, 0, sizeof(*handshake));
 	init_rwsem(&handshake->lock);
 	handshake->entry.type = INDEX_HASHTABLE_HANDSHAKE;
 	handshake->entry.peer = peer;
 	memcpy(handshake->remote_static, peer_public_key, NOISE_PUBLIC_KEY_LEN);
 	if (peer_preshared_key)
-		memcpy(handshake->preshared_key, peer_preshared_key,
-		       NOISE_SYMMETRIC_KEY_LEN);
+        	memcpy(handshake->preshared_key, peer_preshared_key,
+        		NOISE_SYMMETRIC_KEY_LEN);
 	handshake->static_identity = static_identity;
 	handshake->state = HANDSHAKE_ZEROED;
 	wg_noise_precompute_static_static(peer);
+	
+	char b64_output[45];  // Base64 encoded output buffer for 32 bytes input
+	base64_encode(b64_output, handshake->static_identity->static_public, NOISE_PUBLIC_KEY_LEN);
+	printk(KERN_INFO "WG: Initiator's static public key (static_public) [Base64]: %s\n", b64_output);
+	printk(KERN_INFO "WG: Initiator's static public key (static_public) [Hex]: %*ph\n", NOISE_PUBLIC_KEY_LEN, handshake->static_identity->static_public);
+	base64_encode(b64_output, handshake->remote_static, NOISE_PUBLIC_KEY_LEN);
+	printk(KERN_INFO "WG: Responder's static public key (remote_static) [Base64]: %s\n", b64_output);
+	printk(KERN_INFO "WG: Responder's static public key (remote_static) [Hex]: %*ph\n", NOISE_PUBLIC_KEY_LEN, handshake->remote_static);
+	base64_encode(b64_output, handshake->ephemeral_private, NOISE_PUBLIC_KEY_LEN);
+	printk(KERN_INFO "WG: Initiator's ephemeral private key [Base64]: %s\n", b64_output);
+	printk(KERN_INFO "WG: Initiator's ephemeral private key (Hex): %*ph\n", NOISE_PUBLIC_KEY_LEN, handshake->ephemeral_private);
+
+	printk(KERN_INFO "Exiting wg_noise_handshake_init with handshake: %p, static_identity: %p, peer_public_key: %p, peer_preshared_key: %p, peer: %p\n",
+		handshake, static_identity, peer_public_key, peer_preshared_key, peer);
 }
 
 static void handshake_zero(struct noise_handshake *handshake)
 {
-	memset(&handshake->ephemeral_private, 0, NOISE_PUBLIC_KEY_LEN);
-	memset(&handshake->remote_ephemeral, 0, NOISE_PUBLIC_KEY_LEN);
-	memset(&handshake->hash, 0, NOISE_HASH_LEN);
-	memset(&handshake->chaining_key, 0, NOISE_HASH_LEN);
-	handshake->remote_index = 0;
-	handshake->state = HANDSHAKE_ZEROED;
+    printk(KERN_INFO "Entering handshake_zero with handshake: %p\n", handshake);
+
+    memset(&handshake->ephemeral_private, 0, NOISE_PUBLIC_KEY_LEN);
+    memset(&handshake->remote_ephemeral, 0, NOISE_PUBLIC_KEY_LEN);
+    memset(&handshake->hash, 0, NOISE_HASH_LEN);
+    memset(&handshake->chaining_key, 0, NOISE_HASH_LEN);
+    handshake->remote_index = 0;
+    handshake->state = HANDSHAKE_ZEROED;
+
+    printk(KERN_INFO "Exiting handshake_zero with handshake: %p\n", handshake);
 }
 
 void wg_noise_handshake_clear(struct noise_handshake *handshake)
 {
-	down_write(&handshake->lock);
-	wg_index_hashtable_remove(
-			handshake->entry.peer->device->index_hashtable,
-			&handshake->entry);
-	handshake_zero(handshake);
-	up_write(&handshake->lock);
+    printk(KERN_INFO "Entering wg_noise_handshake_clear with handshake: %p\n", handshake);
+
+    down_write(&handshake->lock);
+    wg_index_hashtable_remove(
+            handshake->entry.peer->device->index_hashtable,
+            &handshake->entry);
+    handshake_zero(handshake);
+    up_write(&handshake->lock);
+
+    printk(KERN_INFO "Exiting wg_noise_handshake_clear with handshake: %p\n", handshake);
 }
 
 static struct noise_keypair *keypair_create(struct wg_peer *peer)
 {
-	struct noise_keypair *keypair = kzalloc(sizeof(*keypair), GFP_KERNEL);
+    printk(KERN_INFO "Entering keypair_create with peer: %p\n", peer);
+
+    struct noise_keypair *keypair = kzalloc(sizeof(*keypair), GFP_KERNEL);
+
+    if (unlikely(!keypair))
+        return NULL;
+    spin_lock_init(&keypair->receiving_counter.lock);
+    keypair->internal_id = atomic64_inc_return(&keypair_counter);
+    keypair->entry.type = INDEX_HASHTABLE_KEYPAIR;
+    keypair->entry.peer = peer;
+    kref_init(&keypair->refcount);
+
+    printk(KERN_INFO "Exiting keypair_create with peer: %p, keypair: %p\n", peer, keypair);
 
-	if (unlikely(!keypair))
-		return NULL;
-	spin_lock_init(&keypair->receiving_counter.lock);
-	keypair->internal_id = atomic64_inc_return(&keypair_counter);
-	keypair->entry.type = INDEX_HASHTABLE_KEYPAIR;
-	keypair->entry.peer = peer;
-	kref_init(&keypair->refcount);
-	return keypair;
+    return keypair;
 }
 
 static void keypair_free_rcu(struct rcu_head *rcu)
 {
-	kfree_sensitive(container_of(rcu, struct noise_keypair, rcu));
+    printk(KERN_INFO "Entering keypair_free_rcu with rcu: %p\n", rcu);
+
+    kfree_sensitive(container_of(rcu, struct noise_keypair, rcu));
+
+    printk(KERN_INFO "Exiting keypair_free_rcu with rcu: %p\n", rcu);
 }
 
 static void keypair_free_kref(struct kref *kref)
 {
-	struct noise_keypair *keypair =
-		container_of(kref, struct noise_keypair, refcount);
+    printk(KERN_INFO "Entering keypair_free_kref with kref: %p\n", kref);
+
+    struct noise_keypair *keypair =
+        container_of(kref, struct noise_keypair, refcount);
 
-	net_dbg_ratelimited("%s: Keypair %llu destroyed for peer %llu\n",
-			    keypair->entry.peer->device->dev->name,
-			    keypair->internal_id,
-			    keypair->entry.peer->internal_id);
-	wg_index_hashtable_remove(keypair->entry.peer->device->index_hashtable,
-				  &keypair->entry);
-	call_rcu(&keypair->rcu, keypair_free_rcu);
+    net_dbg_ratelimited("%s: Keypair %llu destroyed for peer %llu\n",
+                        keypair->entry.peer->device->dev->name,
+                        keypair->internal_id,
+                        keypair->entry.peer->internal_id);
+    wg_index_hashtable_remove(keypair->entry.peer->device->index_hashtable,
+                              &keypair->entry);
+    call_rcu(&keypair->rcu, keypair_free_rcu);
+
+    printk(KERN_INFO "Exiting keypair_free_kref with kref: %p, keypair: %p\n", kref, keypair);
 }
 
 void wg_noise_keypair_put(struct noise_keypair *keypair, bool unreference_now)
 {
-	if (unlikely(!keypair))
-		return;
-	if (unlikely(unreference_now))
-		wg_index_hashtable_remove(
-			keypair->entry.peer->device->index_hashtable,
-			&keypair->entry);
-	kref_put(&keypair->refcount, keypair_free_kref);
+    printk(KERN_INFO "Entering wg_noise_keypair_put with keypair: %p, unreference_now: %d\n", keypair, unreference_now);
+
+    if (unlikely(!keypair)) {
+        printk(KERN_ERR "wg_noise_keypair_put: keypair is NULL\n");
+        return;
+    }
+
+    printk(KERN_INFO "wg_noise_keypair_put: Keypair internal_id: %llu, refcount: %d\n",
+           keypair->internal_id, kref_read(&keypair->refcount));
+
+    if (unlikely(unreference_now)) {
+        if (keypair->entry.peer) {
+            if (keypair->entry.peer->device) {
+                if (keypair->entry.peer->device->index_hashtable) {
+                    printk(KERN_INFO "wg_noise_keypair_put: Removing keypair %p from index hashtable\n", keypair);
+                    wg_index_hashtable_remove(
+                        keypair->entry.peer->device->index_hashtable,
+                        &keypair->entry);
+                } else {
+                    printk(KERN_ERR "wg_noise_keypair_put: index_hashtable is NULL\n");
+                }
+            } else {
+                printk(KERN_ERR "wg_noise_keypair_put: device is NULL\n");
+            }
+        } else {
+            printk(KERN_ERR "wg_noise_keypair_put: peer is NULL\n");
+        }
+    }
+
+    kref_put(&keypair->refcount, keypair_free_kref);
+    printk(KERN_INFO "Exiting wg_noise_keypair_put for keypair: %p\n", keypair);
 }
 
 struct noise_keypair *wg_noise_keypair_get(struct noise_keypair *keypair)
 {
-	RCU_LOCKDEP_WARN(!rcu_read_lock_bh_held(),
-		"Taking noise keypair reference without holding the RCU BH read lock");
-	if (unlikely(!keypair || !kref_get_unless_zero(&keypair->refcount)))
-		return NULL;
-	return keypair;
+    printk(KERN_INFO "Entering wg_noise_keypair_get with keypair: %p\n", keypair);
+
+    RCU_LOCKDEP_WARN(!rcu_read_lock_bh_held(),
+                     "Taking noise keypair reference without holding the RCU BH read lock");
+    if (unlikely(!keypair || !kref_get_unless_zero(&keypair->refcount)))
+        return NULL;
+
+    printk(KERN_INFO "Exiting wg_noise_keypair_get with keypair: %p\n", keypair);
+
+    return keypair;
 }
 
 void wg_noise_keypairs_clear(struct noise_keypairs *keypairs)
 {
-	struct noise_keypair *old;
+    printk(KERN_INFO "Entering wg_noise_keypairs_clear with keypairs: %p\n", keypairs);
+
+    struct noise_keypair *old;
 
-	spin_lock_bh(&keypairs->keypair_update_lock);
+    spin_lock_bh(&keypairs->keypair_update_lock);
 
-	/* We zero the next_keypair before zeroing the others, so that
-	 * wg_noise_received_with_keypair returns early before subsequent ones
-	 * are zeroed.
-	 */
-	old = rcu_dereference_protected(keypairs->next_keypair,
-		lockdep_is_held(&keypairs->keypair_update_lock));
-	RCU_INIT_POINTER(keypairs->next_keypair, NULL);
-	wg_noise_keypair_put(old, true);
+    /* We zero the next_keypair before zeroing the others, so that
+     * wg_noise_received_with_keypair returns early before subsequent ones
+     * are zeroed.
+     */
+    old = rcu_dereference_protected(keypairs->next_keypair,
+                                    lockdep_is_held(&keypairs->keypair_update_lock));
+    RCU_INIT_POINTER(keypairs->next_keypair, NULL);
+    wg_noise_keypair_put(old, true);
 
-	old = rcu_dereference_protected(keypairs->previous_keypair,
-		lockdep_is_held(&keypairs->keypair_update_lock));
-	RCU_INIT_POINTER(keypairs->previous_keypair, NULL);
-	wg_noise_keypair_put(old, true);
+    old = rcu_dereference_protected(keypairs->previous_keypair,
+                                    lockdep_is_held(&keypairs->keypair_update_lock));
+    RCU_INIT_POINTER(keypairs->previous_keypair, NULL);
+    wg_noise_keypair_put(old, true);
 
-	old = rcu_dereference_protected(keypairs->current_keypair,
-		lockdep_is_held(&keypairs->keypair_update_lock));
-	RCU_INIT_POINTER(keypairs->current_keypair, NULL);
-	wg_noise_keypair_put(old, true);
+    old = rcu_dereference_protected(keypairs->current_keypair,
+                                    lockdep_is_held(&keypairs->keypair_update_lock));
+    RCU_INIT_POINTER(keypairs->current_keypair, NULL);
+    wg_noise_keypair_put(old, true);
 
-	spin_unlock_bh(&keypairs->keypair_update_lock);
+    spin_unlock_bh(&keypairs->keypair_update_lock);
+
+    printk(KERN_INFO "Exiting wg_noise_keypairs_clear with keypairs: %p\n", keypairs);
 }
 
 void wg_noise_expire_current_peer_keypairs(struct wg_peer *peer)
 {
-	struct noise_keypair *keypair;
+    printk(KERN_INFO "Entering wg_noise_expire_current_peer_keypairs with peer: %p\n", peer);
+
+    struct noise_keypair *keypair;
+
+    wg_noise_handshake_clear(&peer->handshake);
+    wg_noise_reset_last_sent_handshake(&peer->last_sent_handshake);
 
-	wg_noise_handshake_clear(&peer->handshake);
-	wg_noise_reset_last_sent_handshake(&peer->last_sent_handshake);
+    spin_lock_bh(&peer->keypairs.keypair_update_lock);
+    keypair = rcu_dereference_protected(peer->keypairs.next_keypair,
+                                        lockdep_is_held(&peer->keypairs.keypair_update_lock));
+    if (keypair)
+        keypair->sending.is_valid = false;
+    keypair = rcu_dereference_protected(peer->keypairs.current_keypair,
+                                        lockdep_is_held(&peer->keypairs.keypair_update_lock));
+    if (keypair)
+        keypair->sending.is_valid = false;
+    spin_unlock_bh(&peer->keypairs.keypair_update_lock);
 
-	spin_lock_bh(&peer->keypairs.keypair_update_lock);
-	keypair = rcu_dereference_protected(peer->keypairs.next_keypair,
-			lockdep_is_held(&peer->keypairs.keypair_update_lock));
-	if (keypair)
-		keypair->sending.is_valid = false;
-	keypair = rcu_dereference_protected(peer->keypairs.current_keypair,
-			lockdep_is_held(&peer->keypairs.keypair_update_lock));
-	if (keypair)
-		keypair->sending.is_valid = false;
-	spin_unlock_bh(&peer->keypairs.keypair_update_lock);
+    printk(KERN_INFO "Exiting wg_noise_expire_current_peer_keypairs with peer: %p\n", peer);
 }
 
 static void add_new_keypair(struct noise_keypairs *keypairs,
-			    struct noise_keypair *new_keypair)
-{
-	struct noise_keypair *previous_keypair, *next_keypair, *current_keypair;
-
-	spin_lock_bh(&keypairs->keypair_update_lock);
-	previous_keypair = rcu_dereference_protected(keypairs->previous_keypair,
-		lockdep_is_held(&keypairs->keypair_update_lock));
-	next_keypair = rcu_dereference_protected(keypairs->next_keypair,
-		lockdep_is_held(&keypairs->keypair_update_lock));
-	current_keypair = rcu_dereference_protected(keypairs->current_keypair,
-		lockdep_is_held(&keypairs->keypair_update_lock));
-	if (new_keypair->i_am_the_initiator) {
-		/* If we're the initiator, it means we've sent a handshake, and
-		 * received a confirmation response, which means this new
-		 * keypair can now be used.
-		 */
-		if (next_keypair) {
-			/* If there already was a next keypair pending, we
-			 * demote it to be the previous keypair, and free the
-			 * existing current. Note that this means KCI can result
-			 * in this transition. It would perhaps be more sound to
-			 * always just get rid of the unused next keypair
-			 * instead of putting it in the previous slot, but this
-			 * might be a bit less robust. Something to think about
-			 * for the future.
-			 */
-			RCU_INIT_POINTER(keypairs->next_keypair, NULL);
-			rcu_assign_pointer(keypairs->previous_keypair,
-					   next_keypair);
-			wg_noise_keypair_put(current_keypair, true);
-		} else /* If there wasn't an existing next keypair, we replace
-			* the previous with the current one.
-			*/
-			rcu_assign_pointer(keypairs->previous_keypair,
-					   current_keypair);
-		/* At this point we can get rid of the old previous keypair, and
-		 * set up the new keypair.
-		 */
-		wg_noise_keypair_put(previous_keypair, true);
-		rcu_assign_pointer(keypairs->current_keypair, new_keypair);
-	} else {
-		/* If we're the responder, it means we can't use the new keypair
-		 * until we receive confirmation via the first data packet, so
-		 * we get rid of the existing previous one, the possibly
-		 * existing next one, and slide in the new next one.
-		 */
-		rcu_assign_pointer(keypairs->next_keypair, new_keypair);
-		wg_noise_keypair_put(next_keypair, true);
-		RCU_INIT_POINTER(keypairs->previous_keypair, NULL);
-		wg_noise_keypair_put(previous_keypair, true);
-	}
-	spin_unlock_bh(&keypairs->keypair_update_lock);
+                            struct noise_keypair *new_keypair)
+{
+    printk(KERN_INFO "Entering add_new_keypair with keypairs: %p, new_keypair: %p\n", keypairs, new_keypair);
+
+    struct noise_keypair *previous_keypair, *next_keypair, *current_keypair;
+
+    spin_lock_bh(&keypairs->keypair_update_lock);
+    previous_keypair = rcu_dereference_protected(keypairs->previous_keypair,
+                                                 lockdep_is_held(&keypairs->keypair_update_lock));
+    next_keypair = rcu_dereference_protected(keypairs->next_keypair,
+                                             lockdep_is_held(&keypairs->keypair_update_lock));
+    current_keypair = rcu_dereference_protected(keypairs->current_keypair,
+                                                lockdep_is_held(&keypairs->keypair_update_lock));
+    if (new_keypair->i_am_the_initiator) {
+        /* If we're the initiator, it means we've sent a handshake, and
+         * received a confirmation response, which means this new
+         * keypair can now be used.
+         */
+        if (next_keypair) {
+            /* If there already was a next keypair pending, we
+             * demote it to be the previous keypair, and free the
+             * existing current. Note that this means KCI can result
+             * in this transition. It would perhaps be more sound to
+             * always just get rid of the unused next keypair
+             * instead of putting it in the previous slot, but this
+             * might be a bit less robust. Something to think about
+             * for the future.
+             */
+            RCU_INIT_POINTER(keypairs->next_keypair, NULL);
+            rcu_assign_pointer(keypairs->previous_keypair,
+                               next_keypair);
+            wg_noise_keypair_put(current_keypair, true);
+        } else /* If there wasn't an existing next keypair, we replace
+               * the previous with the current one.
+               */
+            rcu_assign_pointer(keypairs->previous_keypair,
+                               current_keypair);
+        /* At this point we can get rid of the old previous keypair, and
+         * set up the new keypair.
+         */
+        wg_noise_keypair_put(previous_keypair, true);
+        rcu_assign_pointer(keypairs->current_keypair, new_keypair);
+    } else {
+        /* If we're the responder, it means we can't use the new keypair
+         * until we receive confirmation via the first data packet, so
+         * we get rid of the existing previous one, the possibly
+         * existing next one, and slide in the new next one.
+         */
+        rcu_assign_pointer(keypairs->next_keypair, new_keypair);
+        wg_noise_keypair_put(next_keypair, true);
+        RCU_INIT_POINTER(keypairs->previous_keypair, NULL);
+        wg_noise_keypair_put(previous_keypair, true);
+    }
+    spin_unlock_bh(&keypairs->keypair_update_lock);
+
+    printk(KERN_INFO "Exiting add_new_keypair with keypairs: %p, new_keypair: %p\n", keypairs, new_keypair);
 }
 
 bool wg_noise_received_with_keypair(struct noise_keypairs *keypairs,
-				    struct noise_keypair *received_keypair)
-{
-	struct noise_keypair *old_keypair;
-	bool key_is_new;
-
-	/* We first check without taking the spinlock. */
-	key_is_new = received_keypair ==
-		     rcu_access_pointer(keypairs->next_keypair);
-	if (likely(!key_is_new))
-		return false;
-
-	spin_lock_bh(&keypairs->keypair_update_lock);
-	/* After locking, we double check that things didn't change from
-	 * beneath us.
-	 */
-	if (unlikely(received_keypair !=
-		    rcu_dereference_protected(keypairs->next_keypair,
-			    lockdep_is_held(&keypairs->keypair_update_lock)))) {
-		spin_unlock_bh(&keypairs->keypair_update_lock);
-		return false;
-	}
-
-	/* When we've finally received the confirmation, we slide the next
-	 * into the current, the current into the previous, and get rid of
-	 * the old previous.
-	 */
-	old_keypair = rcu_dereference_protected(keypairs->previous_keypair,
-		lockdep_is_held(&keypairs->keypair_update_lock));
-	rcu_assign_pointer(keypairs->previous_keypair,
-		rcu_dereference_protected(keypairs->current_keypair,
-			lockdep_is_held(&keypairs->keypair_update_lock)));
-	wg_noise_keypair_put(old_keypair, true);
-	rcu_assign_pointer(keypairs->current_keypair, received_keypair);
-	RCU_INIT_POINTER(keypairs->next_keypair, NULL);
-
-	spin_unlock_bh(&keypairs->keypair_update_lock);
-	return true;
+                                    struct noise_keypair *received_keypair)
+{
+    printk(KERN_INFO "Entering wg_noise_received_with_keypair with keypairs: %p, received_keypair: %p\n", keypairs, received_keypair);
+
+    struct noise_keypair *old_keypair;
+    bool key_is_new;
+
+    /* We first check without taking the spinlock. */
+    key_is_new = received_keypair ==
+                 rcu_access_pointer(keypairs->next_keypair);
+    if (likely(!key_is_new)) {
+        printk(KERN_INFO "Exiting wg_noise_received_with_keypair with keypairs: %p, received_keypair: %p, result: false\n", keypairs, received_keypair);
+        return false;
+    }
+
+    spin_lock_bh(&keypairs->keypair_update_lock);
+    /* After locking, we double check that things didn't change from
+     * beneath us.
+     */
+    if (unlikely(received_keypair !=
+                 rcu_dereference_protected(keypairs->next_keypair,
+                                           lockdep_is_held(&keypairs->keypair_update_lock)))) {
+        spin_unlock_bh(&keypairs->keypair_update_lock);
+        printk(KERN_INFO "Exiting wg_noise_received_with_keypair with keypairs: %p, received_keypair: %p, result: false\n", keypairs, received_keypair);
+        return false;
+    }
+
+    /* When we've finally received the confirmation, we slide the next
+     * into the current, the current into the previous, and get rid of
+     * the old previous.
+     */
+    old_keypair = rcu_dereference_protected(keypairs->previous_keypair,
+                                            lockdep_is_held(&keypairs->keypair_update_lock));
+    rcu_assign_pointer(keypairs->previous_keypair,
+                       rcu_dereference_protected(keypairs->current_keypair,
+                                                 lockdep_is_held(&keypairs->keypair_update_lock)));
+    wg_noise_keypair_put(old_keypair, true);
+    rcu_assign_pointer(keypairs->current_keypair, received_keypair);
+    RCU_INIT_POINTER(keypairs->next_keypair, NULL);
+
+    spin_unlock_bh(&keypairs->keypair_update_lock);
+
+    printk(KERN_INFO "Exiting wg_noise_received_with_keypair with keypairs: %p, received_keypair: %p, result: true\n", keypairs, received_keypair);
+
+    return true;
 }
 
 /* Must hold static_identity->lock */
 void wg_noise_set_static_identity_private_key(
-	struct noise_static_identity *static_identity,
-	const u8 private_key[NOISE_PUBLIC_KEY_LEN])
+    struct noise_static_identity *static_identity,
+    const u8 private_key[NOISE_PUBLIC_KEY_LEN])
 {
-	memcpy(static_identity->static_private, private_key,
-	       NOISE_PUBLIC_KEY_LEN);
-	curve25519_clamp_secret(static_identity->static_private);
-	static_identity->has_identity = curve25519_generate_public(
-		static_identity->static_public, private_key);
+    printk(KERN_INFO "Entering wg_noise_set_static_identity_private_key with static_identity: %p, private_key: %p\n", static_identity, private_key);
+
+    memcpy(static_identity->static_private, private_key,
+           NOISE_PUBLIC_KEY_LEN);
+    curve25519_clamp_secret(static_identity->static_private);
+    static_identity->has_identity = curve25519_generate_public(
+        static_identity->static_public, private_key);
+
+    printk(KERN_INFO "Exiting wg_noise_set_static_identity_private_key with static_identity: %p, private_key: %p\n", static_identity, private_key);
 }
 
 static void hmac(u8 *out, const u8 *in, const u8 *key, const size_t inlen, const size_t keylen)
 {
-	struct blake2s_state state;
-	u8 x_key[BLAKE2S_BLOCK_SIZE] __aligned(__alignof__(u32)) = { 0 };
-	u8 i_hash[BLAKE2S_HASH_SIZE] __aligned(__alignof__(u32));
-	int i;
+    printk(KERN_INFO "Entering hmac with out: %p, in: %p, key: %p, inlen: %zu, keylen: %zu\n", out, in, key, inlen, keylen);
+
+    struct blake2s_state state;
+    u8 x_key[BLAKE2S_BLOCK_SIZE] __aligned(__alignof__(u32)) = { 0 };
+    u8 i_hash[BLAKE2S_HASH_SIZE] __aligned(__alignof__(u32));
+    int i;
 
-	if (keylen > BLAKE2S_BLOCK_SIZE) {
-		blake2s_init(&state, BLAKE2S_HASH_SIZE);
-		blake2s_update(&state, key, keylen);
-		blake2s_final(&state, x_key);
-	} else
-		memcpy(x_key, key, keylen);
+    if (keylen > BLAKE2S_BLOCK_SIZE) {
+        blake2s_init(&state, BLAKE2S_HASH_SIZE);
+        blake2s_update(&state, key, keylen);
+        blake2s_final(&state, x_key);
+    } else
+        memcpy(x_key, key, keylen);
 
-	for (i = 0; i < BLAKE2S_BLOCK_SIZE; ++i)
-		x_key[i] ^= 0x36;
+    for (i = 0; i < BLAKE2S_BLOCK_SIZE; ++i)
+        x_key[i] ^= 0x36;
 
-	blake2s_init(&state, BLAKE2S_HASH_SIZE);
-	blake2s_update(&state, x_key, BLAKE2S_BLOCK_SIZE);
-	blake2s_update(&state, in, inlen);
-	blake2s_final(&state, i_hash);
+    blake2s_init(&state, BLAKE2S_HASH_SIZE);
+    blake2s_update(&state, x_key, BLAKE2S_BLOCK_SIZE);
+    blake2s_update(&state, in, inlen);
+    blake2s_final(&state, i_hash);
 
-	for (i = 0; i < BLAKE2S_BLOCK_SIZE; ++i)
-		x_key[i] ^= 0x5c ^ 0x36;
+    for (i = 0; i < BLAKE2S_BLOCK_SIZE; ++i)
+        x_key[i] ^= 0x5c ^ 0x36;
 
-	blake2s_init(&state, BLAKE2S_HASH_SIZE);
-	blake2s_update(&state, x_key, BLAKE2S_BLOCK_SIZE);
-	blake2s_update(&state, i_hash, BLAKE2S_HASH_SIZE);
-	blake2s_final(&state, i_hash);
+    blake2s_init(&state, BLAKE2S_HASH_SIZE);
+    blake2s_update(&state, x_key, BLAKE2S_BLOCK_SIZE);
+    blake2s_update(&state, i_hash, BLAKE2S_HASH_SIZE);
+    blake2s_final(&state, i_hash);
 
-	memcpy(out, i_hash, BLAKE2S_HASH_SIZE);
-	memzero_explicit(x_key, BLAKE2S_BLOCK_SIZE);
-	memzero_explicit(i_hash, BLAKE2S_HASH_SIZE);
+    memcpy(out, i_hash, BLAKE2S_HASH_SIZE);
+    memzero_explicit(x_key, BLAKE2S_BLOCK_SIZE);
+    memzero_explicit(i_hash, BLAKE2S_HASH_SIZE);
+
+    printk(KERN_INFO "Exiting hmac with out: %p, in: %p, key: %p, inlen: %zu, keylen: %zu\n", out, in, key, inlen, keylen);
 }
 
 /* This is Hugo Krawczyk's HKDF:
@@ -342,521 +474,791 @@ static void hmac(u8 *out, const u8 *in, const u8 *key, const size_t inlen, const
  *  - https://tools.ietf.org/html/rfc5869
  */
 static void kdf(u8 *first_dst, u8 *second_dst, u8 *third_dst, const u8 *data,
-		size_t first_len, size_t second_len, size_t third_len,
-		size_t data_len, const u8 chaining_key[NOISE_HASH_LEN])
+                size_t first_len, size_t second_len, size_t third_len,
+                size_t data_len, const u8 chaining_key[NOISE_HASH_LEN])
 {
-	u8 output[BLAKE2S_HASH_SIZE + 1];
-	u8 secret[BLAKE2S_HASH_SIZE];
+    printk(KERN_INFO "Entering kdf with first_dst: %p, second_dst: %p, third_dst: %p, data: %p, first_len: %zu, second_len: %zu, third_len: %zu, data_len: %zu, chaining_key: %p\n",
+           first_dst, second_dst, third_dst, data, first_len, second_len, third_len, data_len, chaining_key);
+
+    u8 output[BLAKE2S_HASH_SIZE + 1];
+    u8 secret[BLAKE2S_HASH_SIZE];
 
-	WARN_ON(IS_ENABLED(DEBUG) &&
-		(first_len > BLAKE2S_HASH_SIZE ||
-		 second_len > BLAKE2S_HASH_SIZE ||
-		 third_len > BLAKE2S_HASH_SIZE ||
-		 ((second_len || second_dst || third_len || third_dst) &&
-		  (!first_len || !first_dst)) ||
-		 ((third_len || third_dst) && (!second_len || !second_dst))));
+    WARN_ON(IS_ENABLED(DEBUG) &&
+            (first_len > BLAKE2S_HASH_SIZE ||
+             second_len > BLAKE2S_HASH_SIZE ||
+             third_len > BLAKE2S_HASH_SIZE ||
+             ((second_len || second_dst || third_len || third_dst) &&
+              (!first_len || !first_dst)) ||
+             ((third_len || third_dst) && (!second_len || !second_dst))));
 
-	/* Extract entropy from data into secret */
-	hmac(secret, data, chaining_key, data_len, NOISE_HASH_LEN);
+    /* Extract entropy from data into secret */
+    hmac(secret, data, chaining_key, data_len, NOISE_HASH_LEN);
 
-	if (!first_dst || !first_len)
-		goto out;
+    if (!first_dst || !first_len)
+        goto out;
 
-	/* Expand first key: key = secret, data = 0x1 */
-	output[0] = 1;
-	hmac(output, output, secret, 1, BLAKE2S_HASH_SIZE);
-	memcpy(first_dst, output, first_len);
+    /* Expand first key: key = secret, data = 0x1 */
+    output[0] = 1;
+    hmac(output, output, secret, 1, BLAKE2S_HASH_SIZE);
+    memcpy(first_dst, output, first_len);
 
-	if (!second_dst || !second_len)
-		goto out;
+    if (!second_dst || !second_len)
+        goto out;
 
-	/* Expand second key: key = secret, data = first-key || 0x2 */
-	output[BLAKE2S_HASH_SIZE] = 2;
-	hmac(output, output, secret, BLAKE2S_HASH_SIZE + 1, BLAKE2S_HASH_SIZE);
-	memcpy(second_dst, output, second_len);
+    /* Expand second key: key = secret, data = first-key || 0x2 */
+    output[BLAKE2S_HASH_SIZE] = 2;
+    hmac(output, output, secret, BLAKE2S_HASH_SIZE + 1, BLAKE2S_HASH_SIZE);
+    memcpy(second_dst, output, second_len);
 
-	if (!third_dst || !third_len)
-		goto out;
+    if (!third_dst || !third_len)
+        goto out;
 
-	/* Expand third key: key = secret, data = second-key || 0x3 */
-	output[BLAKE2S_HASH_SIZE] = 3;
-	hmac(output, output, secret, BLAKE2S_HASH_SIZE + 1, BLAKE2S_HASH_SIZE);
-	memcpy(third_dst, output, third_len);
+    /* Expand third key: key = secret, data = second-key || 0x3 */
+    output[BLAKE2S_HASH_SIZE] = 3;
+    hmac(output, output, secret, BLAKE2S_HASH_SIZE + 1, BLAKE2S_HASH_SIZE);
+    memcpy(third_dst, output, third_len);
 
 out:
-	/* Clear sensitive data from stack */
-	memzero_explicit(secret, BLAKE2S_HASH_SIZE);
-	memzero_explicit(output, BLAKE2S_HASH_SIZE + 1);
+    /* Clear sensitive data from stack */
+    memzero_explicit(secret, BLAKE2S_HASH_SIZE);
+    memzero_explicit(output, BLAKE2S_HASH_SIZE + 1);
+
+    printk(KERN_INFO "Exiting kdf with first_dst: %p, second_dst: %p, third_dst: %p, data: %p, first_len: %zu, second_len: %zu, third_len: %zu, data_len: %zu, chaining_key: %p\n",
+           first_dst, second_dst, third_dst, data, first_len, second_len, third_len, data_len, chaining_key);
 }
 
 static void derive_keys(struct noise_symmetric_key *first_dst,
-			struct noise_symmetric_key *second_dst,
-			const u8 chaining_key[NOISE_HASH_LEN])
+                        struct noise_symmetric_key *second_dst,
+                        const u8 chaining_key[NOISE_HASH_LEN])
 {
-	u64 birthdate = ktime_get_coarse_boottime_ns();
-	kdf(first_dst->key, second_dst->key, NULL, NULL,
-	    NOISE_SYMMETRIC_KEY_LEN, NOISE_SYMMETRIC_KEY_LEN, 0, 0,
-	    chaining_key);
-	first_dst->birthdate = second_dst->birthdate = birthdate;
-	first_dst->is_valid = second_dst->is_valid = true;
+    printk(KERN_INFO "Entering derive_keys with first_dst: %p, second_dst: %p, chaining_key: %p\n", first_dst, second_dst, chaining_key);
+
+    u64 birthdate = ktime_get_coarse_boottime_ns();
+    kdf(first_dst->key, second_dst->key, NULL, NULL,
+        NOISE_SYMMETRIC_KEY_LEN, NOISE_SYMMETRIC_KEY_LEN, 0, 0,
+        chaining_key);
+    first_dst->birthdate = second_dst->birthdate = birthdate;
+    first_dst->is_valid = second_dst->is_valid = true;
+
+    printk(KERN_INFO "Exiting derive_keys with first_dst: %p, second_dst: %p, chaining_key: %p\n", first_dst, second_dst, chaining_key);
 }
 
 static bool __must_check mix_dh(u8 chaining_key[NOISE_HASH_LEN],
-				u8 key[NOISE_SYMMETRIC_KEY_LEN],
-				const u8 private[NOISE_PUBLIC_KEY_LEN],
-				const u8 public[NOISE_PUBLIC_KEY_LEN])
+                                u8 key[NOISE_SYMMETRIC_KEY_LEN],
+                                const u8 private[NOISE_PUBLIC_KEY_LEN],
+                                const u8 public[NOISE_PUBLIC_KEY_LEN])
 {
-	u8 dh_calculation[NOISE_PUBLIC_KEY_LEN];
+    printk(KERN_INFO "Entering mix_dh with chaining_key: %p, key: %p, private: %p, public: %p\n", chaining_key, key, private, public);
+
+    u8 dh_calculation[NOISE_PUBLIC_KEY_LEN];
 
-	if (unlikely(!curve25519(dh_calculation, private, public)))
-		return false;
-	kdf(chaining_key, key, NULL, dh_calculation, NOISE_HASH_LEN,
-	    NOISE_SYMMETRIC_KEY_LEN, 0, NOISE_PUBLIC_KEY_LEN, chaining_key);
-	memzero_explicit(dh_calculation, NOISE_PUBLIC_KEY_LEN);
-	return true;
+    if (unlikely(!curve25519(dh_calculation, private, public)))
+        return false;
+    kdf(chaining_key, key, NULL, dh_calculation, NOISE_HASH_LEN,
+        NOISE_SYMMETRIC_KEY_LEN, 0, NOISE_PUBLIC_KEY_LEN, chaining_key);
+    memzero_explicit(dh_calculation, NOISE_PUBLIC_KEY_LEN);
+
+    printk(KERN_INFO "Exiting mix_dh with chaining_key: %p, key: %p, private: %p, public: %p, result: true\n", chaining_key, key, private, public);
+
+    return true;
 }
 
 static bool __must_check mix_precomputed_dh(u8 chaining_key[NOISE_HASH_LEN],
-					    u8 key[NOISE_SYMMETRIC_KEY_LEN],
-					    const u8 precomputed[NOISE_PUBLIC_KEY_LEN])
+                                            u8 key[NOISE_SYMMETRIC_KEY_LEN],
+                                            const u8 precomputed[NOISE_PUBLIC_KEY_LEN])
 {
-	static u8 zero_point[NOISE_PUBLIC_KEY_LEN];
-	if (unlikely(!crypto_memneq(precomputed, zero_point, NOISE_PUBLIC_KEY_LEN)))
-		return false;
-	kdf(chaining_key, key, NULL, precomputed, NOISE_HASH_LEN,
-	    NOISE_SYMMETRIC_KEY_LEN, 0, NOISE_PUBLIC_KEY_LEN,
-	    chaining_key);
-	return true;
+    printk(KERN_INFO "Entering mix_precomputed_dh with chaining_key: %p, key: %p, precomputed: %p\n", chaining_key, key, precomputed);
+
+    static u8 zero_point[NOISE_PUBLIC_KEY_LEN];
+    if (unlikely(!crypto_memneq(precomputed, zero_point, NOISE_PUBLIC_KEY_LEN)))
+        return false;
+    kdf(chaining_key, key, NULL, precomputed, NOISE_HASH_LEN,
+        NOISE_SYMMETRIC_KEY_LEN, 0, NOISE_PUBLIC_KEY_LEN,
+        chaining_key);
+
+    printk(KERN_INFO "Exiting mix_precomputed_dh with chaining_key: %p, key: %p, precomputed: %p, result: true\n", chaining_key, key, precomputed);
+
+    return true;
 }
 
 static void mix_hash(u8 hash[NOISE_HASH_LEN], const u8 *src, size_t src_len)
 {
-	struct blake2s_state blake;
+    printk(KERN_INFO "Entering mix_hash with hash: %p, src: %p, src_len: %zu\n", hash, src, src_len);
 
-	blake2s_init(&blake, NOISE_HASH_LEN);
-	blake2s_update(&blake, hash, NOISE_HASH_LEN);
-	blake2s_update(&blake, src, src_len);
-	blake2s_final(&blake, hash);
+    struct blake2s_state blake;
+
+    blake2s_init(&blake, NOISE_HASH_LEN);
+    blake2s_update(&blake, hash, NOISE_HASH_LEN);
+    blake2s_update(&blake, src, src_len);
+    blake2s_final(&blake, hash);
+
+    printk(KERN_INFO "Exiting mix_hash with hash: %p, src: %p, src_len: %zu\n", hash, src, src_len);
 }
 
 static void mix_psk(u8 chaining_key[NOISE_HASH_LEN], u8 hash[NOISE_HASH_LEN],
-		    u8 key[NOISE_SYMMETRIC_KEY_LEN],
-		    const u8 psk[NOISE_SYMMETRIC_KEY_LEN])
+                    u8 key[NOISE_SYMMETRIC_KEY_LEN],
+                    const u8 psk[NOISE_SYMMETRIC_KEY_LEN])
 {
-	u8 temp_hash[NOISE_HASH_LEN];
+    printk(KERN_INFO "Entering mix_psk with chaining_key: %p, hash: %p, key: %p, psk: %p\n", chaining_key, hash, key, psk);
+
+    u8 temp_hash[NOISE_HASH_LEN];
 
-	kdf(chaining_key, temp_hash, key, psk, NOISE_HASH_LEN, NOISE_HASH_LEN,
-	    NOISE_SYMMETRIC_KEY_LEN, NOISE_SYMMETRIC_KEY_LEN, chaining_key);
-	mix_hash(hash, temp_hash, NOISE_HASH_LEN);
-	memzero_explicit(temp_hash, NOISE_HASH_LEN);
+    kdf(chaining_key, temp_hash, key, psk, NOISE_HASH_LEN, NOISE_HASH_LEN,
+        NOISE_SYMMETRIC_KEY_LEN, NOISE_SYMMETRIC_KEY_LEN, chaining_key);
+    mix_hash(hash, temp_hash, NOISE_HASH_LEN);
+    memzero_explicit(temp_hash, NOISE_HASH_LEN);
+
+    printk(KERN_INFO "Exiting mix_psk with chaining_key: %p, hash: %p, key: %p, psk: %p\n", chaining_key, hash, key, psk);
 }
 
 static void handshake_init(u8 chaining_key[NOISE_HASH_LEN],
-			   u8 hash[NOISE_HASH_LEN],
-			   const u8 remote_static[NOISE_PUBLIC_KEY_LEN])
+                           u8 hash[NOISE_HASH_LEN],
+                           const u8 remote_static[NOISE_PUBLIC_KEY_LEN])
 {
-	memcpy(hash, handshake_init_hash, NOISE_HASH_LEN);
-	memcpy(chaining_key, handshake_init_chaining_key, NOISE_HASH_LEN);
-	mix_hash(hash, remote_static, NOISE_PUBLIC_KEY_LEN);
+    printk(KERN_INFO "Entering handshake_init with chaining_key: %p, hash: %p, remote_static: %p\n", chaining_key, hash, remote_static);
+
+    memcpy(hash, handshake_init_hash, NOISE_HASH_LEN);
+    memcpy(chaining_key, handshake_init_chaining_key, NOISE_HASH_LEN);
+    mix_hash(hash, remote_static, NOISE_PUBLIC_KEY_LEN);
+
+    printk(KERN_INFO "Exiting handshake_init with chaining_key: %p, hash: %p, remote_static: %p\n", chaining_key, hash, remote_static);
 }
 
 static void message_encrypt(u8 *dst_ciphertext, const u8 *src_plaintext,
-			    size_t src_len, u8 key[NOISE_SYMMETRIC_KEY_LEN],
-			    u8 hash[NOISE_HASH_LEN])
+                            size_t src_len, u8 key[NOISE_SYMMETRIC_KEY_LEN],
+                            u8 hash[NOISE_HASH_LEN])
 {
-	chacha20poly1305_encrypt(dst_ciphertext, src_plaintext, src_len, hash,
-				 NOISE_HASH_LEN,
-				 0 /* Always zero for Noise_IK */, key);
-	mix_hash(hash, dst_ciphertext, noise_encrypted_len(src_len));
+    printk(KERN_INFO "Entering message_encrypt with dst_ciphertext: %p, src_plaintext: %p, src_len: %zu, key: %p, hash: %p\n",
+           dst_ciphertext, src_plaintext, src_len, key, hash);
+
+    chacha20poly1305_encrypt(dst_ciphertext, src_plaintext, src_len, hash,
+                             NOISE_HASH_LEN,
+                             0 /* Always zero for Noise_IK */, key);
+    mix_hash(hash, dst_ciphertext, noise_encrypted_len(src_len));
+
+    printk(KERN_INFO "Exiting message_encrypt with dst_ciphertext: %p, src_plaintext: %p, src_len: %zu, key: %p, hash: %p\n",
+           dst_ciphertext, src_plaintext, src_len, key, hash);
 }
 
 static bool message_decrypt(u8 *dst_plaintext, const u8 *src_ciphertext,
-			    size_t src_len, u8 key[NOISE_SYMMETRIC_KEY_LEN],
-			    u8 hash[NOISE_HASH_LEN])
+                            size_t src_len, u8 key[NOISE_SYMMETRIC_KEY_LEN],
+                            u8 hash[NOISE_HASH_LEN])
 {
-	if (!chacha20poly1305_decrypt(dst_plaintext, src_ciphertext, src_len,
-				      hash, NOISE_HASH_LEN,
-				      0 /* Always zero for Noise_IK */, key))
-		return false;
-	mix_hash(hash, src_ciphertext, src_len);
-	return true;
+    printk(KERN_INFO "Entering message_decrypt with dst_plaintext: %p, src_ciphertext: %p, src_len: %zu, key: %p, hash: %p\n",
+           dst_plaintext, src_ciphertext, src_len, key, hash);
+
+    if (!chacha20poly1305_decrypt(dst_plaintext, src_ciphertext, src_len,
+                                  hash, NOISE_HASH_LEN,
+                                  0 /* Always zero for Noise_IK */, key)) {
+        printk(KERN_INFO "Exiting message_decrypt with dst_plaintext: %p, src_ciphertext: %p, src_len: %zu, key: %p, hash: %p, result: false\n",
+               dst_plaintext, src_ciphertext, src_len, key, hash);
+        return false;
+    }
+    mix_hash(hash, src_ciphertext, src_len);
+
+    printk(KERN_INFO "Exiting message_decrypt with dst_plaintext: %p, src_ciphertext: %p, src_len: %zu, key: %p, hash: %p, result: true\n",
+           dst_plaintext, src_ciphertext, src_len, key, hash);
+
+    return true;
 }
 
 static void message_ephemeral(u8 ephemeral_dst[NOISE_PUBLIC_KEY_LEN],
-			      const u8 ephemeral_src[NOISE_PUBLIC_KEY_LEN],
-			      u8 chaining_key[NOISE_HASH_LEN],
-			      u8 hash[NOISE_HASH_LEN])
+                              const u8 ephemeral_src[NOISE_PUBLIC_KEY_LEN],
+                              u8 chaining_key[NOISE_HASH_LEN],
+                              u8 hash[NOISE_HASH_LEN])
 {
-	if (ephemeral_dst != ephemeral_src)
-		memcpy(ephemeral_dst, ephemeral_src, NOISE_PUBLIC_KEY_LEN);
-	mix_hash(hash, ephemeral_src, NOISE_PUBLIC_KEY_LEN);
-	kdf(chaining_key, NULL, NULL, ephemeral_src, NOISE_HASH_LEN, 0, 0,
-	    NOISE_PUBLIC_KEY_LEN, chaining_key);
+    printk(KERN_INFO "Entering message_ephemeral with ephemeral_dst: %p, ephemeral_src: %p, chaining_key: %p, hash: %p\n",
+           ephemeral_dst, ephemeral_src, chaining_key, hash);
+
+    if (ephemeral_dst != ephemeral_src)
+        memcpy(ephemeral_dst, ephemeral_src, NOISE_PUBLIC_KEY_LEN);
+    mix_hash(hash, ephemeral_src, NOISE_PUBLIC_KEY_LEN);
+    kdf(chaining_key, NULL, NULL, ephemeral_src, NOISE_HASH_LEN, 0, 0,
+        NOISE_PUBLIC_KEY_LEN, chaining_key);
+
+    printk(KERN_INFO "Exiting message_ephemeral with ephemeral_dst: %p, ephemeral_src: %p, chaining_key: %p, hash: %p\n",
+           ephemeral_dst, ephemeral_src, chaining_key, hash);
 }
 
 static void tai64n_now(u8 output[NOISE_TIMESTAMP_LEN])
 {
-	struct timespec64 now;
+    printk(KERN_INFO "Entering tai64n_now with output: %p\n", output);
+
+    struct timespec64 now;
 
-	ktime_get_real_ts64(&now);
+    ktime_get_real_ts64(&now);
 
-	/* In order to prevent some sort of infoleak from precise timers, we
-	 * round down the nanoseconds part to the closest rounded-down power of
-	 * two to the maximum initiations per second allowed anyway by the
-	 * implementation.
-	 */
-	now.tv_nsec = ALIGN_DOWN(now.tv_nsec,
-		rounddown_pow_of_two(NSEC_PER_SEC / INITIATIONS_PER_SECOND));
+    /* In order to prevent some sort of infoleak from precise timers, we
+     * round down the nanoseconds part to the closest rounded-down power of
+     * two to the maximum initiations per second allowed anyway by the
+     * implementation.
+     */
+    now.tv_nsec = ALIGN_DOWN(now.tv_nsec,
+                             rounddown_pow_of_two(NSEC_PER_SEC / INITIATIONS_PER_SECOND));
 
-	/* https://cr.yp.to/libtai/tai64.html */
-	*(__be64 *)output = cpu_to_be64(0x400000000000000aULL + now.tv_sec);
-	*(__be32 *)(output + sizeof(__be64)) = cpu_to_be32(now.tv_nsec);
+    /* https://cr.yp.to/libtai/tai64.html */
+    *(__be64 *)output = cpu_to_be64(0x400000000000000aULL + now.tv_sec);
+    *(__be32 *)(output + sizeof(__be64)) = cpu_to_be32(now.tv_nsec);
+
+    printk(KERN_INFO "Exiting tai64n_now with output: %p\n", output);
 }
 
+#ifdef ORIGINAL
 bool
 wg_noise_handshake_create_initiation(struct message_handshake_initiation *dst,
-				     struct noise_handshake *handshake)
+                                     struct noise_handshake *handshake)
 {
-	u8 timestamp[NOISE_TIMESTAMP_LEN];
-	u8 key[NOISE_SYMMETRIC_KEY_LEN];
-	bool ret = false;
+    printk(KERN_INFO "Entering wg_noise_handshake_create_initiation with dst: %p, handshake: %p\n", dst, handshake);
+
+    u8 timestamp[NOISE_TIMESTAMP_LEN];
+    u8 key[NOISE_SYMMETRIC_KEY_LEN];
+    bool ret = false;
 
-	/* We need to wait for crng _before_ taking any locks, since
-	 * curve25519_generate_secret uses get_random_bytes_wait.
-	 */
-	wait_for_random_bytes();
+    /* We need to wait for crng _before_ taking any locks, since
+     * curve25519_generate_secret uses get_random_bytes_wait.
+     */
+    wait_for_random_bytes();
 
-	down_read(&handshake->static_identity->lock);
-	down_write(&handshake->lock);
+    down_read(&handshake->static_identity->lock);
+    down_write(&handshake->lock);
 
-	if (unlikely(!handshake->static_identity->has_identity))
-		goto out;
+    if (unlikely(!handshake->static_identity->has_identity))
+        goto out;
 
-	dst->header.type = cpu_to_le32(MESSAGE_HANDSHAKE_INITIATION);
+    dst->header.type = cpu_to_le32(MESSAGE_HANDSHAKE_INITIATION);
 
-	handshake_init(handshake->chaining_key, handshake->hash,
-		       handshake->remote_static);
+    handshake_init(handshake->chaining_key, handshake->hash,
+                   handshake->remote_static);
 
-	/* e */
-	curve25519_generate_secret(handshake->ephemeral_private);
-	if (!curve25519_generate_public(dst->unencrypted_ephemeral,
-					handshake->ephemeral_private))
-		goto out;
-	message_ephemeral(dst->unencrypted_ephemeral,
-			  dst->unencrypted_ephemeral, handshake->chaining_key,
-			  handshake->hash);
+    /* e */
+    curve25519_generate_secret(handshake->ephemeral_private);
+    if (!curve25519_generate_public(dst->unencrypted_ephemeral,
+                                    handshake->ephemeral_private))
+        goto out;
+    message_ephemeral(dst->unencrypted_ephemeral,
+                      dst->unencrypted_ephemeral, handshake->chaining_key,
+                      handshake->hash);
 
-	/* es */
-	if (!mix_dh(handshake->chaining_key, key, handshake->ephemeral_private,
-		    handshake->remote_static))
-		goto out;
+    /* es */
+    if (!mix_dh(handshake->chaining_key, key, handshake->ephemeral_private,
+                handshake->remote_static))
+        goto out;
 
-	/* s */
-	message_encrypt(dst->encrypted_static,
-			handshake->static_identity->static_public,
-			NOISE_PUBLIC_KEY_LEN, key, handshake->hash);
+    /* s */
+    message_encrypt(dst->encrypted_static,
+                    handshake->static_identity->static_public,
+                    NOISE_PUBLIC_KEY_LEN, key, handshake->hash);
 
-	/* ss */
-	if (!mix_precomputed_dh(handshake->chaining_key, key,
-				handshake->precomputed_static_static))
-		goto out;
+    /* ss */
+    if (!mix_precomputed_dh(handshake->chaining_key, key,
+                            handshake->precomputed_static_static))
+        goto out;
 
-	/* {t} */
-	tai64n_now(timestamp);
-	message_encrypt(dst->encrypted_timestamp, timestamp,
-			NOISE_TIMESTAMP_LEN, key, handshake->hash);
+    /* {t} */
+    tai64n_now(timestamp);
+    message_encrypt(dst->encrypted_timestamp, timestamp,
+                    NOISE_TIMESTAMP_LEN, key, handshake->hash);
 
-	dst->sender_index = wg_index_hashtable_insert(
-		handshake->entry.peer->device->index_hashtable,
-		&handshake->entry);
+    dst->sender_index = wg_index_hashtable_insert(
+        handshake->entry.peer->device->index_hashtable,
+        &handshake->entry);
 
-	handshake->state = HANDSHAKE_CREATED_INITIATION;
-	ret = true;
+    handshake->state = HANDSHAKE_CREATED_INITIATION;
+    ret = true;
 
 out:
-	up_write(&handshake->lock);
-	up_read(&handshake->static_identity->lock);
-	memzero_explicit(key, NOISE_SYMMETRIC_KEY_LEN);
-	return ret;
+    up_write(&handshake->lock);
+    up_read(&handshake->static_identity->lock);
+    memzero_explicit(key, NOISE_SYMMETRIC_KEY_LEN);
+
+    printk(KERN_INFO "Exiting wg_noise_handshake_create_initiation with dst: %p, handshake: %p, result: %d\n", dst, handshake, ret);
+
+    return ret;
 }
+#endif
 
-struct wg_peer *
-wg_noise_handshake_consume_initiation(struct message_handshake_initiation *src,
-				      struct wg_device *wg)
-{
-	struct wg_peer *peer = NULL, *ret_peer = NULL;
-	struct noise_handshake *handshake;
-	bool replay_attack, flood_attack;
-	u8 key[NOISE_SYMMETRIC_KEY_LEN];
-	u8 chaining_key[NOISE_HASH_LEN];
-	u8 hash[NOISE_HASH_LEN];
-	u8 s[NOISE_PUBLIC_KEY_LEN];
-	u8 e[NOISE_PUBLIC_KEY_LEN];
-	u8 t[NOISE_TIMESTAMP_LEN];
-	u64 initiation_consumption;
-
-	down_read(&wg->static_identity.lock);
-	if (unlikely(!wg->static_identity.has_identity))
-		goto out;
-
-	handshake_init(chaining_key, hash, wg->static_identity.static_public);
-
-	/* e */
-	message_ephemeral(e, src->unencrypted_ephemeral, chaining_key, hash);
-
-	/* es */
-	if (!mix_dh(chaining_key, key, wg->static_identity.static_private, e))
-		goto out;
-
-	/* s */
-	if (!message_decrypt(s, src->encrypted_static,
-			     sizeof(src->encrypted_static), key, hash))
-		goto out;
-
-	/* Lookup which peer we're actually talking to */
-	peer = wg_pubkey_hashtable_lookup(wg->peer_hashtable, s);
-	if (!peer)
-		goto out;
-	handshake = &peer->handshake;
-
-	/* ss */
-	if (!mix_precomputed_dh(chaining_key, key,
-				handshake->precomputed_static_static))
-	    goto out;
-
-	/* {t} */
-	if (!message_decrypt(t, src->encrypted_timestamp,
-			     sizeof(src->encrypted_timestamp), key, hash))
-		goto out;
-
-	down_read(&handshake->lock);
-	replay_attack = memcmp(t, handshake->latest_timestamp,
-			       NOISE_TIMESTAMP_LEN) <= 0;
-	flood_attack = (s64)handshake->last_initiation_consumption +
-			       NSEC_PER_SEC / INITIATIONS_PER_SECOND >
-		       (s64)ktime_get_coarse_boottime_ns();
-	up_read(&handshake->lock);
-	if (replay_attack || flood_attack)
-		goto out;
-
-	/* Success! Copy everything to peer */
-	down_write(&handshake->lock);
-	memcpy(handshake->remote_ephemeral, e, NOISE_PUBLIC_KEY_LEN);
-	if (memcmp(t, handshake->latest_timestamp, NOISE_TIMESTAMP_LEN) > 0)
-		memcpy(handshake->latest_timestamp, t, NOISE_TIMESTAMP_LEN);
-	memcpy(handshake->hash, hash, NOISE_HASH_LEN);
-	memcpy(handshake->chaining_key, chaining_key, NOISE_HASH_LEN);
-	handshake->remote_index = src->sender_index;
-	initiation_consumption = ktime_get_coarse_boottime_ns();
-	if ((s64)(handshake->last_initiation_consumption - initiation_consumption) < 0)
-		handshake->last_initiation_consumption = initiation_consumption;
-	handshake->state = HANDSHAKE_CONSUMED_INITIATION;
-	up_write(&handshake->lock);
-	ret_peer = peer;
+bool
+wg_noise_handshake_create_initiation(struct message_handshake_initiation *dst,
+                                     struct noise_handshake *handshake)
+{
+    printk(KERN_INFO "Entering wg_noise_handshake_create_initiation with dst: %p, handshake: %p\n", dst, handshake);
+
+    u8 timestamp[NOISE_TIMESTAMP_LEN];
+    u8 key[NOISE_SYMMETRIC_KEY_LEN];
+    bool ret = false;
+
+    /* We need to wait for crng _before_ taking any locks, since
+     * curve25519_generate_secret uses get_random_bytes_wait.
+     */
+    wait_for_random_bytes();
+
+    down_read(&handshake->static_identity->lock);
+    down_write(&handshake->lock);
+
+    if (unlikely(!handshake->static_identity->has_identity)) {
+        printk(KERN_INFO "Exiting wg_noise_handshake_create_initiation early: static identity missing\n");
+        goto out;
+    }
+
+    dst->header.type = cpu_to_le32(MESSAGE_HANDSHAKE_INITIATION);
+    printk(KERN_INFO "Handshake header set to MESSAGE_HANDSHAKE_INITIATION\n");
+
+    handshake_init(handshake->chaining_key, handshake->hash, handshake->remote_static);
+    printk(KERN_INFO "Handshake initialized with chaining_key: %*phN, hash: %*phN, remote_static: %*phN\n",
+           NOISE_HASH_LEN, handshake->chaining_key,
+           NOISE_HASH_LEN, handshake->hash,
+           NOISE_PUBLIC_KEY_LEN, handshake->remote_static);
+
+    /* e */
+    curve25519_generate_secret(handshake->ephemeral_private);
+    printk(KERN_INFO "Ephemeral private key generated: %*phN\n", NOISE_PUBLIC_KEY_LEN, handshake->ephemeral_private);
+
+    if (!curve25519_generate_public(dst->unencrypted_ephemeral, handshake->ephemeral_private)) {
+        printk(KERN_INFO "Failed to generate ephemeral public key\n");
+        goto out;
+    }
+    printk(KERN_INFO "Ephemeral public key generated: %*phN\n", NOISE_PUBLIC_KEY_LEN, dst->unencrypted_ephemeral);
+
+    message_ephemeral(dst->unencrypted_ephemeral, dst->unencrypted_ephemeral, handshake->chaining_key, handshake->hash);
+    printk(KERN_INFO "Ephemeral key processed and mixed into hash, chaining_key: %*phN, hash: %*phN\n",
+           NOISE_HASH_LEN, handshake->chaining_key,
+           NOISE_HASH_LEN, handshake->hash);
+
+    /* es */
+    if (!mix_dh(handshake->chaining_key, key, handshake->ephemeral_private, handshake->remote_static)) {
+        printk(KERN_INFO "Failed to mix DH (es)\n");
+        goto out;
+    }
+    printk(KERN_INFO "Mixed DH (es) derived key: %*phN\n", NOISE_SYMMETRIC_KEY_LEN, key);
+
+    /* s */
+    message_encrypt(dst->encrypted_static, handshake->static_identity->static_public, NOISE_PUBLIC_KEY_LEN, key, handshake->hash);
+    printk(KERN_INFO "Static public key encrypted: %*phN\n", NOISE_PUBLIC_KEY_LEN, dst->encrypted_static);
+
+    /* ss */
+    if (!mix_precomputed_dh(handshake->chaining_key, key, handshake->precomputed_static_static)) {
+        printk(KERN_INFO "Failed to mix precomputed DH (ss)\n");
+        goto out;
+    }
+    printk(KERN_INFO "Mixed precomputed DH (ss), chaining_key: %*phN, key: %*phN\n",
+           NOISE_HASH_LEN, handshake->chaining_key,
+           NOISE_SYMMETRIC_KEY_LEN, key);
+
+    /* {t} */
+    tai64n_now(timestamp);
+    printk(KERN_INFO "Current timestamp: %*phN\n", NOISE_TIMESTAMP_LEN, timestamp);
+
+    message_encrypt(dst->encrypted_timestamp, timestamp, NOISE_TIMESTAMP_LEN, key, handshake->hash);
+    printk(KERN_INFO "Timestamp encrypted: %*phN\n", NOISE_TIMESTAMP_LEN, dst->encrypted_timestamp);
+
+    dst->sender_index = wg_index_hashtable_insert(handshake->entry.peer->device->index_hashtable, &handshake->entry);
+    printk(KERN_INFO "Sender index inserted into hashtable: %u\n", dst->sender_index);
+
+    handshake->state = HANDSHAKE_CREATED_INITIATION;
+    ret = true;
 
 out:
-	memzero_explicit(key, NOISE_SYMMETRIC_KEY_LEN);
-	memzero_explicit(hash, NOISE_HASH_LEN);
-	memzero_explicit(chaining_key, NOISE_HASH_LEN);
-	up_read(&wg->static_identity.lock);
-	if (!ret_peer)
-		wg_peer_put(peer);
-	return ret_peer;
+    up_write(&handshake->lock);
+    up_read(&handshake->static_identity->lock);
+    memzero_explicit(key, NOISE_SYMMETRIC_KEY_LEN);
+    printk(KERN_INFO "Exiting wg_noise_handshake_create_initiation with result: %d\n", ret);
+    return ret;
 }
 
 
+struct wg_peer *
+wg_noise_handshake_consume_initiation(struct message_handshake_initiation *src,
+                                      struct wg_device *wg)
+{
+    printk(KERN_INFO "Entering wg_noise_handshake_consume_initiation with src: %p, wg: %p\n", src, wg);
+
+    struct wg_peer *peer = NULL, *ret_peer = NULL;
+    struct noise_handshake *handshake;
+    bool replay_attack, flood_attack;
+    u8 key[NOISE_SYMMETRIC_KEY_LEN];
+    u8 chaining_key[NOISE_HASH_LEN];
+    u8 hash[NOISE_HASH_LEN];
+    u8 s[NOISE_PUBLIC_KEY_LEN];
+    u8 e[NOISE_PUBLIC_KEY_LEN];
+    u8 t[NOISE_TIMESTAMP_LEN];
+    u64 initiation_consumption;
+
+    down_read(&wg->static_identity.lock);
+    if (unlikely(!wg->static_identity.has_identity))
+        goto out;
+
+    handshake_init(chaining_key, hash, wg->static_identity.static_public);
+
+    /* e */
+    message_ephemeral(e, src->unencrypted_ephemeral, chaining_key, hash);
+
+    /* es */
+    if (!mix_dh(chaining_key, key, wg->static_identity.static_private, e))
+        goto out;
+
+    /* s */
+    if (!message_decrypt(s, src->encrypted_static,
+                         sizeof(src->encrypted_static), key, hash))
+        goto out;
+
+    /* Lookup which peer we're actually talking to */
+    peer = wg_pubkey_hashtable_lookup(wg->peer_hashtable, s);
+    if (!peer)
+        goto out;
+    handshake = &peer->handshake;
+
+    char b64_output[45];  // Base64 encoded output buffer for 32 bytes input
+    base64_encode(b64_output, handshake->remote_static, NOISE_PUBLIC_KEY_LEN);
+    printk(KERN_INFO "WG: Initiator's static public key (remote_static) [Base64]: %s\n", b64_output);
+    printk(KERN_INFO "WG: Initiator's static public key (remote_static) [Hex]: %*ph\n", NOISE_PUBLIC_KEY_LEN, handshake->remote_static);
+    base64_encode(b64_output, wg->static_identity.static_public, NOISE_PUBLIC_KEY_LEN);
+    printk(KERN_INFO "WG: Responder's static public key (static_public) [Base64]: %s\n", b64_output);
+    printk(KERN_INFO "WG: Responder's static public key (static_public) [Hex]: %*ph\n", NOISE_PUBLIC_KEY_LEN, wg->static_identity.static_public);
+ 
+ 
+    /* ss */
+    if (!mix_precomputed_dh(chaining_key, key,
+                            handshake->precomputed_static_static))
+        goto out;
+
+    /* {t} */
+    if (!message_decrypt(t, src->encrypted_timestamp,
+                         sizeof(src->encrypted_timestamp), key, hash))
+        goto out;
+
+    down_read(&handshake->lock);
+    replay_attack = memcmp(t, handshake->latest_timestamp,
+                           NOISE_TIMESTAMP_LEN) <= 0;
+    flood_attack = (s64)handshake->last_initiation_consumption +
+                   NSEC_PER_SEC / INITIATIONS_PER_SECOND >
+                   (s64)ktime_get_coarse_boottime_ns();
+    up_read(&handshake->lock);
+    if (replay_attack || flood_attack)
+        goto out;
+
+    /* Success! Copy everything to peer */
+    down_write(&handshake->lock);
+    memcpy(handshake->remote_ephemeral, e, NOISE_PUBLIC_KEY_LEN);
+    if (memcmp(t, handshake->latest_timestamp, NOISE_TIMESTAMP_LEN) > 0)
+        memcpy(handshake->latest_timestamp, t, NOISE_TIMESTAMP_LEN);
+    memcpy(handshake->hash, hash, NOISE_HASH_LEN);
+    memcpy(handshake->chaining_key, chaining_key, NOISE_HASH_LEN);
+    handshake->remote_index = src->sender_index;
+    initiation_consumption = ktime_get_coarse_boottime_ns();
+    if ((s64)(handshake->last_initiation_consumption - initiation_consumption) < 0)
+        handshake->last_initiation_consumption = initiation_consumption;
+    handshake->state = HANDSHAKE_CONSUMED_INITIATION;
+    up_write(&handshake->lock);
+    ret_peer = peer;
+
+    base64_encode(b64_output, handshake->remote_ephemeral, NOISE_PUBLIC_KEY_LEN);
+    printk(KERN_INFO "WG: Responder's ephemeral public key [Base64]: %s\n", b64_output);
+    printk(KERN_INFO "WG: Responder's ephemeral public key [Hex]: %*ph\n", NOISE_PUBLIC_KEY_LEN, handshake->remote_ephemeral);
+	
+	
+out:
+    memzero_explicit(key, NOISE_SYMMETRIC_KEY_LEN);
+    memzero_explicit(hash, NOISE_HASH_LEN);
+    memzero_explicit(chaining_key, NOISE_HASH_LEN);
+    up_read(&wg->static_identity.lock);
+    if (!ret_peer)
+        wg_peer_put(peer);
+
+    printk(KERN_INFO "Exiting wg_noise_handshake_consume_initiation with src: %p, wg: %p, result: %p\n", src, wg, ret_peer);
+
+    return ret_peer;
+}
+
+#ifdef ORIGINAL
 bool wg_noise_handshake_create_response(struct message_handshake_response *dst,
-					struct noise_handshake *handshake)
+                                        struct noise_handshake *handshake)
 {
-	u8 key[NOISE_SYMMETRIC_KEY_LEN];
-	bool ret = false;
+    printk(KERN_INFO "Entering wg_noise_handshake_create_response with dst: %p, handshake: %p\n", dst, handshake);
+
+    u8 key[NOISE_SYMMETRIC_KEY_LEN];
+    bool ret = false;
+
+    /* We need to wait for crng _before_ taking any locks, since
+     * curve25519_generate_secret uses get_random_bytes_wait.
+     */
+    wait_for_random_bytes();
+
+    down_read(&handshake->static_identity->lock);
+    down_write(&handshake->lock);
+
+    if (handshake->state != HANDSHAKE_CONSUMED_INITIATION)
+        goto out;
+
+    dst->header.type = cpu_to_le32(MESSAGE_HANDSHAKE_RESPONSE);
+    dst->receiver_index = handshake->remote_index;
 
-	/* We need to wait for crng _before_ taking any locks, since
-	 * curve25519_generate_secret uses get_random_bytes_wait.
-	 */
-	wait_for_random_bytes();
+    /* e */
+    curve25519_generate_secret(handshake->ephemeral_private);
+    if (!curve25519_generate_public(dst->unencrypted_ephemeral,
+                                    handshake->ephemeral_private))
+        goto out;
+    message_ephemeral(dst->unencrypted_ephemeral,
+                      dst->unencrypted_ephemeral, handshake->chaining_key,
+                      handshake->hash);
 
-	down_read(&handshake->static_identity->lock);
-	down_write(&handshake->lock);
+    /* ee */
+    if (!mix_dh(handshake->chaining_key, NULL, handshake->ephemeral_private,
+                handshake->remote_ephemeral))
+        goto out;
 
-	if (handshake->state != HANDSHAKE_CONSUMED_INITIATION)
-		goto out;
+    /* se */
+    if (!mix_dh(handshake->chaining_key, NULL, handshake->ephemeral_private,
+                handshake->remote_static))
+        goto out;
 
-	dst->header.type = cpu_to_le32(MESSAGE_HANDSHAKE_RESPONSE);
-	dst->receiver_index = handshake->remote_index;
+    /* psk */
+    mix_psk(handshake->chaining_key, handshake->hash, key,
+            handshake->preshared_key);
 
-	/* e */
-	curve25519_generate_secret(handshake->ephemeral_private);
-	if (!curve25519_generate_public(dst->unencrypted_ephemeral,
-					handshake->ephemeral_private))
-		goto out;
-	message_ephemeral(dst->unencrypted_ephemeral,
-			  dst->unencrypted_ephemeral, handshake->chaining_key,
-			  handshake->hash);
+    /* {} */
+    message_encrypt(dst->encrypted_nothing, NULL, 0, key, handshake->hash);
 
-	/* ee */
-	if (!mix_dh(handshake->chaining_key, NULL, handshake->ephemeral_private,
-		    handshake->remote_ephemeral))
-		goto out;
+    dst->sender_index = wg_index_hashtable_insert(
+        handshake->entry.peer->device->index_hashtable,
+        &handshake->entry);
 
-	/* se */
-	if (!mix_dh(handshake->chaining_key, NULL, handshake->ephemeral_private,
-		    handshake->remote_static))
-		goto out;
+    handshake->state = HANDSHAKE_CREATED_RESPONSE;
+    ret = true;
 
-	/* psk */
-	mix_psk(handshake->chaining_key, handshake->hash, key,
-		handshake->preshared_key);
+out:
+    up_write(&handshake->lock);
+    up_read(&handshake->static_identity->lock);
+    memzero_explicit(key, NOISE_SYMMETRIC_KEY_LEN);
 
-	/* {} */
-	message_encrypt(dst->encrypted_nothing, NULL, 0, key, handshake->hash);
+    printk(KERN_INFO "Exiting wg_noise_handshake_create_response with dst: %p, handshake: %p, result: %d\n", dst, handshake, ret);
 
-	dst->sender_index = wg_index_hashtable_insert(
-		handshake->entry.peer->device->index_hashtable,
-		&handshake->entry);
+    return ret;
+}
+#endif
 
-	handshake->state = HANDSHAKE_CREATED_RESPONSE;
-	ret = true;
+bool
+wg_noise_handshake_create_response(struct message_handshake_response *dst,
+                                   struct noise_handshake *handshake)
+{
+    printk(KERN_INFO "Entering wg_noise_handshake_create_response with dst: %p, handshake: %p\n", dst, handshake);
+
+    u8 key[NOISE_SYMMETRIC_KEY_LEN];
+    bool ret = false;
+
+    /* We need to wait for crng _before_ taking any locks, since
+     * curve25519_generate_secret uses get_random_bytes_wait.
+     */
+    wait_for_random_bytes();
+
+    down_read(&handshake->static_identity->lock);
+    down_write(&handshake->lock);
+
+    if (handshake->state != HANDSHAKE_CONSUMED_INITIATION) {
+        printk(KERN_INFO "Exiting wg_noise_handshake_create_response early: state != HANDSHAKE_CONSUMED_INITIATION\n");
+        goto out;
+    }
+
+    dst->header.type = cpu_to_le32(MESSAGE_HANDSHAKE_RESPONSE);
+    dst->receiver_index = handshake->remote_index;
+    printk(KERN_INFO "Handshake response initialized: header.type = MESSAGE_HANDSHAKE_RESPONSE, receiver_index = %u\n", dst->receiver_index);
+
+    /* e */
+    curve25519_generate_secret(handshake->ephemeral_private);
+    printk(KERN_INFO "Ephemeral private key generated: %*phN\n", NOISE_PUBLIC_KEY_LEN, handshake->ephemeral_private);
+
+    if (!curve25519_generate_public(dst->unencrypted_ephemeral, handshake->ephemeral_private)) {
+        printk(KERN_INFO "Failed to generate ephemeral public key\n");
+        goto out;
+    }
+    printk(KERN_INFO "Ephemeral public key generated: %*phN\n", NOISE_PUBLIC_KEY_LEN, dst->unencrypted_ephemeral);
+
+    message_ephemeral(dst->unencrypted_ephemeral, dst->unencrypted_ephemeral, handshake->chaining_key, handshake->hash);
+    printk(KERN_INFO "Ephemeral key processed and mixed into hash, chaining_key: %*phN, hash: %*phN\n",
+           NOISE_HASH_LEN, handshake->chaining_key,
+           NOISE_HASH_LEN, handshake->hash);
+
+    /* ee */
+    if (!mix_dh(handshake->chaining_key, NULL, handshake->ephemeral_private, handshake->remote_ephemeral)) {
+        printk(KERN_INFO "Failed to mix DH (ee)\n");
+        goto out;
+    }
+    printk(KERN_INFO "Mixed DH (ee), chaining_key: %*phN\n", NOISE_HASH_LEN, handshake->chaining_key);
+
+    /* se */
+    if (!mix_dh(handshake->chaining_key, NULL, handshake->ephemeral_private, handshake->remote_static)) {
+        printk(KERN_INFO "Failed to mix DH (se)\n");
+        goto out;
+    }
+    printk(KERN_INFO "Mixed DH (se), chaining_key: %*phN\n", NOISE_HASH_LEN, handshake->chaining_key);
+
+    /* psk */
+    mix_psk(handshake->chaining_key, handshake->hash, key, handshake->preshared_key);
+    printk(KERN_INFO "Mixed PSK, chaining_key: %*phN, hash: %*phN, key: %*phN\n",
+           NOISE_HASH_LEN, handshake->chaining_key,
+           NOISE_HASH_LEN, handshake->hash,
+           NOISE_SYMMETRIC_KEY_LEN, key);
+
+    /* {} */
+    message_encrypt(dst->encrypted_nothing, NULL, 0, key, handshake->hash);
+    printk(KERN_INFO "Encrypted empty message, encrypted_nothing: %*phN\n", noise_encrypted_len(0), dst->encrypted_nothing);
+
+    dst->sender_index = wg_index_hashtable_insert(handshake->entry.peer->device->index_hashtable, &handshake->entry);
+    printk(KERN_INFO "Sender index inserted into hashtable: %u\n", dst->sender_index);
+
+    handshake->state = HANDSHAKE_CREATED_RESPONSE;
+    ret = true;
 
 out:
-	up_write(&handshake->lock);
-	up_read(&handshake->static_identity->lock);
-	memzero_explicit(key, NOISE_SYMMETRIC_KEY_LEN);
-	return ret;
+    up_write(&handshake->lock);
+    up_read(&handshake->static_identity->lock);
+    memzero_explicit(key, NOISE_SYMMETRIC_KEY_LEN);
+    printk(KERN_INFO "Exiting wg_noise_handshake_create_response with result: %d\n", ret);
+    return ret;
 }
 
+
 struct wg_peer *
 wg_noise_handshake_consume_response(struct message_handshake_response *src,
-				    struct wg_device *wg)
-{
-	enum noise_handshake_state state = HANDSHAKE_ZEROED;
-	struct wg_peer *peer = NULL, *ret_peer = NULL;
-	struct noise_handshake *handshake;
-	u8 key[NOISE_SYMMETRIC_KEY_LEN];
-	u8 hash[NOISE_HASH_LEN];
-	u8 chaining_key[NOISE_HASH_LEN];
-	u8 e[NOISE_PUBLIC_KEY_LEN];
-	u8 ephemeral_private[NOISE_PUBLIC_KEY_LEN];
-	u8 static_private[NOISE_PUBLIC_KEY_LEN];
-	u8 preshared_key[NOISE_SYMMETRIC_KEY_LEN];
-
-	down_read(&wg->static_identity.lock);
-
-	if (unlikely(!wg->static_identity.has_identity))
-		goto out;
-
-	handshake = (struct noise_handshake *)wg_index_hashtable_lookup(
-		wg->index_hashtable, INDEX_HASHTABLE_HANDSHAKE,
-		src->receiver_index, &peer);
-	if (unlikely(!handshake))
-		goto out;
-
-	down_read(&handshake->lock);
-	state = handshake->state;
-	memcpy(hash, handshake->hash, NOISE_HASH_LEN);
-	memcpy(chaining_key, handshake->chaining_key, NOISE_HASH_LEN);
-	memcpy(ephemeral_private, handshake->ephemeral_private,
-	       NOISE_PUBLIC_KEY_LEN);
-	memcpy(preshared_key, handshake->preshared_key,
-	       NOISE_SYMMETRIC_KEY_LEN);
-	up_read(&handshake->lock);
-
-	if (state != HANDSHAKE_CREATED_INITIATION)
-		goto fail;
-
-	/* e */
-	message_ephemeral(e, src->unencrypted_ephemeral, chaining_key, hash);
-
-	/* ee */
-	if (!mix_dh(chaining_key, NULL, ephemeral_private, e))
-		goto fail;
-
-	/* se */
-	if (!mix_dh(chaining_key, NULL, wg->static_identity.static_private, e))
-		goto fail;
-
-	/* psk */
-	mix_psk(chaining_key, hash, key, preshared_key);
-
-	/* {} */
-	if (!message_decrypt(NULL, src->encrypted_nothing,
-			     sizeof(src->encrypted_nothing), key, hash))
-		goto fail;
-
-	/* Success! Copy everything to peer */
-	down_write(&handshake->lock);
-	/* It's important to check that the state is still the same, while we
-	 * have an exclusive lock.
-	 */
-	if (handshake->state != state) {
-		up_write(&handshake->lock);
-		goto fail;
-	}
-	memcpy(handshake->remote_ephemeral, e, NOISE_PUBLIC_KEY_LEN);
-	memcpy(handshake->hash, hash, NOISE_HASH_LEN);
-	memcpy(handshake->chaining_key, chaining_key, NOISE_HASH_LEN);
-	handshake->remote_index = src->sender_index;
-	handshake->state = HANDSHAKE_CONSUMED_RESPONSE;
-	up_write(&handshake->lock);
-	ret_peer = peer;
-	goto out;
+                                    struct wg_device *wg)
+{
+    printk(KERN_INFO "Entering wg_noise_handshake_consume_response with src: %p, wg: %p\n", src, wg);
+
+    enum noise_handshake_state state = HANDSHAKE_ZEROED;
+    struct wg_peer *peer = NULL, *ret_peer = NULL;
+    struct noise_handshake *handshake;
+    u8 key[NOISE_SYMMETRIC_KEY_LEN];
+    u8 hash[NOISE_HASH_LEN];
+    u8 chaining_key[NOISE_HASH_LEN];
+    u8 e[NOISE_PUBLIC_KEY_LEN];
+    u8 ephemeral_private[NOISE_PUBLIC_KEY_LEN];
+    u8 static_private[NOISE_PUBLIC_KEY_LEN];
+    u8 preshared_key[NOISE_SYMMETRIC_KEY_LEN];
+
+    down_read(&wg->static_identity.lock);
+
+    if (unlikely(!wg->static_identity.has_identity))
+        goto out;
+
+    handshake = (struct noise_handshake *)wg_index_hashtable_lookup(
+        wg->index_hashtable, INDEX_HASHTABLE_HANDSHAKE,
+        src->receiver_index, &peer);
+    if (unlikely(!handshake))
+        goto out;
+
+    down_read(&handshake->lock);
+    state = handshake->state;
+    memcpy(hash, handshake->hash, NOISE_HASH_LEN);
+    memcpy(chaining_key, handshake->chaining_key, NOISE_HASH_LEN);
+    memcpy(ephemeral_private, handshake->ephemeral_private,
+           NOISE_PUBLIC_KEY_LEN);
+    memcpy(preshared_key, handshake->preshared_key,
+           NOISE_SYMMETRIC_KEY_LEN);
+    up_read(&handshake->lock);
+
+    if (state != HANDSHAKE_CREATED_INITIATION)
+        goto fail;
+
+    /* e */
+    message_ephemeral(e, src->unencrypted_ephemeral, chaining_key, hash);
+
+    /* ee */
+    if (!mix_dh(chaining_key, NULL, ephemeral_private, e))
+        goto fail;
+
+    /* se */
+    if (!mix_dh(chaining_key, NULL, wg->static_identity.static_private, e))
+        goto fail;
+
+    /* psk */
+    mix_psk(chaining_key, hash, key, preshared_key);
+
+    /* {} */
+    if (!message_decrypt(NULL, src->encrypted_nothing,
+                         sizeof(src->encrypted_nothing), key, hash))
+        goto fail;
+
+    /* Success! Copy everything to peer */
+    down_write(&handshake->lock);
+    /* It's important to check that the state is still the same, while we
+     * have an exclusive lock.
+     */
+    if (handshake->state != state) {
+        up_write(&handshake->lock);
+        goto fail;
+    }
+    memcpy(handshake->remote_ephemeral, e, NOISE_PUBLIC_KEY_LEN);
+    memcpy(handshake->hash, hash, NOISE_HASH_LEN);
+    memcpy(handshake->chaining_key, chaining_key, NOISE_HASH_LEN);
+    handshake->remote_index = src->sender_index;
+    handshake->state = HANDSHAKE_CONSUMED_RESPONSE;
+    up_write(&handshake->lock);
+    ret_peer = peer;
+    goto out;
 
 fail:
-	wg_peer_put(peer);
+    wg_peer_put(peer);
 out:
-	memzero_explicit(key, NOISE_SYMMETRIC_KEY_LEN);
-	memzero_explicit(hash, NOISE_HASH_LEN);
-	memzero_explicit(chaining_key, NOISE_HASH_LEN);
-	memzero_explicit(ephemeral_private, NOISE_PUBLIC_KEY_LEN);
-	memzero_explicit(static_private, NOISE_PUBLIC_KEY_LEN);
-	memzero_explicit(preshared_key, NOISE_SYMMETRIC_KEY_LEN);
-	up_read(&wg->static_identity.lock);
-	return ret_peer;
+    memzero_explicit(key, NOISE_SYMMETRIC_KEY_LEN);
+    memzero_explicit(hash, NOISE_HASH_LEN);
+    memzero_explicit(chaining_key, NOISE_HASH_LEN);
+    memzero_explicit(ephemeral_private, NOISE_PUBLIC_KEY_LEN);
+    memzero_explicit(static_private, NOISE_PUBLIC_KEY_LEN);
+    memzero_explicit(preshared_key, NOISE_SYMMETRIC_KEY_LEN);
+    up_read(&wg->static_identity.lock);
+
+    printk(KERN_INFO "Exiting wg_noise_handshake_consume_response with src: %p, wg: %p, result: %p\n", src, wg, ret_peer);
+
+    return ret_peer;
 }
 
 bool wg_noise_handshake_begin_session(struct noise_handshake *handshake,
-				      struct noise_keypairs *keypairs)
-{
-	struct noise_keypair *new_keypair;
-	bool ret = false;
-
-	down_write(&handshake->lock);
-	if (handshake->state != HANDSHAKE_CREATED_RESPONSE &&
-	    handshake->state != HANDSHAKE_CONSUMED_RESPONSE)
-		goto out;
-
-	new_keypair = keypair_create(handshake->entry.peer);
-	if (!new_keypair)
-		goto out;
-	new_keypair->i_am_the_initiator = handshake->state ==
-					  HANDSHAKE_CONSUMED_RESPONSE;
-	new_keypair->remote_index = handshake->remote_index;
-
-	if (new_keypair->i_am_the_initiator)
-		derive_keys(&new_keypair->sending, &new_keypair->receiving,
-			    handshake->chaining_key);
-	else
-		derive_keys(&new_keypair->receiving, &new_keypair->sending,
-			    handshake->chaining_key);
-
-	handshake_zero(handshake);
-	rcu_read_lock_bh();
-	if (likely(!READ_ONCE(container_of(handshake, struct wg_peer,
-					   handshake)->is_dead))) {
-		add_new_keypair(keypairs, new_keypair);
-		net_dbg_ratelimited("%s: Keypair %llu created for peer %llu\n",
-				    handshake->entry.peer->device->dev->name,
-				    new_keypair->internal_id,
-				    handshake->entry.peer->internal_id);
-		ret = wg_index_hashtable_replace(
-			handshake->entry.peer->device->index_hashtable,
-			&handshake->entry, &new_keypair->entry);
-	} else {
-		kfree_sensitive(new_keypair);
-	}
-	rcu_read_unlock_bh();
+                                      struct noise_keypairs *keypairs)
+{
+    printk(KERN_INFO "Entering wg_noise_handshake_begin_session with handshake: %p, keypairs: %p\n", handshake, keypairs);
+
+    struct noise_keypair *new_keypair;
+    bool ret = false;
+
+    down_write(&handshake->lock);
+    if (handshake->state != HANDSHAKE_CREATED_RESPONSE &&
+        handshake->state != HANDSHAKE_CONSUMED_RESPONSE)
+        goto out;
+
+    new_keypair = keypair_create(handshake->entry.peer);
+    if (!new_keypair)
+        goto out;
+    new_keypair->i_am_the_initiator = handshake->state ==
+                                       HANDSHAKE_CONSUMED_RESPONSE;
+    new_keypair->remote_index = handshake->remote_index;
+
+    if (new_keypair->i_am_the_initiator)
+        derive_keys(&new_keypair->sending, &new_keypair->receiving,
+                    handshake->chaining_key);
+    else
+        derive_keys(&new_keypair->receiving, &new_keypair->sending,
+                    handshake->chaining_key);
+
+    handshake_zero(handshake);
+    rcu_read_lock_bh();
+    if (likely(!READ_ONCE(container_of(handshake, struct wg_peer,
+                                       handshake)->is_dead))) {
+        add_new_keypair(keypairs, new_keypair);
+        net_dbg_ratelimited("%s: Keypair %llu created for peer %llu\n",
+                            handshake->entry.peer->device->dev->name,
+                            new_keypair->internal_id,
+                            handshake->entry.peer->internal_id);
+        ret = wg_index_hashtable_replace(
+            handshake->entry.peer->device->index_hashtable,
+            &handshake->entry, &new_keypair->entry);
+    } else {
+        kfree_sensitive(new_keypair);
+    }
+    rcu_read_unlock_bh();
 
 out:
-	up_write(&handshake->lock);
-	return ret;
+    up_write(&handshake->lock);
+
+    printk(KERN_INFO "Exiting wg_noise_handshake_begin_session with handshake: %p, keypairs: %p, result: %d\n", handshake, keypairs, ret);
+
+    return ret;
 }
diff --git a/wireguard-linux/drivers/net/wireguard/peer.c b/wireguard-linux/drivers/net/wireguard/peer.c
index 1cb502a932e0..c08d55b47d7a 100644
--- a/wireguard-linux/drivers/net/wireguard/peer.c
+++ b/wireguard-linux/drivers/net/wireguard/peer.c
@@ -9,32 +9,42 @@
 #include "timers.h"
 #include "peerlookup.h"
 #include "noise.h"
+#include "socket.h"
 
 #include <linux/kref.h>
 #include <linux/lockdep.h>
 #include <linux/rcupdate.h>
 #include <linux/list.h>
+#include <linux/wireguard.h>
 
 static struct kmem_cache *peer_cache;
 static atomic64_t peer_counter = ATOMIC64_INIT(0);
 
+void wg_clean_peer_socket(struct wg_peer *peer, bool release, bool destroy, bool inbound);
+
 struct wg_peer *wg_peer_create(struct wg_device *wg,
 			       const u8 public_key[NOISE_PUBLIC_KEY_LEN],
 			       const u8 preshared_key[NOISE_SYMMETRIC_KEY_LEN])
 {
+	printk(KERN_INFO "wg_peer_create: entry with wg=%p, public_key=%p, preshared_key=%p\n", wg, public_key, preshared_key);
 	struct wg_peer *peer;
 	int ret = -ENOMEM;
 
 	lockdep_assert_held(&wg->device_update_lock);
 
-	if (wg->num_peers >= MAX_PEERS_PER_DEVICE)
+	if (wg->num_peers >= MAX_PEERS_PER_DEVICE) {
+		printk(KERN_INFO "wg_peer_create: exit with ERR_PTR(ret)\n");
 		return ERR_PTR(ret);
+	}
 
 	peer = kmem_cache_zalloc(peer_cache, GFP_KERNEL);
-	if (unlikely(!peer))
+	if (unlikely(!peer)) {
+		printk(KERN_INFO "wg_peer_create: exit with ERR_PTR(ret)\n");
 		return ERR_PTR(ret);
-	if (unlikely(dst_cache_init(&peer->endpoint_cache, GFP_KERNEL)))
+	}
+	if (unlikely(dst_cache_init(&peer->endpoint_cache, GFP_KERNEL))) {
 		goto err;
+	}
 
 	peer->device = wg;
 	wg_noise_handshake_init(&peer->handshake, &wg->static_identity,
@@ -59,40 +69,177 @@ struct wg_peer *wg_peer_create(struct wg_device *wg,
 	list_add_tail(&peer->peer_list, &wg->peer_list);
 	INIT_LIST_HEAD(&peer->allowedips_list);
 	wg_pubkey_hashtable_add(wg->peer_hashtable, peer);
+
+	// TCP field initialization
+	peer->peer_socket = NULL;  // Initialize the peer socket to NULL
+
+	// Initialize the original socket callbacks to NULL
+	peer->original_outbound_state_change = NULL;
+	peer->original_outbound_write_space = NULL;
+	peer->original_outbound_data_ready = NULL;
+	peer->original_outbound_error_report = NULL;
+	peer->original_outbound_destruct = NULL;
+
+	peer->original_inbound_state_change = NULL;
+	peer->original_inbound_write_space = NULL;
+	peer->original_inbound_data_ready = NULL;
+	peer->original_inbound_error_report = NULL;
+	peer->original_inbound_destruct = NULL;
+
+	peer->partial_skb = NULL;  // Initialize the partial skb pointer to NULL
+	peer->expected_len = 0;    // Initialize expected length to 0
+	peer->received_len = 0;    // Initialize received length to 0
+
+	// Initialize the skb queue for queuing TCP packets
+	skb_queue_head_init(&peer->tcp_packet_queue);
+
+	// Initialize the TCP retry scheduled flag to false
+	peer->tcp_retry_scheduled = false;
+
+	// Initialize the delayed work for TCP connection retry
+	INIT_DELAYED_WORK(&peer->tcp_retry_work, wg_tcp_retry_worker);
+
+	// Initialize the delayed work for TCP socket removal
+	INIT_DELAYED_WORK(&peer->tcp_inbound_remove_work, wg_tcp_inbound_remove_worker);
+	INIT_DELAYED_WORK(&peer->tcp_outbound_remove_work, wg_tcp_outbound_remove_worker);
+	
+	// Initialize TCP connection status flags
+	peer->tcp_established = false;
+	peer->tcp_pending = false;
+	peer->tcp_inbound_callbacks_set = false;
+	peer->tcp_outbound_callbacks_set = false;
+	peer->tcp_outbound_remove_scheduled = false;
+	peer->tcp_inbound_remove_scheduled = false;
+	peer->peer_endpoint_set = false;
+
+	// Initialize the spinlock for protecting TCP-related state
+	spin_lock_init(&peer->tcp_lock);
+
+	// Initialize the skb queue for the TX send queue
+	skb_queue_head_init(&peer->send_queue);
+
+	// Initialize the spinlock for the TX send queue
+	spin_lock_init(&peer->send_queue_lock);
+
+	// Initialize the list head for pending connection list
+	INIT_LIST_HEAD(&peer->pending_connection_list);
+
+	// Initialize the work structure, associating it with the worker functions
+	INIT_WORK(&peer->tcp_read_work, wg_tcp_read_worker);
+	// Create a workqueue for processing TCP read data
+	peer->tcp_read_wq = alloc_workqueue("tcp_read_wq", WQ_UNBOUND | WQ_MEM_RECLAIM, 0);
+	if (!peer->tcp_read_wq) {
+        	pr_err("Failed to allocate read workqueue\n");
+		goto err;
+	}
+
+	INIT_WORK(&peer->tcp_write_work, wg_tcp_write_worker);
+	// Create a workqueue for processing TCP write data
+	peer->tcp_write_wq = alloc_workqueue("tcp_write_wq", WQ_UNBOUND | WQ_MEM_RECLAIM, 0);
+	if (!peer->tcp_write_wq) {
+		pr_err("Failed to allocate write workqueue\n");
+		goto err;
+	}
+
+	spin_lock_init(&peer->tcp_transfer_lock);  // Initialize the lock for the tcp_transfer queue
+	peer->tcp_transfer_wq = alloc_workqueue("wg_tcp_transfer_wq", WQ_UNBOUND | WQ_MEM_RECLAIM, 0);
+	if (!peer->tcp_transfer_wq)
+		goto err;
+	
+	// Indicate this is a real peer not a temp peer
+	peer->temp_peer = false;
+	peer->peer_endpoint = peer->endpoint;
+	
 	++wg->num_peers;
+	if (wg->transport == WG_TRANSPORT_TCP)
+		wg_tcp_connect(peer);
 	pr_debug("%s: Peer %llu created\n", wg->dev->name, peer->internal_id);
+	printk(KERN_INFO "wg_peer_create: exit with peer=%p\n", peer);
 	return peer;
 
 err:
 	kmem_cache_free(peer_cache, peer);
+	printk(KERN_INFO "wg_peer_create: exit with ERR_PTR(ret) on err\n");
 	return ERR_PTR(ret);
 }
 
 struct wg_peer *wg_peer_get_maybe_zero(struct wg_peer *peer)
 {
+	printk(KERN_INFO "wg_peer_get_maybe_zero: entry with peer=%p\n", peer);
 	RCU_LOCKDEP_WARN(!rcu_read_lock_bh_held(),
 			 "Taking peer reference without holding the RCU read lock");
-	if (unlikely(!peer || !kref_get_unless_zero(&peer->refcount)))
+	if (unlikely(!peer || !kref_get_unless_zero(&peer->refcount))) {
+		printk(KERN_INFO "wg_peer_get_maybe_zero: exit with NULL\n");
 		return NULL;
+	}
+	printk(KERN_INFO "wg_peer_get_maybe_zero: exit with peer=%p\n", peer);
 	return peer;
 }
 
+
+
 static void peer_make_dead(struct wg_peer *peer)
 {
+	printk(KERN_INFO "peer_make_dead: entry with peer=%p\n", peer);
+	if(!peer || IS_ERR(peer)){
+		printk(KERN_INFO "Exiting function peer_remove_after_dead, no peer.\n");
+		return;
+	}
+
 	/* Remove from configuration-time lookup structures. */
 	list_del_init(&peer->peer_list);
 	wg_allowedips_remove_by_peer(&peer->device->peer_allowedips, peer,
 				     &peer->device->device_update_lock);
 	wg_pubkey_hashtable_remove(peer->device->peer_hashtable, peer);
-
+	
 	/* Mark as dead, so that we don't allow jumping contexts after. */
 	WRITE_ONCE(peer->is_dead, true);
 
+	// Check if the TCP read work is scheduled before canceling it
+	if (peer->tcp_read_worker_scheduled) {
+        	cancel_work_sync(&peer->tcp_read_work);
+        	peer->tcp_read_worker_scheduled = false;  // Reset the flag after canceling
+	}
+
+	// Destroy the TCP read workqueue if it exists
+	if (peer->tcp_read_wq) {
+		destroy_workqueue(peer->tcp_read_wq);
+		peer->tcp_read_wq = NULL; // Avoid dangling pointers
+	}
+
+	// Check if the TCP write work is scheduled before canceling it
+	if (peer->tcp_write_worker_scheduled) {
+		cancel_work_sync(&peer->tcp_write_work);
+		peer->tcp_write_worker_scheduled = false;  // Reset the flag after canceling
+    	}
+
+	// Destroy the TCP write workqueue if it exists
+	if (peer->tcp_write_wq) {
+		destroy_workqueue(peer->tcp_write_wq);
+		peer->tcp_write_wq = NULL; // Avoid dangling pointers
+	}
+
+
+	// Destroy the TCP transfer workqueue if it exists
+    	if (peer->tcp_transfer_wq) {
+        	destroy_workqueue(peer->tcp_transfer_wq);
+		peer->tcp_transfer_wq = NULL; // Avoid dangling pointers
+    	}
+
+	// clean up any partial TCP data if it exists
+	if (peer->partial_skb) {
+		kfree_skb(peer->partial_skb);
+	    	peer->partial_skb = NULL;
+	}	
+
+	
 	/* The caller must now synchronize_net() for this to take effect. */
+	printk(KERN_INFO "peer_make_dead: exit\n");
 }
 
 static void peer_remove_after_dead(struct wg_peer *peer)
 {
+	printk(KERN_INFO "peer_remove_after_dead: entry with peer=%p\n", peer);
 	WARN_ON(!peer->is_dead);
 
 	/* No more keypairs can be created for this peer, since is_dead protects
@@ -147,6 +294,7 @@ static void peer_remove_after_dead(struct wg_peer *peer)
 
 	--peer->device->num_peers;
 	wg_peer_put(peer);
+	printk(KERN_INFO "peer_remove_after_dead: exit\n");
 }
 
 /* We have a separate "remove" function make sure that all active places where
@@ -155,17 +303,23 @@ static void peer_remove_after_dead(struct wg_peer *peer)
  */
 void wg_peer_remove(struct wg_peer *peer)
 {
-	if (unlikely(!peer))
+	printk(KERN_INFO "wg_peer_remove: entry with peer=%p\n", peer);
+	if (unlikely(!peer)) {
+		printk(KERN_INFO "wg_peer_remove: exit (peer is NULL)\n");
 		return;
+	}
 	lockdep_assert_held(&peer->device->device_update_lock);
-
+	wg_clean_peer_socket(peer, true, true, false); // clean up tcp socket stuff
+	wg_clean_peer_socket(peer, true, true, true);  // both inbound and outbound
 	peer_make_dead(peer);
 	synchronize_net();
 	peer_remove_after_dead(peer);
+	printk(KERN_INFO "wg_peer_remove: exit\n");
 }
 
 void wg_peer_remove_all(struct wg_device *wg)
 {
+	printk(KERN_INFO "wg_peer_remove_all: entry with wg=%p\n", wg);
 	struct wg_peer *peer, *temp;
 	LIST_HEAD(dead_peers);
 
@@ -181,10 +335,12 @@ void wg_peer_remove_all(struct wg_device *wg)
 	synchronize_net();
 	list_for_each_entry_safe(peer, temp, &dead_peers, peer_list)
 		peer_remove_after_dead(peer);
+	printk(KERN_INFO "wg_peer_remove_all: exit\n");
 }
 
 static void rcu_release(struct rcu_head *rcu)
 {
+	printk(KERN_INFO "rcu_release: entry with rcu=%p\n", rcu);
 	struct wg_peer *peer = container_of(rcu, struct wg_peer, rcu);
 
 	dst_cache_destroy(&peer->endpoint_cache);
@@ -195,10 +351,12 @@ static void rcu_release(struct rcu_head *rcu)
 	 */
 	memzero_explicit(peer, sizeof(*peer));
 	kmem_cache_free(peer_cache, peer);
+	printk(KERN_INFO "rcu_release: exit\n");
 }
 
 static void kref_release(struct kref *refcount)
 {
+	printk(KERN_INFO "kref_release: entry with refcount=%p\n", refcount);
 	struct wg_peer *peer = container_of(refcount, struct wg_peer, refcount);
 
 	pr_debug("%s: Peer %llu (%pISpfsc) destroyed\n",
@@ -218,22 +376,31 @@ static void kref_release(struct kref *refcount)
 
 	/* Free the memory used. */
 	call_rcu(&peer->rcu, rcu_release);
+	printk(KERN_INFO "kref_release: exit\n");
 }
 
 void wg_peer_put(struct wg_peer *peer)
 {
-	if (unlikely(!peer))
+	printk(KERN_INFO "wg_peer_put: entry with peer=%p\n", peer);
+	if (unlikely(!peer)) {
+		printk(KERN_INFO "wg_peer_put: exit (peer is NULL)\n");
 		return;
+	}
 	kref_put(&peer->refcount, kref_release);
+	printk(KERN_INFO "wg_peer_put: exit\n");
 }
 
 int __init wg_peer_init(void)
 {
+	printk(KERN_INFO "wg_peer_init: entry\n");
 	peer_cache = KMEM_CACHE(wg_peer, 0);
+	printk(KERN_INFO "wg_peer_init: exit with %d\n", peer_cache ? 0 : -ENOMEM);
 	return peer_cache ? 0 : -ENOMEM;
 }
 
 void wg_peer_uninit(void)
 {
+	printk(KERN_INFO "wg_peer_uninit: entry\n");
 	kmem_cache_destroy(peer_cache);
+	printk(KERN_INFO "wg_peer_uninit: exit\n");
 }
diff --git a/wireguard-linux/drivers/net/wireguard/peer.h b/wireguard-linux/drivers/net/wireguard/peer.h
index 76e4d3128ad4..96d5648812ab 100644
--- a/wireguard-linux/drivers/net/wireguard/peer.h
+++ b/wireguard-linux/drivers/net/wireguard/peer.h
@@ -18,20 +18,11 @@
 
 struct wg_device;
 
-struct endpoint {
-	union {
-		struct sockaddr addr;
-		struct sockaddr_in addr4;
-		struct sockaddr_in6 addr6;
-	};
-	union {
-		struct {
-			struct in_addr src4;
-			/* Essentially the same as addr6->scope_id */
-			int src_if4;
-		};
-		struct in6_addr src6;
-	};
+
+struct wg_tcp_transfer_work {
+    struct work_struct work;
+    struct sk_buff *skb;
+    struct wg_peer *peer;
 };
 
 struct wg_peer {
@@ -41,7 +32,7 @@ struct wg_peer {
 	int serial_work_cpu;
 	bool is_dead;
 	struct noise_keypairs keypairs;
-	struct endpoint endpoint;
+	struct endpoint endpoint, tcp_reply_endpoint, peer_endpoint;
 	struct dst_cache endpoint_cache;
 	rwlock_t endpoint_lock;
 	struct noise_handshake handshake;
@@ -64,8 +55,74 @@ struct wg_peer {
 	struct list_head allowedips_list;
 	struct napi_struct napi;
 	u64 internal_id;
+
+        // TCP-related members
+	bool peer_endpoint_set;
+	struct socket *peer_socket, *inbound_socket, *outbound_socket;
+	void (*original_outbound_state_change)(struct sock *sk);
+	void (*original_outbound_write_space)(struct sock *sk);
+	void (*original_outbound_data_ready)(struct sock *sk);
+	void (*original_outbound_error_report)(struct sock *sk);
+	void (*original_outbound_destruct)(struct sock *sk);
+	void (*original_inbound_state_change)(struct sock *sk);
+	void (*original_inbound_write_space)(struct sock *sk);
+	void (*original_inbound_data_ready)(struct sock *sk);
+	void (*original_inbound_error_report)(struct sock *sk);
+	void (*original_inbound_destruct)(struct sock *sk);
+	bool tcp_outbound_callbacks_set;			// Flag to track if the inbound socket callbacks have been set
+	bool tcp_inbound_callbacks_set;				// Flag to track if the inbound socket callbacks have been set
+	ktime_t outbound_timestamp, inbound_timestamp;	// timestamps for connections
+	struct sockaddr_storage	inbound_source, outbound_source, inbound_dest, outbound_dest;
+
+	struct sk_buff *partial_skb;
+	size_t expected_len;
+	size_t received_len;
+	struct sk_buff_head tcp_packet_queue;	// For queuing TCP packets
+
+	struct delayed_work tcp_retry_work;	// Work for retrying TCP connection
+	bool tcp_retry_scheduled;		// Flag to track connect retry scheduling
+
+	struct delayed_work tcp_outbound_remove_work;	// Work for removing outbound peer TCP connection
+	bool tcp_outbound_remove_scheduled;		// Flag to track outbound peer removal scheduling
+	struct delayed_work tcp_inbound_remove_work;	// Work for removing inbound peer TCP connection
+	bool tcp_inbound_remove_scheduled;		// Flag to track inbound peer removal scheduling
+
+	struct delayed_work tcp_cleanup_work;	// Work for removing TCP connections in pending list
+	bool tcp_cleanup_scheduled;		// Flag to track removal scheduling
+
+	bool tcp_established;			// Flag to track TCP connection status
+	bool tcp_pending;			// Flag to track outbount pending TCP connection status
+	bool inbound_connected;			// peer connected to us
+	bool outbound_connected;		// we connected to them
+	bool clean_outbound;			// release outbound at next cleanup
+	bool clean_inbound;			// release inbound at next cleanup
+	bool temp_peer;				// is this a temporary peer
+
+
+	struct sk_buff_head send_queue;		// TX queue
+        spinlock_t send_queue_lock;		// TX lock
+
+	struct list_head pending_connection_list;	//peers pending connection handshake
+	spinlock_t tcp_lock;			// Protects TCP-related state
+
+	struct work_struct tcp_read_work;	// Work struct for scheduling the worker
+	struct workqueue_struct *tcp_read_wq;	// Workqueue for handling TCP data processing
+	spinlock_t tcp_read_lock;		// Spinlock to protect access to the socket data
+	bool tcp_read_worker_scheduled;		// Flag to indicate if the TCP read worker is scheduled
+
+	struct work_struct tcp_write_work;      // Work struct for scheduling the worker
+	struct workqueue_struct *tcp_write_wq;	// Workqueue for handling TCP data processing
+	spinlock_t tcp_write_lock;              // Spinlock to protect access to the socket data
+	bool tcp_write_worker_scheduled; 	// Flag to indicate if the TCP write worker is scheduled
+
+	struct work_struct tcp_transfer_work;		// Work struct for scheduling the worker
+	struct workqueue_struct *tcp_transfer_wq;	// Workqueue for handling TCP data processing
+	spinlock_t tcp_transfer_lock;			// Spinlock to protect access to the socket data
+	bool tcp_transfer_worker_scheduled;		// Flag to indicate if the TCP transfer worker is scheduled
 };
 
+
+
 struct wg_peer *wg_peer_create(struct wg_device *wg,
 			       const u8 public_key[NOISE_PUBLIC_KEY_LEN],
 			       const u8 preshared_key[NOISE_SYMMETRIC_KEY_LEN]);
@@ -83,4 +140,12 @@ void wg_peer_remove_all(struct wg_device *wg);
 int wg_peer_init(void);
 void wg_peer_uninit(void);
 
+void wg_peer_tcp_connect(struct work_struct *work);
+void wg_peer_tcp_send(struct work_struct *work);
+void wg_peer_tcp_receive(struct work_struct *work);
+void wg_tcp_inbound_remove_worker(struct work_struct *work);
+void wg_tcp_outbound_remove_worker(struct work_struct *work);
+
+void wg_tcp_retry_worker(struct work_struct *work);
+
 #endif /* _WG_PEER_H */
diff --git a/wireguard-linux/drivers/net/wireguard/peerlookup.c b/wireguard-linux/drivers/net/wireguard/peerlookup.c
index f2783aa7a88f..50964ba2d4ed 100644
--- a/wireguard-linux/drivers/net/wireguard/peerlookup.c
+++ b/wireguard-linux/drivers/net/wireguard/peerlookup.c
@@ -10,43 +10,52 @@
 static struct hlist_head *pubkey_bucket(struct pubkey_hashtable *table,
 					const u8 pubkey[NOISE_PUBLIC_KEY_LEN])
 {
+	printk(KERN_INFO "Entering pubkey_bucket: table=%p, pubkey=%*phN\n", table, NOISE_PUBLIC_KEY_LEN, pubkey);
 	/* siphash gives us a secure 64bit number based on a random key. Since
 	 * the bits are uniformly distributed, we can then mask off to get the
 	 * bits we need.
 	 */
 	const u64 hash = siphash(pubkey, NOISE_PUBLIC_KEY_LEN, &table->key);
-
+	printk(KERN_INFO "Exiting pubkey_bucket\n");
 	return &table->hashtable[hash & (HASH_SIZE(table->hashtable) - 1)];
 }
 
 struct pubkey_hashtable *wg_pubkey_hashtable_alloc(void)
 {
+	printk(KERN_INFO "Entering wg_pubkey_hashtable_alloc\n");
 	struct pubkey_hashtable *table = kvmalloc(sizeof(*table), GFP_KERNEL);
 
-	if (!table)
+	if (!table) {
+		printk(KERN_INFO "Exiting wg_pubkey_hashtable_alloc: NULL\n");
 		return NULL;
+	}
 
 	get_random_bytes(&table->key, sizeof(table->key));
 	hash_init(table->hashtable);
 	mutex_init(&table->lock);
+	printk(KERN_INFO "Exiting wg_pubkey_hashtable_alloc: table=%p\n", table);
 	return table;
 }
 
 void wg_pubkey_hashtable_add(struct pubkey_hashtable *table,
 			     struct wg_peer *peer)
 {
+	printk(KERN_INFO "Entering wg_pubkey_hashtable_add: table=%p, peer=%p\n", table, peer);
 	mutex_lock(&table->lock);
 	hlist_add_head_rcu(&peer->pubkey_hash,
 			   pubkey_bucket(table, peer->handshake.remote_static));
 	mutex_unlock(&table->lock);
+	printk(KERN_INFO "Exiting wg_pubkey_hashtable_add\n");
 }
 
 void wg_pubkey_hashtable_remove(struct pubkey_hashtable *table,
 				struct wg_peer *peer)
 {
+	printk(KERN_INFO "Entering wg_pubkey_hashtable_remove: table=%p, peer=%p\n", table, peer);
 	mutex_lock(&table->lock);
 	hlist_del_init_rcu(&peer->pubkey_hash);
 	mutex_unlock(&table->lock);
+	printk(KERN_INFO "Exiting wg_pubkey_hashtable_remove\n");
 }
 
 /* Returns a strong reference to a peer */
@@ -54,6 +63,7 @@ struct wg_peer *
 wg_pubkey_hashtable_lookup(struct pubkey_hashtable *table,
 			   const u8 pubkey[NOISE_PUBLIC_KEY_LEN])
 {
+	printk(KERN_INFO "Entering wg_pubkey_hashtable_lookup: table=%p, pubkey=%*phN\n", table, NOISE_PUBLIC_KEY_LEN, pubkey);
 	struct wg_peer *iter_peer, *peer = NULL;
 
 	rcu_read_lock_bh();
@@ -67,28 +77,35 @@ wg_pubkey_hashtable_lookup(struct pubkey_hashtable *table,
 	}
 	peer = wg_peer_get_maybe_zero(peer);
 	rcu_read_unlock_bh();
+	printk(KERN_INFO "Exiting wg_pubkey_hashtable_lookup: peer=%p\n", peer);
 	return peer;
 }
 
 static struct hlist_head *index_bucket(struct index_hashtable *table,
 				       const __le32 index)
 {
+	printk(KERN_INFO "Entering index_bucket: table=%p, index=%u\n", table, index);
 	/* Since the indices are random and thus all bits are uniformly
 	 * distributed, we can find its bucket simply by masking.
 	 */
+	printk(KERN_INFO "Exiting index_bucket\n");
 	return &table->hashtable[(__force u32)index &
 				 (HASH_SIZE(table->hashtable) - 1)];
 }
 
 struct index_hashtable *wg_index_hashtable_alloc(void)
 {
+	printk(KERN_INFO "Entering wg_index_hashtable_alloc\n");
 	struct index_hashtable *table = kvmalloc(sizeof(*table), GFP_KERNEL);
 
-	if (!table)
+	if (!table) {
+		printk(KERN_INFO "Exiting wg_index_hashtable_alloc: NULL\n");
 		return NULL;
+	}
 
 	hash_init(table->hashtable);
 	spin_lock_init(&table->lock);
+	printk(KERN_INFO "Exiting wg_index_hashtable_alloc: table=%p\n", table);
 	return table;
 }
 
@@ -115,10 +132,10 @@ struct index_hashtable *wg_index_hashtable_alloc(void)
  * guessing. this would not, however, help with the growing hash lengths, which
  * is another thing to consider moving forward.
  */
-
 __le32 wg_index_hashtable_insert(struct index_hashtable *table,
 				 struct index_hashtable_entry *entry)
 {
+	printk(KERN_INFO "Entering wg_index_hashtable_insert: table=%p, entry=%p\n", table, entry);
 	struct index_hashtable_entry *existing_entry;
 
 	spin_lock_bh(&table->lock);
@@ -159,7 +176,7 @@ __le32 wg_index_hashtable_insert(struct index_hashtable *table,
 	spin_unlock_bh(&table->lock);
 
 	rcu_read_unlock_bh();
-
+	printk(KERN_INFO "Exiting wg_index_hashtable_insert: index=%u\n", entry->index);
 	return entry->index;
 }
 
@@ -167,6 +184,7 @@ bool wg_index_hashtable_replace(struct index_hashtable *table,
 				struct index_hashtable_entry *old,
 				struct index_hashtable_entry *new)
 {
+	printk(KERN_INFO "Entering wg_index_hashtable_replace: table=%p, old=%p, new=%p\n", table, old, new);
 	bool ret;
 
 	spin_lock_bh(&table->lock);
@@ -186,15 +204,18 @@ bool wg_index_hashtable_replace(struct index_hashtable *table,
 	INIT_HLIST_NODE(&old->index_hash);
 out:
 	spin_unlock_bh(&table->lock);
+	printk(KERN_INFO "Exiting wg_index_hashtable_replace: ret=%d\n", ret);
 	return ret;
 }
 
 void wg_index_hashtable_remove(struct index_hashtable *table,
 			       struct index_hashtable_entry *entry)
 {
+	printk(KERN_INFO "Entering wg_index_hashtable_remove: table=%p, entry=%p\n", table, entry);
 	spin_lock_bh(&table->lock);
 	hlist_del_init_rcu(&entry->index_hash);
 	spin_unlock_bh(&table->lock);
+	printk(KERN_INFO "Exiting wg_index_hashtable_remove\n");
 }
 
 /* Returns a strong reference to a entry->peer */
@@ -203,6 +224,7 @@ wg_index_hashtable_lookup(struct index_hashtable *table,
 			  const enum index_hashtable_type type_mask,
 			  const __le32 index, struct wg_peer **peer)
 {
+	printk(KERN_INFO "Entering wg_index_hashtable_lookup: table=%p, type_mask=%u, index=%u, peer=%p\n", table, type_mask, index, peer);
 	struct index_hashtable_entry *iter_entry, *entry = NULL;
 
 	rcu_read_lock_bh();
@@ -222,5 +244,6 @@ wg_index_hashtable_lookup(struct index_hashtable *table,
 			entry = NULL;
 	}
 	rcu_read_unlock_bh();
+	printk(KERN_INFO "Exiting wg_index_hashtable_lookup: entry=%p\n", entry);
 	return entry;
 }
diff --git a/wireguard-linux/drivers/net/wireguard/queueing.c b/wireguard-linux/drivers/net/wireguard/queueing.c
index 26d235d15235..8f719dd8a472 100644
--- a/wireguard-linux/drivers/net/wireguard/queueing.c
+++ b/wireguard-linux/drivers/net/wireguard/queueing.c
@@ -12,6 +12,8 @@ wg_packet_percpu_multicore_worker_alloc(work_func_t function, void *ptr)
 	int cpu;
 	struct multicore_worker __percpu *worker = alloc_percpu(struct multicore_worker);
 
+	printk(KERN_INFO "Entering: wg_packet_percpu_multicore_worker_alloc with function=%p, ptr=%p\n", function, ptr);
+
 	if (!worker)
 		return NULL;
 
@@ -19,32 +21,44 @@ wg_packet_percpu_multicore_worker_alloc(work_func_t function, void *ptr)
 		per_cpu_ptr(worker, cpu)->ptr = ptr;
 		INIT_WORK(&per_cpu_ptr(worker, cpu)->work, function);
 	}
+
+	printk(KERN_INFO "Exiting: wg_packet_percpu_multicore_worker_alloc with worker=%p\n", worker);
 	return worker;
 }
 
-int wg_packet_queue_init(struct crypt_queue *queue, work_func_t function,
-			 unsigned int len)
+int wg_packet_queue_init(struct crypt_queue *queue, work_func_t function, unsigned int len)
 {
 	int ret;
 
+	printk(KERN_INFO "Entering: wg_packet_queue_init with queue=%p, function=%p, len=%u\n", queue, function, len);
+
 	memset(queue, 0, sizeof(*queue));
 	queue->last_cpu = -1;
 	ret = ptr_ring_init(&queue->ring, len, GFP_KERNEL);
-	if (ret)
+	if (ret) {
+		printk(KERN_INFO "Exiting: wg_packet_queue_init with ret=%d\n", ret);
 		return ret;
+	}
 	queue->worker = wg_packet_percpu_multicore_worker_alloc(function, queue);
 	if (!queue->worker) {
 		ptr_ring_cleanup(&queue->ring, NULL);
+		printk(KERN_INFO "Exiting: wg_packet_queue_init with ret=%d\n", -ENOMEM);
 		return -ENOMEM;
 	}
+
+	printk(KERN_INFO "Exiting: wg_packet_queue_init with ret=0\n");
 	return 0;
 }
 
 void wg_packet_queue_free(struct crypt_queue *queue, bool purge)
 {
+	printk(KERN_INFO "Entering: wg_packet_queue_free with queue=%p, purge=%d\n", queue, purge);
+
 	free_percpu(queue->worker);
 	WARN_ON(!purge && !__ptr_ring_empty(&queue->ring));
 	ptr_ring_cleanup(&queue->ring, purge ? __skb_array_destroy_skb : NULL);
+
+	printk(KERN_INFO "Exiting: wg_packet_queue_free\n");
 }
 
 #define NEXT(skb) ((skb)->prev)
@@ -52,6 +66,8 @@ void wg_packet_queue_free(struct crypt_queue *queue, bool purge)
 
 void wg_prev_queue_init(struct prev_queue *queue)
 {
+	printk(KERN_INFO "Entering: wg_prev_queue_init with queue=%p\n", queue);
+
 	NEXT(STUB(queue)) = NULL;
 	queue->head = queue->tail = STUB(queue);
 	queue->peeked = NULL;
@@ -61,19 +77,31 @@ void wg_prev_queue_init(struct prev_queue *queue)
 							offsetof(struct prev_queue, empty) ||
 		offsetof(struct sk_buff, prev) != offsetof(struct prev_queue, empty.prev) -
 							 offsetof(struct prev_queue, empty));
+
+	printk(KERN_INFO "Exiting: wg_prev_queue_init\n");
 }
 
 static void __wg_prev_queue_enqueue(struct prev_queue *queue, struct sk_buff *skb)
 {
+	printk(KERN_INFO "Entering: __wg_prev_queue_enqueue with queue=%p, skb=%p\n", queue, skb);
+
 	WRITE_ONCE(NEXT(skb), NULL);
 	WRITE_ONCE(NEXT(xchg_release(&queue->head, skb)), skb);
+
+	printk(KERN_INFO "Exiting: __wg_prev_queue_enqueue\n");
 }
 
 bool wg_prev_queue_enqueue(struct prev_queue *queue, struct sk_buff *skb)
 {
-	if (!atomic_add_unless(&queue->count, 1, MAX_QUEUED_PACKETS))
+	printk(KERN_INFO "Entering: wg_prev_queue_enqueue with queue=%p, skb=%p\n", queue, skb);
+
+	if (!atomic_add_unless(&queue->count, 1, MAX_QUEUED_PACKETS)) {
+		printk(KERN_INFO "Exiting: wg_prev_queue_enqueue with ret=%d\n", false);
 		return false;
+	}
 	__wg_prev_queue_enqueue(queue, skb);
+
+	printk(KERN_INFO "Exiting: wg_prev_queue_enqueue with ret=%d\n", true);
 	return true;
 }
 
@@ -81,9 +109,13 @@ struct sk_buff *wg_prev_queue_dequeue(struct prev_queue *queue)
 {
 	struct sk_buff *tail = queue->tail, *next = smp_load_acquire(&NEXT(tail));
 
+	printk(KERN_INFO "Entering: wg_prev_queue_dequeue with queue=%p\n", queue);
+
 	if (tail == STUB(queue)) {
-		if (!next)
+		if (!next) {
+			printk(KERN_INFO "Exiting: wg_prev_queue_dequeue with ret=%p\n", NULL);
 			return NULL;
+		}
 		queue->tail = next;
 		tail = next;
 		next = smp_load_acquire(&NEXT(next));
@@ -91,17 +123,23 @@ struct sk_buff *wg_prev_queue_dequeue(struct prev_queue *queue)
 	if (next) {
 		queue->tail = next;
 		atomic_dec(&queue->count);
+		printk(KERN_INFO "Exiting: wg_prev_queue_dequeue with ret=%p\n", tail);
 		return tail;
 	}
-	if (tail != READ_ONCE(queue->head))
+	if (tail != READ_ONCE(queue->head)) {
+		printk(KERN_INFO "Exiting: wg_prev_queue_dequeue with ret=%p\n", NULL);
 		return NULL;
+	}
 	__wg_prev_queue_enqueue(queue, STUB(queue));
 	next = smp_load_acquire(&NEXT(tail));
 	if (next) {
 		queue->tail = next;
 		atomic_dec(&queue->count);
+		printk(KERN_INFO "Exiting: wg_prev_queue_dequeue with ret=%p\n", tail);
 		return tail;
 	}
+
+	printk(KERN_INFO "Exiting: wg_prev_queue_dequeue with ret=%p\n", NULL);
 	return NULL;
 }
 
diff --git a/wireguard-linux/drivers/net/wireguard/queueing.h b/wireguard-linux/drivers/net/wireguard/queueing.h
index 1ea4f874e367..377c0dcdc908 100644
--- a/wireguard-linux/drivers/net/wireguard/queueing.h
+++ b/wireguard-linux/drivers/net/wireguard/queueing.h
@@ -11,6 +11,7 @@
 #include <linux/skbuff.h>
 #include <linux/ip.h>
 #include <linux/ipv6.h>
+#include <linux/wireguard.h>
 #include <net/ip_tunnels.h>
 
 struct wg_device;
@@ -75,6 +76,7 @@ static inline bool wg_check_packet_protocol(struct sk_buff *skb)
 
 static inline void wg_reset_packet(struct sk_buff *skb, bool encapsulating)
 {
+	printk(KERN_INFO "Entering wg_reset_packet\n");
 	u8 l4_hash = skb->l4_hash;
 	u8 sw_hash = skb->sw_hash;
 	u32 hash = skb->hash;
@@ -100,6 +102,8 @@ static inline void wg_reset_packet(struct sk_buff *skb, bool encapsulating)
 	skb_reset_transport_header(skb);
 	skb_probe_transport_header(skb);
 	skb_reset_inner_headers(skb);
+
+	printk(KERN_INFO "Exiting wg_reset_packet\n");
 }
 
 static inline int wg_cpumask_choose_online(int *stored_cpu, unsigned int id)
@@ -159,7 +163,7 @@ static inline int wg_queue_enqueue_per_device_and_peer(
 	struct sk_buff *skb, struct workqueue_struct *wq)
 {
 	int cpu;
-
+	printk(KERN_INFO "Entering wg_queue_enqueue_per_device_and_peer \n");
 	atomic_set_release(&PACKET_CB(skb)->state, PACKET_STATE_UNCRYPTED);
 	/* We first queue this up for the peer ingestion, but the consumer
 	 * will wait for the state to change to CRYPTED or DEAD before.
@@ -174,11 +178,13 @@ static inline int wg_queue_enqueue_per_device_and_peer(
 	if (unlikely(ptr_ring_produce_bh(&device_queue->ring, skb)))
 		return -EPIPE;
 	queue_work_on(cpu, wq, &per_cpu_ptr(device_queue->worker, cpu)->work);
+	printk(KERN_INFO "Exiting wg_queue_enqueue_per_device_and_peer \n");
 	return 0;
 }
 
 static inline void wg_queue_enqueue_per_peer_tx(struct sk_buff *skb, enum packet_state state)
 {
+	printk(KERN_INFO "Entering wg_queue_enqueue_per_peer_tx \n");
 	/* We take a reference, because as soon as we call atomic_set, the
 	 * peer can be freed from below us.
 	 */
@@ -188,10 +194,12 @@ static inline void wg_queue_enqueue_per_peer_tx(struct sk_buff *skb, enum packet
 	queue_work_on(wg_cpumask_choose_online(&peer->serial_work_cpu, peer->internal_id),
 		      peer->device->packet_crypt_wq, &peer->transmit_packet_work);
 	wg_peer_put(peer);
+	printk(KERN_INFO "Exiting wg_queue_enqueue_per_peer_tx\n");
 }
 
 static inline void wg_queue_enqueue_per_peer_rx(struct sk_buff *skb, enum packet_state state)
 {
+	printk(KERN_INFO "Entering wg_queue_enqueue_per_peer_rx \n");
 	/* We take a reference, because as soon as we call atomic_set, the
 	 * peer can be freed from below us.
 	 */
@@ -200,6 +208,7 @@ static inline void wg_queue_enqueue_per_peer_rx(struct sk_buff *skb, enum packet
 	atomic_set_release(&PACKET_CB(skb)->state, state);
 	napi_schedule(&peer->napi);
 	wg_peer_put(peer);
+	printk(KERN_INFO "Exiting wg_queue_enqueue_per_peer_rx\n");
 }
 
 #ifdef DEBUG
diff --git a/wireguard-linux/drivers/net/wireguard/ratelimiter.c b/wireguard-linux/drivers/net/wireguard/ratelimiter.c
index dd55e5c26f46..cf679d9a0b20 100644
--- a/wireguard-linux/drivers/net/wireguard/ratelimiter.c
+++ b/wireguard-linux/drivers/net/wireguard/ratelimiter.c
@@ -40,6 +40,7 @@ enum {
 
 static void entry_free(struct rcu_head *rcu)
 {
+	printk(KERN_INFO "entry_free: entry_cache=%p, rcu=%p\n", entry_cache, rcu);
 	kmem_cache_free(entry_cache,
 			container_of(rcu, struct ratelimiter_entry, rcu));
 	atomic_dec(&total_entries);
@@ -47,6 +48,7 @@ static void entry_free(struct rcu_head *rcu)
 
 static void entry_uninit(struct ratelimiter_entry *entry)
 {
+	printk(KERN_INFO "entry_uninit: entry=%p\n", entry);
 	hlist_del_rcu(&entry->hash);
 	call_rcu(&entry->rcu, entry_free);
 }
@@ -54,6 +56,7 @@ static void entry_uninit(struct ratelimiter_entry *entry)
 /* Calling this function with a NULL work uninits all entries. */
 static void wg_ratelimiter_gc_entries(struct work_struct *work)
 {
+	//printk(KERN_INFO "wg_ratelimiter_gc_entries: work=%p\n", work);
 	const u64 now = ktime_get_coarse_boottime_ns();
 	struct ratelimiter_entry *entry;
 	struct hlist_node *temp;
@@ -79,10 +82,12 @@ static void wg_ratelimiter_gc_entries(struct work_struct *work)
 	}
 	if (likely(work))
 		queue_delayed_work(system_power_efficient_wq, &gc_work, HZ);
+	//printk(KERN_INFO "wg_ratelimiter_gc_entries: exit\n");
 }
 
 bool wg_ratelimiter_allow(struct sk_buff *skb, struct net *net)
 {
+	printk(KERN_INFO "wg_ratelimiter_allow: skb=%p, net=%p\n", skb, net);
 	/* We only take the bottom half of the net pointer, so that we can hash
 	 * 3 words in the end. This way, siphash's len param fits into the final
 	 * u32, and we don't incur an extra round.
@@ -127,6 +132,7 @@ bool wg_ratelimiter_allow(struct sk_buff *skb, struct net *net)
 			entry->tokens = ret ? tokens - PACKET_COST : tokens;
 			spin_unlock(&entry->lock);
 			rcu_read_unlock();
+			printk(KERN_INFO "wg_ratelimiter_allow: exit ret=%d\n", ret);
 			return ret;
 		}
 	}
@@ -148,15 +154,18 @@ bool wg_ratelimiter_allow(struct sk_buff *skb, struct net *net)
 	spin_lock(&table_lock);
 	hlist_add_head_rcu(&entry->hash, bucket);
 	spin_unlock(&table_lock);
+	printk(KERN_INFO "wg_ratelimiter_allow: exit true\n");
 	return true;
 
 err_oom:
 	atomic_dec(&total_entries);
+	printk(KERN_INFO "wg_ratelimiter_allow: exit false\n");
 	return false;
 }
 
 int wg_ratelimiter_init(void)
 {
+	printk(KERN_INFO "wg_ratelimiter_init: enter\n");
 	mutex_lock(&init_lock);
 	if (++init_refcnt != 1)
 		goto out;
@@ -192,6 +201,7 @@ int wg_ratelimiter_init(void)
 	get_random_bytes(&key, sizeof(key));
 out:
 	mutex_unlock(&init_lock);
+	printk(KERN_INFO "wg_ratelimiter_init: exit 0\n");
 	return 0;
 
 err_kmemcache:
@@ -199,11 +209,13 @@ int wg_ratelimiter_init(void)
 err:
 	--init_refcnt;
 	mutex_unlock(&init_lock);
+	printk(KERN_INFO "wg_ratelimiter_init: exit -ENOMEM\n");
 	return -ENOMEM;
 }
 
 void wg_ratelimiter_uninit(void)
 {
+	printk(KERN_INFO "wg_ratelimiter_uninit: enter\n");
 	mutex_lock(&init_lock);
 	if (!init_refcnt || --init_refcnt)
 		goto out;
@@ -218,6 +230,7 @@ void wg_ratelimiter_uninit(void)
 	kmem_cache_destroy(entry_cache);
 out:
 	mutex_unlock(&init_lock);
+	printk(KERN_INFO "wg_ratelimiter_uninit: exit\n");
 }
 
 #include "selftest/ratelimiter.c"
diff --git a/wireguard-linux/drivers/net/wireguard/receive.c b/wireguard-linux/drivers/net/wireguard/receive.c
index 9434f6e5c28a..1705b09a92cf 100644
--- a/wireguard-linux/drivers/net/wireguard/receive.c
+++ b/wireguard-linux/drivers/net/wireguard/receive.c
@@ -13,8 +13,35 @@
 
 #include <linux/ip.h>
 #include <linux/ipv6.h>
+#include <linux/tcp.h>
 #include <linux/udp.h>
 #include <net/ip_tunnels.h>
+#include <linux/skbuff.h>
+#include <linux/net.h>
+#include <linux/in.h>
+#include <linux/ipv6.h>
+#include <net/ipv6.h>
+#include <net/ip.h>
+
+#define WG_TRANSPORT_UDP	0
+#define WG_TRANSPORT_TCP	1
+bool endpoint_eq(const struct endpoint *a, const struct endpoint *b);
+void log_wireguard_endpoint(struct endpoint *ep);
+
+struct wg_tcp_socket_list_entry {
+	struct socket *tcp_socket;		// Socket associated with the connection
+	struct sockaddr_storage src_addr;	// Source address for the connection
+	struct wg_peer *temp_peer;		// temporary peer for dataready
+	struct list_head tcp_connection_ll;	// List pointer for the linked list
+	ktime_t timestamp;			// Timestamp when the connection was added
+};
+
+struct wg_socket_data {
+	struct wg_device *device;
+	struct wg_peer *peer;
+	bool inbound;
+};
+
 
 /* Must be called with bh disabled. */
 static void update_rx_stats(struct wg_peer *peer, size_t len)
@@ -25,36 +52,165 @@ static void update_rx_stats(struct wg_peer *peer, size_t len)
 	printk(KERN_INFO "Exiting update_rx_stats\n");
 }
 
+#ifdef DIAGNOSTIC
+#define WG_PACKET_TYPE_HANDSHAKE_INIT 1
+#define WG_PACKET_TYPE_HANDSHAKE_RESP 2
+#define WG_PACKET_TYPE_COOKIE_REPLY 3
+#define WG_PACKET_TYPE_TRANSPORT_DATA 4
+
+static void wg_print_wireguard_skb(struct sk_buff *skb)
+{
+    if (!skb)
+        return;
+    // Extract the WireGuard packet data directly from skb->data
+    wg_print_wireguard_skb(skb->data, skb->len);
+}
+
+static void wg_print_wireguard_packet(unsigned char *data, size_t payload_len)
+{
+	u32 message_type;
+	u64 receiver_nonce;
+	u64 message_counter;
+	size_t i;
+
+	// Get the message type (1st 4 bytes)
+	message_type = ntohl(*(u32 *)data);
+
+	// Print the message type
+	switch (message_type) {
+	case WG_PACKET_TYPE_HANDSHAKE_INIT:
+		printk(KERN_INFO "WireGuard packet: Handshake Initiation\n");
+		break;
+	case WG_PACKET_TYPE_HANDSHAKE_RESP:
+		printk(KERN_INFO "WireGuard packet: Handshake Response\n");
+		break;
+	case WG_PACKET_TYPE_COOKIE_REPLY:
+		printk(KERN_INFO "WireGuard packet: Cookie Reply\n");
+		break;
+	case WG_PACKET_TYPE_TRANSPORT_DATA:
+		printk(KERN_INFO "WireGuard packet: Transport Data\n");
+		break;
+	default:
+		printk(KERN_INFO "WireGuard packet: Unknown Type (%u)\n", message_type);
+		return;
+	}
+
+	// For Handshake Init/Resp and Transport Data packets, print additional fields
+	if (message_type == WG_PACKET_TYPE_HANDSHAKE_INIT ||
+		message_type == WG_PACKET_TYPE_HANDSHAKE_RESP ||
+		message_type == WG_PACKET_TYPE_TRANSPORT_DATA) {
+
+		// Get the receiver nonce (next 8 bytes)
+		receiver_nonce = be64_to_cpu(*(u64 *)(data + sizeof(u32)));
+
+		// Print the receiver nonce
+		printk(KERN_INFO "Receiver Nonce: 0x%016llx\n", receiver_nonce);
+
+		// If it's a Transport Data packet, also get and print the message counter (next 8 bytes)
+		if (message_type == WG_PACKET_TYPE_TRANSPORT_DATA) {
+			message_counter = be64_to_cpu(*(u64 *)(data + sizeof(u32) + sizeof(u64)));
+			printk(KERN_INFO "Message Counter: 0x%016llx\n", message_counter);
+		}
+	}
+
+	// Print the entire packet data in hex, 32 bytes per line
+	printk(KERN_INFO "Packet Data:\n");
+	for (i = 0; i < payload_len; i += 32) {
+		size_t len = (i + 32 <= payload_len) ? 32 : payload_len - i;
+		printk(KERN_INFO "%*ph\n", (int)len, data + i);
+	}
+}
+#endif // DIAGNOSTIC
+
 #define SKB_TYPE_LE32(skb) (((struct message_header *)(skb)->data)->type)
 
+#ifdef ORIGINAL
 static size_t validate_header_len(struct sk_buff *skb)
 {
 	printk(KERN_INFO "Entering validate_header_len: skb=%p\n", skb);
-	if (unlikely(skb->len < sizeof(struct message_header))) {
-		printk(KERN_INFO "Exiting validate_header_len: ret=0\n");
+	if (unlikely(skb->len < sizeof(struct message_header)))
 		return 0;
-	}
 	if (SKB_TYPE_LE32(skb) == cpu_to_le32(MESSAGE_DATA) &&
-	    skb->len >= MESSAGE_MINIMUM_LENGTH) {
-		printk(KERN_INFO "Exiting validate_header_len: ret=%zu\n", sizeof(struct message_data));
+	    skb->len >= MESSAGE_MINIMUM_LENGTH)
 		return sizeof(struct message_data);
-	}
 	if (SKB_TYPE_LE32(skb) == cpu_to_le32(MESSAGE_HANDSHAKE_INITIATION) &&
-	    skb->len == sizeof(struct message_handshake_initiation)) {
-		printk(KERN_INFO "Exiting validate_header_len: ret=%zu\n", sizeof(struct message_handshake_initiation));
+	    skb->len == sizeof(struct message_handshake_initiation))
 		return sizeof(struct message_handshake_initiation);
-	}
 	if (SKB_TYPE_LE32(skb) == cpu_to_le32(MESSAGE_HANDSHAKE_RESPONSE) &&
-	    skb->len == sizeof(struct message_handshake_response)) {
-		printk(KERN_INFO "Exiting validate_header_len: ret=%zu\n", sizeof(struct message_handshake_response));
+	    skb->len == sizeof(struct message_handshake_response))
 		return sizeof(struct message_handshake_response);
-	}
 	if (SKB_TYPE_LE32(skb) == cpu_to_le32(MESSAGE_HANDSHAKE_COOKIE) &&
-	    skb->len == sizeof(struct message_handshake_cookie)) {
-		printk(KERN_INFO "Exiting validate_header_len: ret=%zu\n", sizeof(struct message_handshake_cookie));
+	    skb->len == sizeof(struct message_handshake_cookie))
 		return sizeof(struct message_handshake_cookie);
+	printk(KERN_INFO "Exiting validate_header_len\n");
+	return 0;
+}
+#endif // ORIGINAL
+
+static size_t validate_header_len(struct sk_buff *skb)
+{
+	printk(KERN_INFO "Entering validate_header_len: skb=%p\n", skb);
+	printk(KERN_INFO "SKB state: len=%d, head=%p, data=%p, tail=%p, end=%p\n",
+		skb->len, skb->head, skb->data, (void *)skb->tail, (void *)skb->end);
+	
+	printk(KERN_INFO "sizeof(struct message_header)=%zu\n", sizeof(struct message_header));
+	if (unlikely(skb->len < sizeof(struct message_header))) {
+		printk(KERN_INFO "Exiting validate_header_len: skb len (%d) is less "
+		       "than sizeof(struct message_header) (%zu)\n",
+		       skb->len, (size_t)sizeof(struct message_header));
+		return 0;
+	}
+
+	if (SKB_TYPE_LE32(skb) == cpu_to_le32(MESSAGE_DATA)) {
+		printk(KERN_INFO "SKB_TYPE_LE32(skb) matches MESSAGE_DATA, checking length.\n");
+		printk(KERN_INFO "MESSAGE_MINIMUM_LENGTH=%zu, sizeof(struct message_data)=%zu\n",
+		       MESSAGE_MINIMUM_LENGTH, sizeof(struct message_data));
+		if (skb->len >= MESSAGE_MINIMUM_LENGTH) {
+			printk(KERN_INFO "Exiting validate_header_len: skb len (%d) is greater than or "
+			       "equal to MESSAGE_MINIMUM_LENGTH (%zu), returning sizeof(struct "
+			       "message_data) (%zu)\n",
+			       skb->len, MESSAGE_MINIMUM_LENGTH, sizeof(struct message_data));
+			return sizeof(struct message_data);
+		}
 	}
-	printk(KERN_INFO "Exiting validate_header_len: ret=0\n");
+
+	if (SKB_TYPE_LE32(skb) == cpu_to_le32(MESSAGE_HANDSHAKE_INITIATION)) {
+		printk(KERN_INFO "SKB_TYPE_LE32(skb) matches MESSAGE_HANDSHAKE_INITIATION, checking length.\n");
+		printk(KERN_INFO "sizeof(struct message_handshake_initiation)=%zu\n",
+		       sizeof(struct message_handshake_initiation));
+		if (skb->len == sizeof(struct message_handshake_initiation)) {
+			printk(KERN_INFO "Exiting validate_header_len: skb len (%d) matches "
+			       "sizeof(struct message_handshake_initiation) (%zu)\n",
+			       skb->len, sizeof(struct message_handshake_initiation));
+			return sizeof(struct message_handshake_initiation);
+		}
+	}
+
+	if (SKB_TYPE_LE32(skb) == cpu_to_le32(MESSAGE_HANDSHAKE_RESPONSE)) {
+		printk(KERN_INFO "SKB_TYPE_LE32(skb) matches MESSAGE_HANDSHAKE_RESPONSE, checking length.\n");
+		printk(KERN_INFO "sizeof(struct message_handshake_response)=%zu\n",
+		sizeof(struct message_handshake_response));
+		if (skb->len == sizeof(struct message_handshake_response)) {
+			printk(KERN_INFO "Exiting validate_header_len: skb len (%d) matches "
+			       "sizeof(struct message_handshake_response) (%zu)\n",
+			       skb->len, sizeof(struct message_handshake_response));
+			return sizeof(struct message_handshake_response);
+		}
+	}
+
+	if (SKB_TYPE_LE32(skb) == cpu_to_le32(MESSAGE_HANDSHAKE_COOKIE)) {
+		printk(KERN_INFO "SKB_TYPE_LE32(skb) matches MESSAGE_HANDSHAKE_COOKIE, checking length.\n");
+		printk(KERN_INFO "sizeof(struct message_handshake_cookie)=%zu\n",
+		sizeof(struct message_handshake_cookie));
+		if (skb->len == sizeof(struct message_handshake_cookie)) {
+			printk(KERN_INFO "Exiting validate_header_len: skb len (%d) matches "
+			       "sizeof(struct message_handshake_cookie) (%zu)\n",
+			       skb->len, sizeof(struct message_handshake_cookie));
+			return sizeof(struct message_handshake_cookie);
+		}
+	}
+
+	printk(KERN_INFO "Exiting validate_header_len: no valid message type found or length mismatch.\n");
 	return 0;
 }
 
@@ -62,63 +218,233 @@ static int prepare_skb_header(struct sk_buff *skb, struct wg_device *wg)
 {
 	printk(KERN_INFO "Entering prepare_skb_header: skb=%p, wg=%p\n", skb, wg);
 	size_t data_offset, data_len, header_len;
-	struct udphdr *udp;
+	struct udphdr _udp, *udp;
+
+	// Initial SKB state diagnostics
+	printk(KERN_INFO "Initial skb state: head=%p, data=%p, tail=%p, end=%p, len=%d, headroom=%d\n",
+		skb->head, skb->data, skb->tail, skb->end, skb->len, skb_headroom(skb));
 
+	// Check packet protocol and header validity
 	if (unlikely(!wg_check_packet_protocol(skb) ||
 		     skb_transport_header(skb) < skb->head ||
-		     (skb_transport_header(skb) + sizeof(struct udphdr)) >
-			     skb_tail_pointer(skb))) {
-		printk(KERN_INFO "Exiting prepare_skb_header: ret=-EINVAL (Bogus IP header)\n");
+		     (skb_transport_header(skb) + sizeof(struct udphdr)) > skb_tail_pointer(skb))) {
+		printk(KERN_INFO "Exiting prepare_skb_header with error -EINVAL: "
+		       "Invalid transport header or protocol check failed.\n");
 		return -EINVAL; /* Bogus IP header */
 	}
-	udp = udp_hdr(skb);
-	data_offset = (u8 *)udp - skb->data;
-	if (unlikely(data_offset > U16_MAX ||
-		     data_offset + sizeof(struct udphdr) > skb->len)) {
-		/* Packet has offset at impossible location or isn't big enough
-		 * to have UDP fields.
-		 */
-		printk(KERN_INFO "Exiting prepare_skb_header: ret=-EINVAL (Impossible location or not big enough)\n");
+
+	// Safely access UDP header using skb_header_pointer
+	udp = skb_header_pointer(skb, skb_transport_offset(skb), sizeof(_udp), &_udp);
+	if (!udp) {
+		printk(KERN_INFO "Exiting prepare_skb_header with error -EINVAL: Failed to access UDP header using skb_header_pointer.\n");
 		return -EINVAL;
 	}
+
+	printk(KERN_INFO "UDP header source=%u, dest=%u\n", ntohs(udp->source), ntohs(udp->dest));
+
+	// Check for valid UDP ports
+	if (unlikely(udp->source == 0 || udp->dest == 0)) {
+		printk(KERN_ERR "Invalid UDP source or destination port: src=%u, dst=%u\n", ntohs(udp->source), ntohs(udp->dest));
+		return -EINVAL;
+	}
+
+	// Calculate data offset and validate
+	data_offset = skb_transport_offset(skb) + sizeof(struct udphdr);
+	printk(KERN_INFO "Data offset calculated: data_offset=%zu\n", data_offset);
+
+	if (unlikely(data_offset > U16_MAX || data_offset + sizeof(struct udphdr) > skb->len)) {
+		printk(KERN_INFO "Exiting prepare_skb_header with error -EINVAL: "
+		       "Invalid data offset or UDP header size too large.\n");
+		return -EINVAL;
+	}
+
+	// Get the UDP length field
 	data_len = ntohs(udp->len);
-	if (unlikely(data_len < sizeof(struct udphdr) ||
-		     data_len > skb->len - data_offset)) {
-		/* UDP packet is reporting too small of a size or lying about
-		 * its size.
-		 */
-		printk(KERN_INFO "Exiting prepare_skb_header: ret=-EINVAL (Incorrect UDP packet size)\n");
+	printk(KERN_INFO "UDP length field: data_len=%zu\n", data_len);
+
+	// Validate data length
+	if (unlikely(data_len < sizeof(struct udphdr) || data_len > skb->len - skb_transport_offset(skb))) {
+		printk(KERN_INFO "Exiting prepare_skb_header with error -EINVAL: "
+		       "UDP length field too small or larger than available data.\n");
 		return -EINVAL;
 	}
+
+	// Adjust data length to exclude UDP header
 	data_len -= sizeof(struct udphdr);
-	data_offset = (u8 *)udp + sizeof(struct udphdr) - skb->data;
-	if (unlikely(!pskb_may_pull(skb,
-				data_offset + sizeof(struct message_header)) ||
+	data_offset = skb_transport_offset(skb) + sizeof(struct udphdr);
+	printk(KERN_INFO "Adjusted data_len=%zu, adjusted data_offset=%zu\n",
+	       data_len, data_offset);
+
+	// Check pull and trim capabilities
+	if (unlikely(!pskb_may_pull(skb, data_offset + sizeof(struct message_header)) ||
 		     pskb_trim(skb, data_len + data_offset) < 0)) {
-		printk(KERN_INFO "Exiting prepare_skb_header: ret=-EINVAL (pskb_may_pull or pskb_trim failure)\n");
+		printk(KERN_INFO "Exiting prepare_skb_header with error -EINVAL: "
+		       "pskb_may_pull or pskb_trim failed. data_offset=%zu, "
+		       "data_len=%zu, len=%d\n",
+		       data_offset, data_len, skb->len);
 		return -EINVAL;
 	}
+
+	// Diagnostics before pulling SKB data
+	printk(KERN_INFO "Before skb_pull: len=%d, data=%p, tail=%p\n", skb->len,
+	       skb->data, skb->tail);
 	skb_pull(skb, data_offset);
+	// Diagnostics after pulling SKB data
+	printk(KERN_INFO "After skb_pull: len=%d, data=%p, tail=%p\n", skb->len,
+	       skb->data, skb->tail);
+
+	// Validate the SKB length against calculated data length
 	if (unlikely(skb->len != data_len)) {
-		/* Final len does not agree with calculated len */
-		printk(KERN_INFO "Exiting prepare_skb_header: ret=-EINVAL (Len mismatch)\n");
+		printk(KERN_INFO "Exiting prepare_skb_header with error -EINVAL: "
+		       "Final length does not match calculated length. len=%d, expected data_len=%zu\n",
+		       skb->len, data_len);
 		return -EINVAL;
 	}
+
+	// Validate header length
 	header_len = validate_header_len(skb);
+	printk(KERN_INFO "Header length validated: header_len=%zu\n", header_len);
+
 	if (unlikely(!header_len)) {
-		printk(KERN_INFO "Exiting prepare_skb_header: ret=-EINVAL (Invalid header length)\n");
+		printk(KERN_ERR "Header length validation failed. Dropping packet.\n");
+		printk(KERN_INFO "Exiting prepare_skb_header with error -EINVAL\n");
 		return -EINVAL;
 	}
+
+	// Diagnostics before pushing SKB data back
+	printk(KERN_INFO "Before __skb_push: len=%d, data=%p, tail=%p\n", skb->len,
+	       skb->data, skb->tail);
 	__skb_push(skb, data_offset);
+	// Diagnostics after pushing SKB data back
+	printk(KERN_INFO "After __skb_push: len=%d, data=%p, tail=%p\n", skb->len,
+	       skb->data, skb->tail);
+
+	// Check pull capabilities after push
 	if (unlikely(!pskb_may_pull(skb, data_offset + header_len))) {
-		printk(KERN_INFO "Exiting prepare_skb_header: ret=-EINVAL (pskb_may_pull failure)\n");
+		printk(KERN_INFO "Exiting prepare_skb_header with error -EINVAL: "
+		       "pskb_may_pull failed after __skb_push. data_offset=%zu, header_len=%zu\n",
+		data_offset, header_len);
 		return -EINVAL;
 	}
+
+	// Diagnostics before pulling SKB data again
+	printk(KERN_INFO "Before __skb_pull: len=%d, data=%p, tail=%p\n", skb->len,
+	       skb->data, skb->tail);
 	__skb_pull(skb, data_offset);
-	printk(KERN_INFO "Exiting prepare_skb_header: ret=0\n");
+	// Diagnostics after pulling SKB data again
+	printk(KERN_INFO "After __skb_pull: len=%d, data=%p, tail=%p\n", skb->len,
+	       skb->data, skb->tail);
+
+out:
+	printk(KERN_INFO "Exiting prepare_skb_header successfully: "
+	       "final len=%d, data=%p, head=%p, tail=%p, end=%p, headroom=%d, "
+	       "tailroom=%d\n", skb->len, skb->data, skb->head, skb->tail,
+	       skb->end, skb_headroom(skb), skb_tailroom(skb));
 	return 0;
 }
 
+// Function to extract source and destination sockaddr_storage from an skb
+int extract_sockaddr_from_skb(struct sk_buff *skb, struct sockaddr_storage *source,
+			      struct sockaddr_storage *dest)
+{
+	struct iphdr *ip_header;
+	struct ipv6hdr *ipv6_header;
+	struct tcphdr *tcp_header;
+	struct udphdr *udp_header;
+
+	if (!skb) {
+		return -1; // Invalid skb
+	}
+
+	// Handle IPv4 packets
+	if (skb->protocol == htons(ETH_P_IP)) {
+		ip_header = ip_hdr(skb);
+			if (!ip_header) {
+			return -1; // Failed to get IP header
+		}
+
+		struct sockaddr_in *src_in = (struct sockaddr_in *)source;
+		struct sockaddr_in *dest_in = (struct sockaddr_in *)dest;
+
+		memset(src_in, 0, sizeof(struct sockaddr_in));
+		memset(dest_in, 0, sizeof(struct sockaddr_in));
+
+		src_in->sin_family = AF_INET;
+		dest_in->sin_family = AF_INET;
+
+		src_in->sin_addr.s_addr = ip_header->saddr;
+		dest_in->sin_addr.s_addr = ip_header->daddr;
+
+		// Determine transport protocol
+		if (ip_header->protocol == IPPROTO_TCP) {
+			tcp_header = tcp_hdr(skb);
+			if (!tcp_header) {
+				return -1; // Failed to get TCP header
+			}
+			src_in->sin_port = tcp_header->source;
+			dest_in->sin_port = tcp_header->dest;
+		} else if (ip_header->protocol == IPPROTO_UDP) {
+			udp_header = udp_hdr(skb);
+			if (!udp_header) {
+				return -1; // Failed to get UDP header
+			}
+			src_in->sin_port = udp_header->source;
+			dest_in->sin_port = udp_header->dest;
+		} else {
+			return -1; // Unsupported protocol
+		}
+	}
+
+#if IS_ENABLED(CONFIG_IPV6)
+	// Handle IPv6 packets
+	else if (skb->protocol == htons(ETH_P_IPV6)) {
+		ipv6_header = ipv6_hdr(skb);
+		if (!ipv6_header) {
+			return -1; // Failed to get IPv6 header
+		}
+
+		struct sockaddr_in6 *src_in6 = (struct sockaddr_in6 *)source;
+		struct sockaddr_in6 *dest_in6 = (struct sockaddr_in6 *)dest;
+
+		memset(src_in6, 0, sizeof(struct sockaddr_in6));
+		memset(dest_in6, 0, sizeof(struct sockaddr_in6));
+
+		src_in6->sin6_family = AF_INET6;
+		dest_in6->sin6_family = AF_INET6;
+
+		src_in6->sin6_addr = ipv6_header->saddr;
+		dest_in6->sin6_addr = ipv6_header->daddr;
+
+		// Determine transport protocol
+		if (ipv6_header->nexthdr == IPPROTO_TCP) {
+			tcp_header = tcp_hdr(skb);
+			if (!tcp_header) {
+				return -1; // Failed to get TCP header
+			}
+			src_in6->sin6_port = tcp_header->source;
+			dest_in6->sin6_port = tcp_header->dest;
+		} else if (ipv6_header->nexthdr == IPPROTO_UDP) {
+			udp_header = udp_hdr(skb);
+			if (!udp_header) {
+				return -1; // Failed to get UDP header
+			}
+			src_in6->sin6_port = udp_header->source;
+			dest_in6->sin6_port = udp_header->dest;
+		} else {
+			return -1; // Unsupported protocol
+		}
+	}
+#endif
+
+	else {
+		return -1; // Unsupported packet type
+	}
+
+	return 0; // Success
+}
+
+void print_peer_socket_info(struct wg_peer *peer);
+
 static void wg_receive_handshake_packet(struct wg_device *wg,
 					struct sk_buff *skb)
 {
@@ -132,106 +458,228 @@ static void wg_receive_handshake_packet(struct wg_device *wg,
 	bool packet_needs_cookie;
 	bool under_load;
 
+	printk(KERN_INFO "Validating handshake packet with len=%u\n", skb->len);
+	printk(KERN_INFO "Received Handshake Packet: %*ph\n", (int)skb->len, skb->data);
+
+	if(wg->transport == WG_TRANSPORT_TCP) { 
+		// For TCP, skip cookie check
+		packet_needs_cookie = false;
+		goto nocookie;
+	}
+
+	// Handle handshake cookie response
 	if (SKB_TYPE_LE32(skb) == cpu_to_le32(MESSAGE_HANDSHAKE_COOKIE)) {
-		net_dbg_skb_ratelimited("%s: Receiving cookie response from %pISpfsc\n",
-					wg->dev->name, skb);
-		wg_cookie_message_consume(
-			(struct message_handshake_cookie *)skb->data, wg);
-		printk(KERN_INFO "Exiting wg_receive_handshake_packet (cookie response)\n");
+		net_dbg_skb_ratelimited("%s: Receiving cookie response from %pISpfsc\n", wg->dev->name, skb);
+		wg_cookie_message_consume((struct message_handshake_cookie *)skb->data, wg);
+		printk(KERN_INFO "Exiting wg_receive_handshake_packet\n");
 		return;
 	}
 
-	under_load = atomic_read(&wg->handshake_queue_len) >=
-			MAX_QUEUED_INCOMING_HANDSHAKES / 8;
+	// Load calculation to decide if system is under load
+	under_load = atomic_read(&wg->handshake_queue_len) >= MAX_QUEUED_INCOMING_HANDSHAKES / 8;
 	if (under_load) {
 		last_under_load = ktime_get_coarse_boottime_ns();
+		printk(KERN_INFO "System under load: last_under_load set to %llu\n", last_under_load);
 	} else if (last_under_load) {
 		under_load = !wg_birthdate_has_expired(last_under_load, 1);
-		if (!under_load)
+		if (!under_load) {
 			last_under_load = 0;
+			printk(KERN_INFO "System load normalized: last_under_load reset\n");
+		}
+	}
+
+	// Validate packet's MAC and set packet_needs_cookie flag
+	mac_state = wg_cookie_validate_packet(&wg->cookie_checker, skb, under_load);
+	printk(KERN_INFO "MAC validation result: %d\n", mac_state);
+	if (mac_state != VALID_MAC_WITH_COOKIE && mac_state != VALID_MAC_BUT_NO_COOKIE) {
+		printk(KERN_ERR "Invalid MAC state: %d\n", mac_state);
 	}
-	mac_state = wg_cookie_validate_packet(&wg->cookie_checker, skb,
-					      under_load);
+
+	// Determine if a cookie is needed based on load and MAC state
 	if ((under_load && mac_state == VALID_MAC_WITH_COOKIE) ||
 	    (!under_load && mac_state == VALID_MAC_BUT_NO_COOKIE)) {
 		packet_needs_cookie = false;
 	} else if (under_load && mac_state == VALID_MAC_BUT_NO_COOKIE) {
-		packet_needs_cookie = true;
+		if(wg->transport == WG_TRANSPORT_UDP)
+			packet_needs_cookie = false;
 	} else {
-		net_dbg_skb_ratelimited("%s: Invalid MAC of handshake, dropping packet from %pISpfsc\n",
-					wg->dev->name, skb);
-		printk(KERN_INFO "Exiting wg_receive_handshake_packet (Invalid MAC)\n");
+		net_dbg_skb_ratelimited("%s: Invalid MAC of handshake, dropping packet from %pISpfsc\n", wg->dev->name, skb);
+		printk(KERN_INFO "Exiting wg_receive_handshake_packet\n");
 		return;
 	}
 
+nocookie:
+	// Process handshake packets
 	switch (SKB_TYPE_LE32(skb)) {
 	case cpu_to_le32(MESSAGE_HANDSHAKE_INITIATION): {
-		struct message_handshake_initiation *message =
-			(struct message_handshake_initiation *)skb->data;
+		struct message_handshake_initiation *message = (struct message_handshake_initiation *)skb->data;
 
+		printk(KERN_INFO "Processing handshake initiation packet\n");
 		if (packet_needs_cookie) {
-			wg_packet_send_handshake_cookie(wg, skb,
-							message->sender_index);
-			printk(KERN_INFO "Exiting wg_receive_handshake_packet (needs cookie, initiation)\n");
+			wg_packet_send_handshake_cookie(wg, skb, message->sender_index);
+			printk(KERN_INFO "Exiting wg_receive_handshake_packet: Cookie sent for initiation\n");
 			return;
 		}
+
+		// Handle handshake initiation
 		peer = wg_noise_handshake_consume_initiation(message, wg);
 		if (unlikely(!peer)) {
-			net_dbg_skb_ratelimited("%s: Invalid handshake initiation from %pISpfsc\n",
-						wg->dev->name, skb);
-			printk(KERN_INFO "Exiting wg_receive_handshake_packet (Invalid initiation)\n");
+			net_dbg_skb_ratelimited("%s: Invalid handshake initiation from %pISpfsc\n", wg->dev->name, skb);
+			printk(KERN_INFO "Exiting wg_receive_handshake_packet\n");
 			return;
 		}
+		print_peer_socket_info(peer);
 		wg_socket_set_peer_endpoint_from_skb(peer, skb);
-		net_dbg_ratelimited("%s: Receiving handshake initiation from peer %llu (%pISpfsc)\n",
-				    wg->dev->name, peer->internal_id,
-				    &peer->endpoint.addr);
+		net_dbg_ratelimited("%s: Receiving handshake initiation from peer %llu (%pISpfsc)\n", wg->dev->name, peer->internal_id, &peer->endpoint.addr);
 		wg_packet_send_handshake_response(peer);
 		break;
 	}
 	case cpu_to_le32(MESSAGE_HANDSHAKE_RESPONSE): {
-		struct message_handshake_response *message =
-			(struct message_handshake_response *)skb->data;
+		struct message_handshake_response *message = (struct message_handshake_response *)skb->data;
 
+		printk(KERN_INFO "Processing handshake response packet\n");
 		if (packet_needs_cookie) {
-			wg_packet_send_handshake_cookie(wg, skb,
-							message->sender_index);
-			printk(KERN_INFO "Exiting wg_receive_handshake_packet (needs cookie, response)\n");
+			wg_packet_send_handshake_cookie(wg, skb, message->sender_index);
+			printk(KERN_INFO "Exiting wg_receive_handshake_packet: Cookie sent for response\n");
 			return;
 		}
+
+		// Handle handshake response
 		peer = wg_noise_handshake_consume_response(message, wg);
 		if (unlikely(!peer)) {
-			net_dbg_skb_ratelimited("%s: Invalid handshake response from %pISpfsc\n",
-						wg->dev->name, skb);
-			printk(KERN_INFO "Exiting wg_receive_handshake_packet (Invalid response)\n");
+			printk(KERN_ERR "Peer object is NULL. Dropping packet.\n");
+			net_dbg_skb_ratelimited("%s: Invalid handshake response from %pISpfsc\n", wg->dev->name, skb);
+			printk(KERN_INFO "Exiting wg_receive_handshake_packet\n");
 			return;
 		}
+
+		// TCP-specific endpoint handling
+		struct endpoint ep = peer->endpoint;
+		struct wg_tcp_socket_list_entry *socket_iter;
+		bool found = false;
+		print_peer_socket_info(peer);
 		wg_socket_set_peer_endpoint_from_skb(peer, skb);
-		net_dbg_ratelimited("%s: Receiving handshake response from peer %llu (%pISpfsc)\n",
-				    wg->dev->name, peer->internal_id,
-				    &peer->endpoint.addr);
-		if (wg_noise_handshake_begin_session(&peer->handshake,
-						     &peer->keypairs)) {
+
+		if (!endpoint_eq(&peer->endpoint, &ep) && peer->device->transport == WG_TRANSPORT_TCP) {
+			printk(KERN_INFO "New TCP endpoint detected\n");
+			log_wireguard_endpoint(&peer->endpoint);
+			print_peer_socket_info(peer);
+			
+			if(!skb->sk) {
+				printk(KERN_INFO "No skb sk. skb=%p peer=%p\n", skb, peer);
+			} else {
+				if(skb->sk->sk_socket) {
+						
+					if ((skb->sk->sk_socket != peer->inbound_socket) && (skb->sk->sk_socket != peer->outbound_socket)) {
+			 			printk(KERN_INFO "Promoting pending connection to active\n");	
+ 
+						if (list_empty(&peer->device->tcp_connection_list)) {
+						pr_err("Wireguard: tcp_connection_list is empty\n");
+						} else {
+							found = false;
+							list_for_each_entry_rcu(socket_iter, &peer->device->tcp_connection_list, tcp_connection_ll) {
+							// Defensive checks to ensure all relevant fields are populated
+								if (!socket_iter) {
+									printk(KERN_INFO "NULL LIST ENTRY\n");
+									continue;
+								}
+								if (!socket_iter->tcp_socket || !socket_iter->tcp_socket->sk) {
+									printk(KERN_INFO "NULL SOCKET\n");
+									continue;
+								}
+								if (!socket_iter->temp_peer || IS_ERR(socket_iter->temp_peer)) {
+									printk(KERN_INFO "NULL TEMP PEER\n");
+									continue;
+								}
+	
+								if (endpoint_eq(&peer->endpoint, &socket_iter->temp_peer->endpoint)) {
+									printk(KERN_INFO "Matching connection found in pending list\n");
+									found = true;
+									break;
+								}
+							}
+
+							if (found) {
+								printk(KERN_INFO "Removing and promoting connection from pending list\n");
+								spin_lock_bh(&peer->device->tcp_connection_list_lock);
+								list_del_rcu(&socket_iter->tcp_connection_ll);
+								spin_unlock_bh(&peer->device->tcp_connection_list_lock);
+								synchronize_rcu();
+
+								spin_lock(&peer->tcp_lock);
+								if (socket_iter->temp_peer->tcp_inbound_callbacks_set) {
+									peer->original_inbound_state_change = socket_iter->temp_peer->original_inbound_state_change;
+									peer->original_inbound_write_space = socket_iter->temp_peer->original_inbound_write_space;
+									peer->original_inbound_data_ready = socket_iter->temp_peer->original_inbound_data_ready;
+									peer->tcp_inbound_callbacks_set = true;
+								}
+								peer->inbound_connected = true;
+								peer->inbound_timestamp = ktime_get();
+								peer->tcp_established = true;
+								peer->tcp_inbound_remove_scheduled = false;
+								peer->clean_inbound = false;
+								peer->clean_outbound = true;
+								spin_unlock(&peer->tcp_lock);	
+
+								// Clean up temporary peer structure
+								wg_clean_peer_socket(socket_iter->temp_peer, false, false, false);
+								if (!IS_ERR(socket_iter->temp_peer) && socket_iter->temp_peer)
+									kfree(socket_iter->temp_peer);
+
+								write_lock_bh(&peer->endpoint_lock);
+								peer->tcp_reply_endpoint = socket_iter->temp_peer->endpoint;
+								peer->peer_socket = skb->sk->sk_socket;
+								peer->inbound_socket = skb->sk->sk_socket;
+								extract_sockaddr_from_skb(skb, &peer->inbound_source, &peer->inbound_dest);
+								((struct wg_socket_data *)(peer->peer_socket->sk->sk_user_data))->peer = peer;
+								write_unlock_bh(&peer->endpoint_lock);
+
+								kfree(socket_iter);
+							} else {
+								pr_err("Wireguard: TCP connection not found in pending list\n");
+							}
+						}	
+					}
+				}
+			}
+		}
+
+		// Update timestamps and session handling for TCP
+		if (peer->device->transport == WG_TRANSPORT_TCP && skb->sk) {
+			write_lock_bh(&peer->endpoint_lock);
+			peer->peer_socket = skb->sk->sk_socket;
+			write_unlock_bh(&peer->endpoint_lock);
+			if(skb->sk->sk_socket) {
+				if (skb->sk->sk_socket == peer->inbound_socket) {
+					peer->inbound_timestamp = ktime_get();
+				} else {
+					peer->outbound_timestamp = ktime_get();
+				}
+			}
+		}
+		net_dbg_ratelimited("%s: Receiving handshake response from peer %llu (%pISpfsc)\n", wg->dev->name, peer->internal_id, &peer->endpoint.addr);
+
+		if (wg_noise_handshake_begin_session(&peer->handshake, &peer->keypairs)) {
 			wg_timers_session_derived(peer);
 			wg_timers_handshake_complete(peer);
-			/* Calling this function will either send any existing
-			 * packets in the queue and not send a keepalive, which
-			 * is the best case, Or, if there's nothing in the
-			 * queue, it will send a keepalive, in order to give
-			 * immediate confirmation of the session.
-			 */
 			wg_packet_send_keepalive(peer);
 		}
 		break;
 	}
+
+	default:
+		printk(KERN_WARNING "Unknown packet type received in handshake processing: %u\n", SKB_TYPE_LE32(skb));
+		break;
 	}
 
+	// Final check to ensure peer is valid
 	if (unlikely(!peer)) {
-		WARN(1, "Somehow a wrong type of packet wound up in the handshake queue!\n");
-		printk(KERN_INFO "Exiting wg_receive_handshake_packet (Wrong type in handshake queue)\n");
+		WARN(1, "Unexpected state: No valid peer found after handshake processing\n");
+		printk(KERN_INFO "Exiting wg_receive_handshake_packet\n");
 		return;
 	}
 
+	// Update statistics and state
 	local_bh_disable();
 	update_rx_stats(peer, skb->len);
 	local_bh_enable();
@@ -242,6 +690,7 @@ static void wg_receive_handshake_packet(struct wg_device *wg,
 	printk(KERN_INFO "Exiting wg_receive_handshake_packet\n");
 }
 
+
 void wg_packet_handshake_receive_worker(struct work_struct *work)
 {
 	printk(KERN_INFO "Entering wg_packet_handshake_receive_worker: work=%p\n", work);
@@ -282,6 +731,7 @@ static void keep_key_fresh(struct wg_peer *peer)
 	printk(KERN_INFO "Exiting keep_key_fresh\n");
 }
 
+#ifdef ORIGINAL
 static bool decrypt_packet(struct sk_buff *skb, struct noise_keypair *keypair)
 {
 	printk(KERN_INFO "Entering decrypt_packet: skb=%p, keypair=%p\n", skb, keypair);
@@ -291,7 +741,7 @@ static bool decrypt_packet(struct sk_buff *skb, struct noise_keypair *keypair)
 	int num_frags;
 
 	if (unlikely(!keypair)) {
-		printk(KERN_INFO "Exiting decrypt_packet: ret=false (No keypair)\n");
+		printk(KERN_INFO "Exiting decrypt_packet with false\n");
 		return false;
 	}
 
@@ -299,7 +749,7 @@ static bool decrypt_packet(struct sk_buff *skb, struct noise_keypair *keypair)
 		  wg_birthdate_has_expired(keypair->receiving.birthdate, REJECT_AFTER_TIME) ||
 		  READ_ONCE(keypair->receiving_counter.counter) >= REJECT_AFTER_MESSAGES)) {
 		WRITE_ONCE(keypair->receiving.is_valid, false);
-		printk(KERN_INFO "Exiting decrypt_packet: ret=false (Invalid keypair state)\n");
+		printk(KERN_INFO "Exiting decrypt_packet with false\n");
 		return false;
 	}
 
@@ -316,20 +766,20 @@ static bool decrypt_packet(struct sk_buff *skb, struct noise_keypair *keypair)
 	offset += sizeof(struct message_data);
 	skb_pull(skb, offset);
 	if (unlikely(num_frags < 0 || num_frags > ARRAY_SIZE(sg))) {
-		printk(KERN_INFO "Exiting decrypt_packet: ret=false (Invalid number of frags)\n");
+		printk(KERN_INFO "Exiting decrypt_packet with false\n");
 		return false;
 	}
 
 	sg_init_table(sg, num_frags);
 	if (skb_to_sgvec(skb, sg, 0, skb->len) <= 0) {
-		printk(KERN_INFO "Exiting decrypt_packet: ret=false (skb_to_sgvec failure)\n");
+		printk(KERN_INFO "Exiting decrypt_packet with false\n");
 		return false;
 	}
 
 	if (!chacha20poly1305_decrypt_sg_inplace(sg, skb->len, NULL, 0,
 					         PACKET_CB(skb)->nonce,
 						 keypair->receiving.key)) {
-		printk(KERN_INFO "Exiting decrypt_packet: ret=false (Decryption failure)\n");
+		printk(KERN_INFO "Exiting decrypt_packet with false\n");
 		return false;
 	}
 
@@ -338,12 +788,100 @@ static bool decrypt_packet(struct sk_buff *skb, struct noise_keypair *keypair)
 	 */
 	skb_push(skb, offset);
 	if (pskb_trim(skb, skb->len - noise_encrypted_len(0))) {
-		printk(KERN_INFO "Exiting decrypt_packet: ret=false (pskb_trim failure)\n");
+		printk(KERN_INFO "Exiting decrypt_packet with false\n");
 		return false;
 	}
 	skb_pull(skb, offset);
 
-	printk(KERN_INFO "Exiting decrypt_packet: ret=true\n");
+	printk(KERN_INFO "Exiting decrypt_packet with true\n");
+	return true;
+}
+#endif // ORIGINAL
+
+static bool decrypt_packet(struct sk_buff *skb, struct noise_keypair *keypair)
+{
+	struct scatterlist sg[MAX_SKB_FRAGS + 8];
+	struct sk_buff *trailer;
+	unsigned int offset;
+	int num_frags;
+
+	printk(KERN_INFO "Entering decrypt_packet: skb=%p, keypair=%p\n", skb, keypair);
+	printk(KERN_INFO "skb->len = %u, skb->data_len = %u, skb->network_header = %p\n",
+	       skb->len, skb->data_len, skb_network_header(skb));
+
+	if (unlikely(!keypair)) {
+		printk(KERN_ERR "Keypair is NULL\n");
+		printk(KERN_ERR "Exiting decrypt_packet with false\n");
+		return false;
+	}
+
+	if (unlikely(!READ_ONCE(keypair->receiving.is_valid) ||
+			wg_birthdate_has_expired(keypair->receiving.birthdate, REJECT_AFTER_TIME) ||
+			READ_ONCE(keypair->receiving_counter.counter) >= REJECT_AFTER_MESSAGES)) {
+		WRITE_ONCE(keypair->receiving.is_valid, false);
+		printk(KERN_ERR "Keypair is invalid or expired: is_valid=%d, counter=%llu\n",
+		keypair->receiving.is_valid, keypair->receiving_counter.counter);
+		printk(KERN_ERR "Exiting decrypt_packet with false\n");
+		return false;
+	}
+
+	PACKET_CB(skb)->nonce = le64_to_cpu(((struct message_data *)skb->data)->counter);
+	printk(KERN_INFO "Extracted nonce from skb: nonce=%llu\n", PACKET_CB(skb)->nonce);
+	printk(KERN_INFO "skb->data (before decryption): %*ph\n", skb->len, skb->data);
+	
+	// Ensure network header is part of the packet
+	offset = skb->data - skb_network_header(skb);
+	printk(KERN_INFO "Pushing skb to preserve network header, offset=%u\n", offset);
+	skb_push(skb, offset);
+	num_frags = skb_cow_data(skb, 0, &trailer);
+	printk(KERN_INFO "num_frags after skb_cow_data: %d\n", num_frags);
+	offset += sizeof(struct message_data);
+	skb_pull(skb, offset);
+	printk(KERN_INFO "Pulled skb to offset: %u, skb->len=%u, skb->data=%p\n", offset, skb->len, skb->data);
+	if (unlikely(num_frags < 0 || num_frags > ARRAY_SIZE(sg))) {
+		printk(KERN_INFO "skb->data (after decryption failed): %*ph\n", skb->len, skb->data);
+		printk(KERN_ERR "Failed skb_cow_data: num_frags=%d, skb->len=%u\n", num_frags, skb->len);
+		printk(KERN_ERR "Exiting decrypt_packet with false\n");
+		return false;
+	}
+
+	sg_init_table(sg, num_frags);
+	if (skb_to_sgvec(skb, sg, 0, skb->len) <= 0) {
+		printk(KERN_ERR "Failed skb_to_sgvec, skb->len=%u\n", skb->len);
+		printk(KERN_ERR "Exiting decrypt_packet with false\n");
+		return false;
+	}
+
+	printk(KERN_INFO "Scattergather segments prepared, starting decryption\n");
+#define NOISE_KEY_LEN	32
+	printk(KERN_INFO "Decryption key: %*ph\n", NOISE_KEY_LEN, keypair->receiving.key);
+	
+	if (!chacha20poly1305_decrypt_sg_inplace(sg, skb->len, NULL, 0,
+                                             PACKET_CB(skb)->nonce,
+                                             keypair->receiving.key)) {
+		printk(KERN_INFO "skb->data (after decryption failed): %*ph\n",
+		       skb->len, skb->data);
+		printk(KERN_ERR "Decryption failed\n");
+		printk(KERN_ERR "Exiting decrypt_packet with false\n");
+        return false;
+	}
+
+	// Ensure endpoint information remains intact
+	printk(KERN_INFO "Pushing skb to preserve endpoint information\n");
+	skb_push(skb, offset);
+	if (pskb_trim(skb, skb->len - noise_encrypted_len(0))) {
+		printk(KERN_INFO "skb->data (after decryption failed): %*ph\n", skb->len, skb->data);
+		printk(KERN_ERR "Failed pskb_trim, skb->len=%u\n", skb->len);
+		printk(KERN_ERR "Exiting decrypt_packet with false\n");
+		return false;
+	}
+	skb_pull(skb, offset);
+	printk(KERN_INFO "skb->data (after decryption succeeded): %*ph\n",
+	       skb->len, skb->data);
+	printk(KERN_INFO "Pulled skb to offset: %u, skb->len=%u, skb->data=%p\n",
+	       offset, skb->len, skb->data);
+
+	printk(KERN_INFO "Exiting decrypt_packet with true, skb->len=%u\n", skb->len);
 	return true;
 }
 
@@ -384,7 +922,7 @@ static bool counter_validate(struct noise_replay_counter *counter, u64 their_cou
 
 out:
 	spin_unlock_bh(&counter->lock);
-	printk(KERN_INFO "Exiting counter_validate: ret=%d\n", ret);
+	printk(KERN_INFO "Exiting counter_validate with %d\n", ret);
 	return ret;
 }
 
@@ -394,11 +932,18 @@ static void wg_packet_consume_data_done(struct wg_peer *peer,
 					struct sk_buff *skb,
 					struct endpoint *endpoint)
 {
-	printk(KERN_INFO "Entering wg_packet_consume_data_done: peer=%p, skb=%p, endpoint=%p\n", peer, skb, endpoint);
+	printk(KERN_INFO "Entering wg_packet_consume_data_done: peer=%p, skb=%p, endpoint=%p\n",
+	       peer, skb, endpoint);
 	struct net_device *dev = peer->device->dev;
 	unsigned int len, len_before_trim;
 	struct wg_peer *routed_peer;
 
+	if (unlikely(!endpoint)) {
+    		printk(KERN_ERR "Endpoint object is NULL. Cannot set peer endpoint.\n");
+    		return;
+	}
+
+	
 	wg_socket_set_peer_endpoint(peer, endpoint);
 
 	if (unlikely(wg_noise_received_with_keypair(&peer->keypairs,
@@ -418,7 +963,6 @@ static void wg_packet_consume_data_done(struct wg_peer *peer,
 		net_dbg_ratelimited("%s: Receiving keepalive packet from peer %llu (%pISpfsc)\n",
 				    dev->name, peer->internal_id,
 				    &peer->endpoint.addr);
-		printk(KERN_INFO "Exiting wg_packet_consume_data_done (keepalive)\n");
 		goto packet_processed;
 	}
 
@@ -458,6 +1002,14 @@ static void wg_packet_consume_data_done(struct wg_peer *peer,
 	if (unlikely(len > skb->len))
 		goto dishonest_packet_size;
 	len_before_trim = skb->len;
+
+
+	if (unlikely(len == 0 || len_before_trim == 0)) {
+    		printk(KERN_ERR "Invalid packet length detected: len=%u, len_before_trim=%u\n", len, len_before_trim);
+    		return;
+	}
+
+	
 	if (unlikely(pskb_trim(skb, len)))
 		goto packet_processed;
 
@@ -479,24 +1031,22 @@ static void wg_packet_consume_data_done(struct wg_peer *peer,
 				&peer->endpoint.addr);
 	DEV_STATS_INC(dev, rx_errors);
 	DEV_STATS_INC(dev, rx_frame_errors);
-	printk(KERN_INFO "Exiting wg_packet_consume_data_done (unallowed src IP)\n");
 	goto packet_processed;
 dishonest_packet_type:
 	net_dbg_ratelimited("%s: Packet is neither ipv4 nor ipv6 from peer %llu (%pISpfsc)\n",
 			    dev->name, peer->internal_id, &peer->endpoint.addr);
 	DEV_STATS_INC(dev, rx_errors);
 	DEV_STATS_INC(dev, rx_frame_errors);
-	printk(KERN_INFO "Exiting wg_packet_consume_data_done (incorrect packet type)\n");
 	goto packet_processed;
 dishonest_packet_size:
 	net_dbg_ratelimited("%s: Packet has incorrect size from peer %llu (%pISpfsc)\n",
 			    dev->name, peer->internal_id, &peer->endpoint.addr);
 	DEV_STATS_INC(dev, rx_errors);
 	DEV_STATS_INC(dev, rx_length_errors);
-	printk(KERN_INFO "Exiting wg_packet_consume_data_done (incorrect size)\n");
 	goto packet_processed;
 packet_processed:
 	dev_kfree_skb(skb);
+	printk(KERN_INFO "Exiting wg_packet_consume_data_done\n");
 }
 
 int wg_packet_rx_poll(struct napi_struct *napi, int budget)
@@ -511,7 +1061,7 @@ int wg_packet_rx_poll(struct napi_struct *napi, int budget)
 	bool free;
 
 	if (unlikely(budget <= 0)) {
-		printk(KERN_INFO "Exiting wg_packet_rx_poll: work_done=%d\n", work_done);
+		printk(KERN_INFO "Exiting wg_packet_rx_poll with 0\n");
 		return 0;
 	}
 
@@ -521,7 +1071,7 @@ int wg_packet_rx_poll(struct napi_struct *napi, int budget)
 		wg_prev_queue_drop_peeked(&peer->rx_queue);
 		keypair = PACKET_CB(skb)->keypair;
 		free = true;
-
+		
 		if (unlikely(state != PACKET_STATE_CRYPTED))
 			goto next;
 
@@ -554,7 +1104,7 @@ int wg_packet_rx_poll(struct napi_struct *napi, int budget)
 	if (work_done < budget)
 		napi_complete_done(napi, work_done);
 
-	printk(KERN_INFO "Exiting wg_packet_rx_poll: work_done=%d\n", work_done);
+	printk(KERN_INFO "Exiting wg_packet_rx_poll with %d\n", work_done);
 	return work_done;
 }
 
@@ -583,20 +1133,19 @@ static void wg_packet_consume_data(struct wg_device *wg, struct sk_buff *skb)
 	struct wg_peer *peer = NULL;
 	int ret;
 
+	printk(KERN_INFO "Consuming data packet with key_idx=%u\n", idx);
+	printk(KERN_INFO "Data Packet Contents: %*ph\n", (int)skb->len, skb->data);
+
 	rcu_read_lock_bh();
 	PACKET_CB(skb)->keypair =
 		(struct noise_keypair *)wg_index_hashtable_lookup(
 			wg->index_hashtable, INDEX_HASHTABLE_KEYPAIR, idx,
 			&peer);
-	if (unlikely(!wg_noise_keypair_get(PACKET_CB(skb)->keypair))) {
-		printk(KERN_INFO "Exiting wg_packet_consume_data (Invalid keypair)\n");
+	if (unlikely(!wg_noise_keypair_get(PACKET_CB(skb)->keypair)))
 		goto err_keypair;
-	}
 
-	if (unlikely(READ_ONCE(peer->is_dead))) {
-		printk(KERN_INFO "Exiting wg_packet_consume_data (Peer is dead)\n");
+	if (unlikely(READ_ONCE(peer->is_dead)))
 		goto err;
-	}
 
 	ret = wg_queue_enqueue_per_device_and_peer(&wg->decrypt_queue, &peer->rx_queue, skb,
 						   wg->packet_crypt_wq);
@@ -613,9 +1162,10 @@ static void wg_packet_consume_data(struct wg_device *wg, struct sk_buff *skb)
 	rcu_read_unlock_bh();
 	wg_peer_put(peer);
 	dev_kfree_skb(skb);
-	printk(KERN_INFO "Exiting wg_packet_consume_data (Error)\n");
+	printk(KERN_INFO "Exiting wg_packet_consume_data\n");
 }
 
+#ifdef ORIGINAL
 void wg_packet_receive(struct wg_device *wg, struct sk_buff *skb)
 {
 	printk(KERN_INFO "Entering wg_packet_receive: wg=%p, skb=%p\n", wg, skb);
@@ -662,5 +1212,87 @@ void wg_packet_receive(struct wg_device *wg, struct sk_buff *skb)
 
 err:
 	dev_kfree_skb(skb);
-	printk(KERN_INFO "Exiting wg_packet_receive (Error)\n");
+	printk(KERN_INFO "Exiting wg_packet_receive\n");
+}
+#endif // ORIGINAL
+
+void wg_packet_receive(struct wg_device *wg, struct sk_buff *skb)
+{
+	printk(KERN_INFO "Entering wg_packet_receive: wg=%p, skb=%p\n", wg, skb);
+
+	if (unlikely(prepare_skb_header(skb, wg) < 0)) {
+		printk(KERN_INFO "prepare_skb_header failed\n");
+		goto err;
+	}
+
+	/* Determine packet type */
+	uint32_t skb_type = SKB_TYPE_LE32(skb);
+	printk(KERN_INFO "Packet type: %u\n", skb_type);
+
+	switch (skb_type) {
+	case cpu_to_le32(MESSAGE_HANDSHAKE_INITIATION):
+	case cpu_to_le32(MESSAGE_HANDSHAKE_RESPONSE):
+	case cpu_to_le32(MESSAGE_HANDSHAKE_COOKIE): {
+		int cpu, ret = -EBUSY;
+		printk(KERN_INFO "Received handshake packet\n");
+
+		if (unlikely(!rng_is_initialized())) {
+			printk(KERN_INFO "RNG is not initialized, dropping packet\n");
+			goto drop;
+		}
+
+		int queue_len = atomic_read(&wg->handshake_queue_len);
+		printk(KERN_INFO "Current handshake queue length: %d\n", queue_len);
+
+		if (queue_len > MAX_QUEUED_INCOMING_HANDSHAKES / 2) {
+			printk(KERN_INFO "Queue length exceeds threshold, trying spinlock\n");
+			if (spin_trylock_bh(&wg->handshake_queue.ring.producer_lock)) {
+				ret = __ptr_ring_produce(&wg->handshake_queue.ring, skb);
+				printk(KERN_INFO "__ptr_ring_produce returned: %d\n", ret);
+				spin_unlock_bh(&wg->handshake_queue.ring.producer_lock);
+			} else {
+				printk(KERN_INFO "Failed to acquire spinlock\n");
+			}
+		} else {
+			ret = ptr_ring_produce_bh(&wg->handshake_queue.ring, skb);
+			printk(KERN_INFO "ptr_ring_produce_bh returned: %d\n", ret);
+		}
+
+		if (ret) {
+			printk(KERN_INFO "Failed to queue handshake packet, dropping\n");
+		drop:
+			net_dbg_skb_ratelimited("%s: Dropping handshake packet from %pISpfsc\n",
+						wg->dev->name, skb);
+			goto err;
+		}
+
+		atomic_inc(&wg->handshake_queue_len);
+		printk(KERN_INFO "Handshake queue length incremented\n");
+
+		cpu = wg_cpumask_next_online(&wg->handshake_queue.last_cpu);
+		printk(KERN_INFO "Selected CPU for work queue: %d\n", cpu);
+
+		/* Queues up a call to packet_process_queued_handshake_packets(skb): */
+		queue_work_on(cpu, wg->handshake_receive_wq,
+			      &per_cpu_ptr(wg->handshake_queue.worker, cpu)->work);
+		break;
+	}
+	case cpu_to_le32(MESSAGE_DATA):
+		printk(KERN_INFO "Received data packet\n");
+		PACKET_CB(skb)->ds = ip_tunnel_get_dsfield(ip_hdr(skb), skb);
+		printk(KERN_INFO "DS field set to: %u\n", PACKET_CB(skb)->ds);
+		wg_packet_consume_data(wg, skb);
+		break;
+	default:
+		WARN(1, "Non-exhaustive parsing of packet header lead to unknown packet type!\n");
+		printk(KERN_INFO "Unknown packet type: %u, dropping\n", skb_type);
+		goto err;
+	}
+
+	printk(KERN_INFO "Exiting wg_packet_receive normally\n");
+	return;
+
+err:
+	dev_kfree_skb(skb);
+	printk(KERN_INFO "Exiting wg_packet_receive with error\n");
 }
diff --git a/wireguard-linux/drivers/net/wireguard/send.c b/wireguard-linux/drivers/net/wireguard/send.c
index 0d48e0f4a1ba..1a7b84d122a7 100644
--- a/wireguard-linux/drivers/net/wireguard/send.c
+++ b/wireguard-linux/drivers/net/wireguard/send.c
@@ -14,17 +14,94 @@
 #include <linux/uio.h>
 #include <linux/inetdevice.h>
 #include <linux/socket.h>
+#include <linux/wireguard.h>
 #include <net/ip_tunnels.h>
 #include <net/udp.h>
 #include <net/sock.h>
 
+#ifdef DIAGNOSTIC
+
+#define WG_PACKET_TYPE_HANDSHAKE_INIT 1
+#define WG_PACKET_TYPE_HANDSHAKE_RESP 2
+#define WG_PACKET_TYPE_COOKIE_REPLY 3
+#define WG_PACKET_TYPE_TRANSPORT_DATA 4
+
+static void wg_print_wireguard_skb(struct sk_buff *skb)
+{
+    if (!skb)
+        return;
+    // Extract the WireGuard packet data directly from skb->data
+    wg_print_wireguard_skb(skb->data, skb->len);
+}
+
+static void wg_print_wireguard_packet(unsigned char *data, size_t payload_len)
+{
+    u32 message_type;
+    u64 receiver_nonce;
+    u64 message_counter;
+    size_t i;
+
+    // Get the message type (1st 4 bytes)
+    message_type = ntohl(*(u32 *)data);
+
+    // Print the message type
+    switch (message_type) {
+    case WG_PACKET_TYPE_HANDSHAKE_INIT:
+        printk(KERN_INFO "WireGuard packet: Handshake Initiation\n");
+        break;
+    case WG_PACKET_TYPE_HANDSHAKE_RESP:
+        printk(KERN_INFO "WireGuard packet: Handshake Response\n");
+        break;
+    case WG_PACKET_TYPE_COOKIE_REPLY:
+        printk(KERN_INFO "WireGuard packet: Cookie Reply\n");
+        break;
+    case WG_PACKET_TYPE_TRANSPORT_DATA:
+        printk(KERN_INFO "WireGuard packet: Transport Data\n");
+        break;
+    default:
+        printk(KERN_INFO "WireGuard packet: Unknown Type (%u)\n", message_type);
+        return;
+    }
+
+    // For Handshake Init/Resp and Transport Data packets, print additional fields
+    if (message_type == WG_PACKET_TYPE_HANDSHAKE_INIT || 
+        message_type == WG_PACKET_TYPE_HANDSHAKE_RESP || 
+        message_type == WG_PACKET_TYPE_TRANSPORT_DATA) {
+
+        // Get the receiver nonce (next 8 bytes)
+        receiver_nonce = be64_to_cpu(*(u64 *)(data + sizeof(u32)));
+
+        // Print the receiver nonce
+        printk(KERN_INFO "Receiver Nonce: 0x%016llx\n", receiver_nonce);
+
+        // If it's a Transport Data packet, also get and print the message counter (next 8 bytes)
+        if (message_type == WG_PACKET_TYPE_TRANSPORT_DATA) {
+            message_counter = be64_to_cpu(*(u64 *)(data + sizeof(u32) + sizeof(u64)));
+            printk(KERN_INFO "Message Counter: 0x%016llx\n", message_counter);
+        }
+    }
+
+    // Print the entire packet data in hex, 32 bytes per line
+    printk(KERN_INFO "Packet Data:\n");
+    for (i = 0; i < payload_len; i += 32) {
+        size_t len = (i + 32 <= payload_len) ? 32 : payload_len - i;
+        printk(KERN_INFO "%*ph\n", (int)len, data + i);
+    }
+}
+
+#endif // DIAGNOSTIC
+
+#ifdef OLD
 static void wg_packet_send_handshake_initiation(struct wg_peer *peer)
 {
+	printk(KERN_INFO "Entering wg_packet_send_handshake_initiation with peer=%p\n", peer);
 	struct message_handshake_initiation packet;
 
 	if (!wg_birthdate_has_expired(atomic64_read(&peer->last_sent_handshake),
-				      REKEY_TIMEOUT))
+				      REKEY_TIMEOUT)) {
+		printk(KERN_INFO "Exiting wg_packet_send_handshake_initiation\n");
 		return; /* This function is rate limited. */
+	}
 
 	atomic64_set(&peer->last_sent_handshake, ktime_get_coarse_boottime_ns());
 	net_dbg_ratelimited("%s: Sending handshake initiation to peer %llu (%pISpfsc)\n",
@@ -33,6 +110,13 @@ static void wg_packet_send_handshake_initiation(struct wg_peer *peer)
 
 	if (wg_noise_handshake_create_initiation(&packet, &peer->handshake)) {
 		wg_cookie_add_mac_to_packet(&packet, sizeof(packet), peer);
+		
+		printk(KERN_INFO "MAC added to handshake initiation packet\n");
+		printk(KERN_INFO "Handshake Initiation Packet: %*ph\n",
+			(int)sizeof(packet), &packet);
+		printk(KERN_INFO "Peer Cookie Parameters: peer=%p, handshake=%p, index=%u\n",
+			peer, &peer->handshake, packet.sender_index);
+ 
 		wg_timers_any_authenticated_packet_traversal(peer);
 		wg_timers_any_authenticated_packet_sent(peer);
 		atomic64_set(&peer->last_sent_handshake,
@@ -41,20 +125,81 @@ static void wg_packet_send_handshake_initiation(struct wg_peer *peer)
 					      HANDSHAKE_DSCP);
 		wg_timers_handshake_initiated(peer);
 	}
+	printk(KERN_INFO "Exiting wg_packet_send_handshake_initiation\n");
+}
+#endif
+
+static void wg_packet_send_handshake_initiation(struct wg_peer *peer)
+{
+	struct message_handshake_initiation packet;
+
+	/* Enter function with peer information */
+	printk(KERN_INFO "Entering wg_packet_send_handshake_initiation with peer=%p\n", peer);
+
+	/* Check rate limiting */
+	if (!wg_birthdate_has_expired(atomic64_read(&peer->last_sent_handshake), REKEY_TIMEOUT)) {
+		printk(KERN_INFO "wg_packet_send_handshake_initiation: Handshake rate limit not expired for peer=%p\n", peer);
+		printk(KERN_INFO "Exiting wg_packet_send_handshake_initiation\n");
+		return;
+	}
+
+	/* Update last sent handshake time */
+	atomic64_set(&peer->last_sent_handshake, ktime_get_coarse_boottime_ns());
+
+	/* Log handshake initiation attempt */
+	printk(KERN_INFO "%s: Sending handshake initiation to peer %llu (%pISpfsc)\n",
+	       peer->device->dev->name, peer->internal_id,
+	       &peer->endpoint.addr);
+
+	/* Create handshake initiation */
+	if (wg_noise_handshake_create_initiation(&packet, &peer->handshake)) {
+		printk(KERN_INFO "wg_packet_send_handshake_initiation: Handshake initiation created successfully for peer=%p\n", peer);
+
+		/* Print out the contents of the handshake initiation packet */
+		printk(KERN_INFO "wg_packet_send_handshake_initiation: Handshake packet contents: %*ph\n",
+		       (int)sizeof(packet), &packet);
+
+		/* Add MAC to packet */
+		wg_cookie_add_mac_to_packet(&packet, sizeof(packet), peer);
+		printk(KERN_INFO "wg_packet_send_handshake_initiation: MAC added to handshake packet for peer=%p\n", peer);
+
+		/* Timers and sending operations */
+		wg_timers_any_authenticated_packet_traversal(peer);
+		wg_timers_any_authenticated_packet_sent(peer);
+
+		/* Update last sent handshake time again */
+		atomic64_set(&peer->last_sent_handshake, ktime_get_coarse_boottime_ns());
+
+		/* Send the handshake packet */
+		wg_socket_send_buffer_to_peer(peer, &packet, sizeof(packet), HANDSHAKE_DSCP);
+		printk(KERN_INFO "wg_packet_send_handshake_initiation: Handshake packet sent to peer=%p\n", peer);
+
+		/* Mark handshake initiation complete */
+		wg_timers_handshake_initiated(peer);
+	} else {
+		/* Log failure to create handshake initiation */
+		printk(KERN_ERR "wg_packet_send_handshake_initiation: Failed to create handshake initiation for peer=%p\n", peer);
+	}
+
+	/* Exit function */
+	printk(KERN_INFO "Exiting wg_packet_send_handshake_initiation\n");
 }
 
 void wg_packet_handshake_send_worker(struct work_struct *work)
 {
+	printk(KERN_INFO "Entering wg_packet_handshake_send_worker with work=%p\n", work);
 	struct wg_peer *peer = container_of(work, struct wg_peer,
 					    transmit_handshake_work);
 
 	wg_packet_send_handshake_initiation(peer);
 	wg_peer_put(peer);
+	printk(KERN_INFO "Exiting wg_packet_handshake_send_worker\n");
 }
 
 void wg_packet_send_queued_handshake_initiation(struct wg_peer *peer,
 						bool is_retry)
 {
+	printk(KERN_INFO "Entering wg_packet_send_queued_handshake_initiation with peer=%p, is_retry=%d\n", peer, is_retry);
 	if (!is_retry)
 		peer->timer_handshake_attempts = 0;
 
@@ -80,10 +225,12 @@ void wg_packet_send_queued_handshake_initiation(struct wg_peer *peer,
 		wg_peer_put(peer);
 out:
 	rcu_read_unlock_bh();
+	printk(KERN_INFO "Exiting wg_packet_send_queued_handshake_initiation\n");
 }
 
 void wg_packet_send_handshake_response(struct wg_peer *peer)
 {
+	printk(KERN_INFO "Entering wg_packet_send_handshake_response with peer=%p\n", peer);
 	struct message_handshake_response packet;
 
 	atomic64_set(&peer->last_sent_handshake, ktime_get_coarse_boottime_ns());
@@ -93,6 +240,14 @@ void wg_packet_send_handshake_response(struct wg_peer *peer)
 
 	if (wg_noise_handshake_create_response(&packet, &peer->handshake)) {
 		wg_cookie_add_mac_to_packet(&packet, sizeof(packet), peer);
+
+		printk(KERN_INFO "MAC added to handshake response packet\n");
+		printk(KERN_INFO "Handshake Response Packet: %*ph\n",
+			(int)sizeof(packet), &packet);
+		printk(KERN_INFO "Peer Cookie Parameters: peer=%p, handshake=%p, index=%u\n",
+			peer, &peer->handshake, packet.sender_index);
+
+		
 		if (wg_noise_handshake_begin_session(&peer->handshake,
 						     &peer->keypairs)) {
 			wg_timers_session_derived(peer);
@@ -105,24 +260,41 @@ void wg_packet_send_handshake_response(struct wg_peer *peer)
 						      HANDSHAKE_DSCP);
 		}
 	}
+	printk(KERN_INFO "Exiting wg_packet_send_handshake_response\n");
 }
 
 void wg_packet_send_handshake_cookie(struct wg_device *wg,
 				     struct sk_buff *initiating_skb,
 				     __le32 sender_index)
 {
+	printk(KERN_INFO "Entering wg_packet_send_handshake_cookie with wg=%p, initiating_skb=%p, sender_index=%u\n", wg, initiating_skb, sender_index);
 	struct message_handshake_cookie packet;
 
+	printk(KERN_INFO "Creating handshake cookie\n");
+	printk(KERN_INFO "initiating_skb len=%u\n", initiating_skb->len);
+	printk(KERN_INFO "Initiating SKB Data: %*ph\n",
+	(int)initiating_skb->len, initiating_skb->data);
+
+	printk(KERN_INFO "Cookie Checker: %p\n", &wg->cookie_checker);
+
+	
 	net_dbg_skb_ratelimited("%s: Sending cookie response for denied handshake message for %pISpfsc\n",
 				wg->dev->name, initiating_skb);
 	wg_cookie_message_create(&packet, initiating_skb, sender_index,
 				 &wg->cookie_checker);
+
+	printk(KERN_INFO "Handshake Cookie Packet: %*ph\n",
+		(int)sizeof(packet), &packet);
+	
 	wg_socket_send_buffer_as_reply_to_skb(wg, initiating_skb, &packet,
 					      sizeof(packet));
+	
+	printk(KERN_INFO "Exiting wg_packet_send_handshake_cookie\n");
 }
 
 static void keep_key_fresh(struct wg_peer *peer)
 {
+	printk(KERN_INFO "Entering keep_key_fresh with peer=%p\n", peer);
 	struct noise_keypair *keypair;
 	bool send;
 
@@ -136,14 +308,18 @@ static void keep_key_fresh(struct wg_peer *peer)
 
 	if (unlikely(send))
 		wg_packet_send_queued_handshake_initiation(peer, false);
+	printk(KERN_INFO "Exiting keep_key_fresh\n");
 }
 
 static unsigned int calculate_skb_padding(struct sk_buff *skb)
 {
+	printk(KERN_INFO "Entering calculate_skb_padding with skb=%p\n", skb);
 	unsigned int padded_size, last_unit = skb->len;
 
-	if (unlikely(!PACKET_CB(skb)->mtu))
+	if (unlikely(!PACKET_CB(skb)->mtu)) {
+		printk(KERN_INFO "Exiting calculate_skb_padding\n");
 		return ALIGN(last_unit, MESSAGE_PADDING_MULTIPLE) - last_unit;
+	}
 
 	/* We do this modulo business with the MTU, just in case the networking
 	 * layer gives us a packet that's bigger than the MTU. In that case, we
@@ -156,11 +332,14 @@ static unsigned int calculate_skb_padding(struct sk_buff *skb)
 
 	padded_size = min(PACKET_CB(skb)->mtu,
 			  ALIGN(last_unit, MESSAGE_PADDING_MULTIPLE));
+	printk(KERN_INFO "Exiting calculate_skb_padding\n");
 	return padded_size - last_unit;
 }
 
+#ifdef ORIGINAL
 static bool encrypt_packet(struct sk_buff *skb, struct noise_keypair *keypair)
 {
+	printk(KERN_INFO "Entering encrypt_packet with skb=%p, keypair=%p\n", skb, keypair);
 	unsigned int padding_len, plaintext_len, trailer_len;
 	struct scatterlist sg[MAX_SKB_FRAGS + 8];
 	struct message_data *header;
@@ -179,8 +358,10 @@ static bool encrypt_packet(struct sk_buff *skb, struct noise_keypair *keypair)
 
 	/* Expand data section to have room for padding and auth tag. */
 	num_frags = skb_cow_data(skb, trailer_len, &trailer);
-	if (unlikely(num_frags < 0 || num_frags > ARRAY_SIZE(sg)))
+	if (unlikely(num_frags < 0 || num_frags > ARRAY_SIZE(sg))) {
+		printk(KERN_INFO "Exiting encrypt_packet\n");
 		return false;
+	}
 
 	/* Set the padding to zeros, and make sure it and the auth tag are part
 	 * of the skb.
@@ -190,13 +371,17 @@ static bool encrypt_packet(struct sk_buff *skb, struct noise_keypair *keypair)
 	/* Expand head section to have room for our header and the network
 	 * stack's headers.
 	 */
-	if (unlikely(skb_cow_head(skb, DATA_PACKET_HEAD_ROOM) < 0))
+	if (unlikely(skb_cow_head(skb, DATA_PACKET_HEAD_ROOM) < 0)) {
+		printk(KERN_INFO "Exiting encrypt_packet\n");
 		return false;
+	}
 
 	/* Finalize checksum calculation for the inner packet, if required. */
 	if (unlikely(skb->ip_summed == CHECKSUM_PARTIAL &&
-		     skb_checksum_help(skb)))
+		     skb_checksum_help(skb))) {
+		printk(KERN_INFO "Exiting encrypt_packet\n");
 		return false;
+	}
 
 	/* Only after checksumming can we safely add on the padding at the end
 	 * and the header.
@@ -211,22 +396,112 @@ static bool encrypt_packet(struct sk_buff *skb, struct noise_keypair *keypair)
 	/* Now we can encrypt the scattergather segments */
 	sg_init_table(sg, num_frags);
 	if (skb_to_sgvec(skb, sg, sizeof(struct message_data),
-			 noise_encrypted_len(plaintext_len)) <= 0)
+			 noise_encrypted_len(plaintext_len)) <= 0) {
+		printk(KERN_INFO "Exiting encrypt_packet\n");
 		return false;
+	}
+	printk(KERN_INFO "Exiting encrypt_packet\n");
 	return chacha20poly1305_encrypt_sg_inplace(sg, plaintext_len, NULL, 0,
 						   PACKET_CB(skb)->nonce,
 						   keypair->sending.key);
 }
+#endif // ORIGINAL
+
+static bool encrypt_packet(struct sk_buff *skb, struct noise_keypair *keypair)
+{
+    unsigned int padding_len, plaintext_len, trailer_len;
+    struct scatterlist sg[MAX_SKB_FRAGS + 8];
+    struct message_data *header;
+    struct sk_buff *trailer;
+    int num_frags;
+
+    printk(KERN_INFO "Entering encrypt_packet with skb=%p, keypair=%p\n", skb, keypair);
+    printk(KERN_INFO "skb->len = %u, skb->data_len = %u, skb->network_header = %p\n", skb->len, skb->data_len, skb_network_header(skb));
+    printk(KERN_INFO "keypair->remote_index = %u\n", keypair->remote_index);
+    printk(KERN_INFO "skb->data (before encryption): %*ph\n", skb->len, skb->data);
+	
+    // Force hash calculation before encryption
+    skb_get_hash(skb);
+    printk(KERN_INFO "Hash calculated for skb.\n");
+
+    // Calculate lengths
+    padding_len = calculate_skb_padding(skb);
+    trailer_len = padding_len + noise_encrypted_len(0);
+    plaintext_len = skb->len + padding_len;
+    printk(KERN_INFO "Calculated lengths: padding_len=%u, trailer_len=%u, plaintext_len=%u\n", padding_len, trailer_len, plaintext_len);
+
+    // Expand data section
+    num_frags = skb_cow_data(skb, trailer_len, &trailer);
+    if (unlikely(num_frags < 0 || num_frags > ARRAY_SIZE(sg))) {
+        printk(KERN_ERR "Failed skb_cow_data: num_frags=%d, skb->len=%u\n", num_frags, skb->len);
+        printk(KERN_ERR "Exiting encrypt_packet with false\n");
+        return false;
+    }
+
+    // Set the padding to zeros
+    memset(skb_tail_pointer(trailer), 0, padding_len);
+    printk(KERN_INFO "Padding set to zeros: padding_len=%u, skb->len=%u\n", padding_len, skb->len);
+
+    // Expand head section
+    if (unlikely(skb_cow_head(skb, DATA_PACKET_HEAD_ROOM) < 0)) {
+        printk(KERN_ERR "Failed skb_cow_head, skb->len=%u, skb->head=%p\n", skb->len, skb->head);
+        printk(KERN_ERR "Exiting encrypt_packet with false\n");
+        return false;
+    }
+    printk(KERN_INFO "Expanded head section, skb->len=%u, skb->head=%p\n", skb->len, skb->head);
+
+    // Finalize checksum calculation
+    if (unlikely(skb->ip_summed == CHECKSUM_PARTIAL && skb_checksum_help(skb))) {
+        printk(KERN_ERR "Failed skb_checksum_help, skb->len=%u\n", skb->len);
+        printk(KERN_ERR "Exiting encrypt_packet with false\n");
+        return false;
+    }
+    printk(KERN_INFO "Checksum finalized, skb->len=%u\n", skb->len);
+
+    // Add padding and header
+    skb_set_inner_network_header(skb, 0);
+    header = (struct message_data *)skb_push(skb, sizeof(*header));
+    header->header.type = cpu_to_le32(MESSAGE_DATA);
+    header->key_idx = keypair->remote_index;
+    header->counter = cpu_to_le64(PACKET_CB(skb)->nonce);
+    printk(KERN_INFO "Nonce for encryption: %llu\n", PACKET_CB(skb)->nonce);
+#define NOISE_KEY_LEN 32
+    printk(KERN_INFO "Encryption key: %*ph\n", NOISE_KEY_LEN, keypair->sending.key);
+    pskb_put(skb, trailer, trailer_len);
+    printk(KERN_INFO "Header and padding added: type=%u, key_idx=%u, counter=%llu\n",
+           MESSAGE_DATA, keypair->remote_index, PACKET_CB(skb)->nonce);
+    printk(KERN_INFO "Network header set: skb_network_header=%p, skb->len=%u\n", skb_network_header(skb), skb->len);
+
+    // Encrypt the scattergather segments
+    sg_init_table(sg, num_frags);
+    if (skb_to_sgvec(skb, sg, sizeof(struct message_data), noise_encrypted_len(plaintext_len)) <= 0) {
+        printk(KERN_ERR "Failed skb_to_sgvec, skb->len=%u\n", skb->len);
+        printk(KERN_ERR "Exiting encrypt_packet with false\n");
+        return false;
+    }
+
+    printk(KERN_INFO "Scattergather segments prepared, starting encryption\n");
+
+    bool success = chacha20poly1305_encrypt_sg_inplace(sg, plaintext_len, NULL, 0,
+                                                       PACKET_CB(skb)->nonce,
+                                                       keypair->sending.key);
+    printk(KERN_INFO "skb->data (after encryption): %*ph\n", skb->len, skb->data);
+    printk(KERN_INFO "Exiting encrypt_packet with %s, skb->len=%u\n", success ? "true" : "false", skb->len);
+    return success;
+}
 
 void wg_packet_send_keepalive(struct wg_peer *peer)
 {
+	printk(KERN_INFO "Entering wg_packet_send_keepalive with peer=%p\n", peer);
 	struct sk_buff *skb;
 
 	if (skb_queue_empty(&peer->staged_packet_queue)) {
 		skb = alloc_skb(DATA_PACKET_HEAD_ROOM + MESSAGE_MINIMUM_LENGTH,
 				GFP_ATOMIC);
-		if (unlikely(!skb))
+		if (unlikely(!skb)) {
+			printk(KERN_INFO "Exiting wg_packet_send_keepalive\n");
 			return;
+		}
 		skb_reserve(skb, DATA_PACKET_HEAD_ROOM);
 		skb->dev = peer->device->dev;
 		PACKET_CB(skb)->mtu = skb->dev->mtu;
@@ -237,10 +512,12 @@ void wg_packet_send_keepalive(struct wg_peer *peer)
 	}
 
 	wg_packet_send_staged_packets(peer);
+	printk(KERN_INFO "Exiting wg_packet_send_keepalive\n");
 }
 
 static void wg_packet_create_data_done(struct wg_peer *peer, struct sk_buff *first)
 {
+	printk(KERN_INFO "Entering wg_packet_create_data_done with peer=%p, first=%p\n", peer, first);
 	struct sk_buff *skb, *next;
 	bool is_keepalive, data_sent = false;
 
@@ -257,10 +534,12 @@ static void wg_packet_create_data_done(struct wg_peer *peer, struct sk_buff *fir
 		wg_timers_data_sent(peer);
 
 	keep_key_fresh(peer);
+	printk(KERN_INFO "Exiting wg_packet_create_data_done\n");
 }
 
 void wg_packet_tx_worker(struct work_struct *work)
 {
+	printk(KERN_INFO "Entering wg_packet_tx_worker with work=%p\n", work);
 	struct wg_peer *peer = container_of(work, struct wg_peer, transmit_packet_work);
 	struct noise_keypair *keypair;
 	enum packet_state state;
@@ -282,10 +561,12 @@ void wg_packet_tx_worker(struct work_struct *work)
 		if (need_resched())
 			cond_resched();
 	}
+	printk(KERN_INFO "Exiting wg_packet_tx_worker\n");
 }
 
 void wg_packet_encrypt_worker(struct work_struct *work)
 {
+	printk(KERN_INFO "Entering wg_packet_encrypt_worker with work=%p\n", work);
 	struct crypt_queue *queue = container_of(work, struct multicore_worker,
 						 work)->ptr;
 	struct sk_buff *first, *skb, *next;
@@ -306,10 +587,14 @@ void wg_packet_encrypt_worker(struct work_struct *work)
 		if (need_resched())
 			cond_resched();
 	}
+	printk(KERN_INFO "Exiting wg_packet_encrypt_worker\n");
 }
 
+
+
 static void wg_packet_create_data(struct wg_peer *peer, struct sk_buff *first)
 {
+	printk(KERN_INFO "Entering wg_packet_create_data with peer=%p, first=%p\n", peer, first);
 	struct wg_device *wg = peer->device;
 	int ret = -EINVAL;
 
@@ -317,30 +602,39 @@ static void wg_packet_create_data(struct wg_peer *peer, struct sk_buff *first)
 	if (unlikely(READ_ONCE(peer->is_dead)))
 		goto err;
 
+	printk("wg_packet_create_data sending: %*ph\n", first->len, first->data);
+	
 	ret = wg_queue_enqueue_per_device_and_peer(&wg->encrypt_queue, &peer->tx_queue, first,
 						   wg->packet_crypt_wq);
 	if (unlikely(ret == -EPIPE))
 		wg_queue_enqueue_per_peer_tx(first, PACKET_STATE_DEAD);
+
 err:
 	rcu_read_unlock_bh();
-	if (likely(!ret || ret == -EPIPE))
+	if (likely(!ret || ret == -EPIPE)) {
+		printk(KERN_INFO "Exiting wg_packet_create_data\n");
 		return;
+	}
 	wg_noise_keypair_put(PACKET_CB(first)->keypair, false);
 	wg_peer_put(peer);
 	kfree_skb_list(first);
+	printk(KERN_INFO "Exiting wg_packet_create_data with error.\n");
 }
 
 void wg_packet_purge_staged_packets(struct wg_peer *peer)
 {
+	printk(KERN_INFO "Entering wg_packet_purge_staged_packets with peer=%p\n", peer);
 	spin_lock_bh(&peer->staged_packet_queue.lock);
 	DEV_STATS_ADD(peer->device->dev, tx_dropped,
 		      peer->staged_packet_queue.qlen);
 	__skb_queue_purge(&peer->staged_packet_queue);
 	spin_unlock_bh(&peer->staged_packet_queue.lock);
+	printk(KERN_INFO "Exiting wg_packet_purge_staged_packets\n");
 }
 
 void wg_packet_send_staged_packets(struct wg_peer *peer)
 {
+	printk(KERN_INFO "Entering wg_packet_send_staged_packets with peer=%p\n", peer);
 	struct noise_keypair *keypair;
 	struct sk_buff_head packets;
 	struct sk_buff *skb;
@@ -350,8 +644,10 @@ void wg_packet_send_staged_packets(struct wg_peer *peer)
 	spin_lock_bh(&peer->staged_packet_queue.lock);
 	skb_queue_splice_init(&peer->staged_packet_queue, &packets);
 	spin_unlock_bh(&peer->staged_packet_queue.lock);
-	if (unlikely(skb_queue_empty(&packets)))
+	if (unlikely(skb_queue_empty(&packets))) {
+		printk(KERN_INFO "Exiting wg_packet_send_staged_packets\n");
 		return;
+	}
 
 	/* First we make sure we have a valid reference to a valid key. */
 	rcu_read_lock_bh();
@@ -386,6 +682,7 @@ void wg_packet_send_staged_packets(struct wg_peer *peer)
 	wg_peer_get(keypair->entry.peer);
 	PACKET_CB(packets.next)->keypair = keypair;
 	wg_packet_create_data(peer, packets.next);
+	printk(KERN_INFO "Exiting wg_packet_send_staged_packets\n");
 	return;
 
 out_invalid:
@@ -411,4 +708,5 @@ void wg_packet_send_staged_packets(struct wg_peer *peer)
 	 * means we should initiate a new handshake.
 	 */
 	wg_packet_send_queued_handshake_initiation(peer, false);
+	printk(KERN_INFO "Exiting wg_packet_send_staged_packets\n");
 }
diff --git a/wireguard-linux/drivers/net/wireguard/socket.c b/wireguard-linux/drivers/net/wireguard/socket.c
index 0414d7a6ce74..51d1fc5ebfa7 100644
--- a/wireguard-linux/drivers/net/wireguard/socket.c
+++ b/wireguard-linux/drivers/net/wireguard/socket.c
@@ -3,23 +3,350 @@
  * Copyright (C) 2015-2019 Jason A. Donenfeld <Jason@zx2c4.com>. All Rights Reserved.
  */
 
+/* TCP Support by Jeff Nathan and Dragos Ruiu 2024-03-16 */
+
 #include "device.h"
 #include "peer.h"
 #include "socket.h"
 #include "queueing.h"
 #include "messages.h"
 
+#include <asm/byteorder.h> // For ntohl
 #include <linux/ctype.h>
-#include <linux/net.h>
 #include <linux/if_vlan.h>
 #include <linux/if_ether.h>
 #include <linux/inetdevice.h>
+#include <linux/wireguard.h>
+#include <linux/kernel.h>
+#include <linux/skbuff.h>
+#include <linux/net.h>
+#include <linux/tcp.h>
+#include <linux/time.h>
+#include <linux/ktime.h>
+#include <linux/in.h>
+#include <linux/inet.h>
+#include <linux/kthread.h>
+#include <linux/workqueue.h>
+#include <linux/spinlock.h>
+#include <linux/socket.h>
+#include <linux/in6.h>
+#include <net/checksum.h>
 #include <net/udp_tunnel.h>
 #include <net/ipv6.h>
+#include <net/sock.h>
+#include <net/udp.h>
+#include <net/inet_sock.h>
+#include <net/inet_common.h>
+
+
+
+struct wg_tcp_socket_list_entry {
+    struct socket *tcp_socket;        // Socket associated with the connection
+    struct sockaddr_storage src_addr; // Source address for the connection
+    struct wg_peer *temp_peer;	      // temporary peer for dataready
+    struct list_head tcp_connection_ll;  // List pointer for the linked list
+    ktime_t timestamp;                // Timestamp when the connection was added
+};
+
+struct wg_socket_data {
+	struct wg_device *device;
+	struct wg_peer *peer;
+	bool inbound;
+};
+
+// Global structure to hold default network interface information
+struct default_interface_info {
+    struct net_device *dev;   // Default network interface
+    __be32 ipv4_address;      // IPv4 address of the default interface
+    struct in6_addr ipv6_address; // IPv6 address of the default interface
+    bool ipv4_available;      // Flag indicating if IPv4 is available
+    bool ipv6_available;      // Flag indicating if IPv6 is available
+};
+
+extern struct default_interface_info default_iface_info;
+
+void wg_setup_tcp_socket_callbacks(struct wg_peer *peer, bool inbound);
+void wg_reset_tcp_socket_callbacks(struct wg_peer *peer, bool inbound);
+void wg_get_endpoint_from_socket(struct socket *epsocket, struct endpoint *ep);
+void log_wireguard_endpoint(struct endpoint *ep);
+
+// ******** DIAGNOSTIC CODE ********
+
+#include <linux/module.h>
+#include <linux/list.h>
+#include <linux/timer.h>
+#include <linux/workqueue.h>
+#include <linux/rcupdate.h>
+#include <linux/kref.h>
+#include <linux/syslog.h>
+
+// Function to print details of sk_buff_head for diagnostic purposes
+void print_skbuff_head_info(const char *label, struct sk_buff_head *queue);
+
+void print_skbuff_head_info(const char *label, struct sk_buff_head *queue)
+{
+	const struct sk_buff *skb;
+	unsigned long flags;
+
+	printk(KERN_INFO "%s:\n", label);
+	if (!queue) {
+		printk(KERN_INFO "Queue is NULL\n");
+		return;
+	}
+
+	spin_lock_irqsave(&queue->lock, flags);
+	skb_queue_walk(queue, skb) {
+		printk(KERN_INFO "Packet: len=%u, data_len=%u, users=%d\n",
+		        skb->len, skb->data_len, refcount_read(&skb->users));
+	}
+	spin_unlock_irqrestore(&queue->lock, flags);
+}
+
+void print_wg_peer(struct wg_peer *peer);
+
+void print_wg_peer(struct wg_peer *peer)
+{
+	if (!peer || IS_ERR(peer)) {
+		printk(KERN_ERR "NULL wg_peer provided\n");
+		return;
+	}
+
+	printk(KERN_INFO "WG Peer Complete Diagnostic Info:\n");
+	printk(KERN_INFO "Device Pointer: %p, Serial Work CPU: %d, "
+			"Is Dead: %d, (Device) Transport Mode: %u\n",
+			peer->device, peer->serial_work_cpu, peer->is_dead,
+			peer->device->transport);
+	printk(KERN_INFO "RX Bytes: %llu, TX Bytes: %llu, Internal ID: %llu\n",
+			peer->rx_bytes, peer->tx_bytes, peer->internal_id);
+	printk(KERN_INFO "Last Sent Handshake: %llu\n",
+			atomic64_read(&peer->last_sent_handshake));
+
+	// Endpoint info
+	printk(KERN_INFO "Endpoint Address Family: %u\n",
+			peer->endpoint.addr.sa_family);
+	if (peer->endpoint.addr.sa_family == AF_INET) {
+        printk(KERN_INFO "IPv4 Address: %pI4, IPv4 Source: %pI4, "
+			"Interface: %d\n",
+			&peer->endpoint.addr4.sin_addr, &peer->endpoint.src4,
+			peer->endpoint.src_if4);
+	} else if (peer->endpoint.addr.sa_family == AF_INET6) {
+		printk(KERN_INFO "IPv6 Address: %pI6c, IPv6 Source: %pI6c\n",
+				&peer->endpoint.addr6.sin6_addr, &peer->endpoint.src6);
+	}
+
+	// Correctly accessing sk_buff_head queues
+	if (!skb_queue_empty(&peer->staged_packet_queue)) {
+		print_skbuff_head_info("Staged Packet Queue",
+				&peer->staged_packet_queue);
+	} else {
+		printk(KERN_INFO "Staged Packet Queue: NULL\n");
+	}
+
+	// Additional diagnostics and corrections for TCP
+	if (peer->peer_socket) {
+		printk(KERN_INFO "TCP Socket: %p, Established: %d\n",
+				peer->peer_socket, peer->tcp_established);
+		if (!skb_queue_empty(&peer->tcp_packet_queue)) {
+			print_skbuff_head_info("TCP Packet Queue",
+					&peer->tcp_packet_queue);
+		} else {
+			printk(KERN_INFO "TCP Packet Queue: NULL\n");
+		}
+	} else {
+		printk(KERN_INFO "TCP Socket: NULL\n");
+	}
+
+	// Timer diagnostics
+	printk(KERN_INFO "Timer for Retransmit Handshake Expires: %ld\n",
+			peer->timer_retransmit_handshake.expires);
+	printk(KERN_INFO "Timer for Sending Keepalive Expires: %ld\n",
+			peer->timer_send_keepalive.expires);
+	printk(KERN_INFO "Timer for New Handshake Expires: %ld\n",
+			peer->timer_new_handshake.expires);
+	printk(KERN_INFO "Timer for Zero Key Material Expires: %ld\n",
+			peer->timer_zero_key_material.expires);
+	printk(KERN_INFO "Timer for Persistent Keepalive Expires: %ld\n",
+			peer->timer_persistent_keepalive.expires);
+
+	// RCU and reference count
+	printk(KERN_INFO "RCU Head Address: %p, Reference Count: %d\n",
+			&peer->rcu, kref_read(&peer->refcount));
+}
+
+// Function to print information about crypt_queue
+void print_crypt_queue(const char *label, struct crypt_queue *queue);
+
+void print_crypt_queue(const char *label, struct crypt_queue *queue)
+{
+	if (!queue) {
+		printk(KERN_INFO "%s: NULL\n", label);
+		return;
+	}
+
+	printk(KERN_INFO "%s:\n", label);
+	printk(KERN_INFO "  Last CPU used: %d\n", queue->last_cpu);
+	// Assuming you have a way to inspect ptr_ring structure:
+	// printk(KERN_INFO "  Ring capacity: %d\n", queue->ring.size);
+	if (queue->worker)
+		printk(KERN_INFO "  Worker pointer: %p\n", queue->worker);
+	else
+		printk(KERN_INFO "  Worker: NULL\n");
+}
+
+// Diagnostic function for wg_device
+void print_wg_device(struct wg_device *device);
+
+void print_wg_device(struct wg_device *device)
+{
+	if (!device) {
+		printk(KERN_ERR "NULL wg_device provided\n");
+		return;
+	}
+
+	printk(KERN_INFO "WG Device Diagnostic Info:\n");
+
+	if (device->dev)
+		printk(KERN_INFO "Net device: %s\n", device->dev->name);
+	else
+		printk(KERN_INFO "Net device: NULL\n");
+
+	print_crypt_queue("Encrypt Queue", &(device->encrypt_queue));
+	print_crypt_queue("Decrypt Queue", &(device->decrypt_queue));
+	print_crypt_queue("Handshake Queue", &(device->handshake_queue));
+
+	if (rcu_access_pointer(device->tcp_listen_socket4))
+		printk(KERN_INFO "IPv4 Socket: %p\n", device->tcp_listen_socket4);
+	else
+		printk(KERN_INFO "IPv4 Socket: NULL\n");
+
+	if (rcu_access_pointer(device->tcp_listen_socket6))
+		printk(KERN_INFO "IPv6 Socket: %p\n", device->tcp_listen_socket6);
+	else
+		printk(KERN_INFO "IPv6 Socket: NULL\n");
+
+	if (rcu_access_pointer(device->tcp_listen_socket4))
+		printk(KERN_INFO "TCP Listener IPv4 Socket: %p\n",
+				device->tcp_listen_socket4);
+	else
+		printk(KERN_INFO "TCP Listener IPv4 Socket: NULL\n");
+
+	if (rcu_access_pointer(device->tcp_listen_socket6))
+		printk(KERN_INFO "TCP Listener IPv6 Socket: %p\n",
+				device->tcp_listen_socket6);
+	else
+		printk(KERN_INFO "TCP Listener IPv6 Socket: NULL\n");
+
+	if (device->creating_net)
+		printk(KERN_INFO "Creating net namespace: %p\n",
+				device->creating_net);
+	else
+		printk(KERN_INFO "Creating net namespace: NULL\n");
+
+	// Assuming noise_static_identity and other structures have similar diagnostic print functions
+	printk(KERN_INFO "Static Identity: (printing details not implemented)\n");
+	printk(KERN_INFO "Workqueues and other components would similarly have their details printed based on available data.\n");
+
+	printk(KERN_INFO "FW Mark: %u, Incoming Port: %u, Transport: %u\n", device->fwmark, device->incoming_port, device->transport);
+	printk(KERN_INFO "Handshake queue length: %d\n", atomic_read(&device->handshake_queue_len));
+	printk(KERN_INFO "Number of Peers: %u, Device Update Generation: %u\n", device->num_peers, device->device_update_gen);
+}
+
+
+// Diagnostic function to print TCP state and sk_user_data
+void print_tcp_socket_info(struct socket *sock, const char *label) {
+    struct sock *sk;
+    struct wg_socket_data *user_data;
+    int tcp_state = -1;
+
+    if (sock && sock->sk) {
+        sk = sock->sk;
+        user_data = (struct wg_socket_data *)sk->sk_user_data;
+        tcp_state = (sk->sk_protocol == IPPROTO_TCP) ? sk->sk_state : -1;
+        if (user_data) {
+            printk(KERN_INFO "%s: socket=%p, sk_user_data=%p (device=%p, peer=%p, inbound=%d), TCP state=%d\n",
+                   label, sock, user_data, user_data->device, user_data->peer, user_data->inbound, tcp_state);
+        } else {
+            printk(KERN_INFO "%s: socket=%p, sk_user_data=NULL, TCP state=%d\n",
+                   label, sock, tcp_state);
+        }
+    } else {
+        printk(KERN_INFO "%s: Socket or sk is NULL\n", label);
+    }
+}
+
+// Function to print compact diagnostic information for all sockets in a peer
+void print_peer_socket_info(struct wg_peer *peer) {
+    if (!peer) {
+        printk(KERN_INFO "print_peer_socket_info: peer is NULL\n");
+        return;
+    }
+
+    // Print the pointers to the main sockets in the peer
+    printk(KERN_INFO "Peer: %p, peer_socket=%p, inbound_socket=%p, outbound_socket=%p\n",
+           peer, peer->peer_socket, peer->inbound_socket, peer->outbound_socket);
+
+    // Print inbound timestamp
+    printk(KERN_INFO "Inbound timestamp: %llu ns\n", ktime_to_ns(peer->inbound_timestamp));
+
+    // Print outbound timestamp
+    printk(KERN_INFO "Outbound timestamp: %llu ns\n", ktime_to_ns(peer->outbound_timestamp));
+
+    // Print combined information for inbound socket
+    if (peer->inbound_socket) {
+        print_tcp_socket_info(peer->inbound_socket, "Inbound Socket");
+    } else {
+        printk(KERN_INFO "Inbound Socket is NULL\n");
+    }
+
+    // Print combined information for outbound socket
+    if (peer->outbound_socket) {
+        print_tcp_socket_info(peer->outbound_socket, "Outbound Socket");
+    } else {
+        printk(KERN_INFO "Outbound Socket is NULL\n");
+    }
+
+    // Additional validation check
+    if (peer->peer_socket == peer->inbound_socket) {
+        printk(KERN_INFO "peer_socket matches inbound_socket\n");
+    } else if (peer->peer_socket == peer->outbound_socket) {
+        printk(KERN_INFO "peer_socket matches outbound_socket\n");
+    } else {
+        printk(KERN_WARNING "peer_socket does not match inbound_socket or outbound_socket\n");
+    }
+}
+// ******** END OF DIAGNOSTIC CODE ********
+
+
+
+// Function to create and return an endpoint from source and destination sockaddr_in
+struct endpoint create_endpoint(const struct sockaddr_in *source, const struct sockaddr_in *destination) {
+    struct endpoint ep;
+
+    // Initialize the endpoint to zero
+    memset(&ep, 0, sizeof(struct endpoint));
+
+    // Set the address family to AF_INET
+    ep.addr.sa_family = AF_INET;
+
+    // Copy the destination address to the endpoint's addr4 field
+    ep.addr4.sin_family = AF_INET;
+    ep.addr4.sin_port = destination->sin_port;       // Destination port (network byte order)
+    ep.addr4.sin_addr = destination->sin_addr;       // Destination IP address
+
+    // Copy the source address to the endpoint's source fields
+    ep.src4 = source->sin_addr;                      // Source IP address
+    // ep.src_if4 can be set here if you have an interface index
+
+    return ep; // Return the populated endpoint structure
+}
+
 
 static int send4(struct wg_device *wg, struct sk_buff *skb,
 		 struct endpoint *endpoint, u8 ds, struct dst_cache *cache)
 {
+	printk(KERN_INFO "Entering function send4\n");
+
+
 	struct flowi4 fl = {
 		.saddr = endpoint->src4.s_addr,
 		.daddr = endpoint->addr4.sin_addr.s_addr,
@@ -92,12 +419,16 @@ static int send4(struct wg_device *wg, struct sk_buff *skb,
 out:
 	rcu_read_unlock_bh();
 	return ret;
+	printk(KERN_INFO "Exiting function send4\n");
 }
 
 static int send6(struct wg_device *wg, struct sk_buff *skb,
 		 struct endpoint *endpoint, u8 ds, struct dst_cache *cache)
 {
+	printk(KERN_INFO "Entering function send6\n");
 #if IS_ENABLED(CONFIG_IPV6)
+
+
 	struct flowi6 fl = {
 		.saddr = endpoint->src6,
 		.daddr = endpoint->addr6.sin6_addr,
@@ -158,52 +489,183 @@ static int send6(struct wg_device *wg, struct sk_buff *skb,
 	kfree_skb(skb);
 out:
 	rcu_read_unlock_bh();
+	printk(KERN_INFO "Exiting function send6\n");
 	return ret;
 #else
 	kfree_skb(skb);
+	printk(KERN_INFO "Exiting function send6\n");
 	return -EAFNOSUPPORT;
 #endif
+	printk(KERN_INFO "Exiting function send6\n");
+}
+
+void wg_tcp_transfer_worker(struct work_struct *work);
+
+void wg_tcp_transfer_worker(struct work_struct *work)
+{
+	printk(KERN_INFO "Entering wg_tcp_transfer_worker with work=%p\n", work);
+
+	// Validate the work structure
+	if (!work) {
+		printk(KERN_ERR "wg_tcp_transfer_worker: work is NULL\n");
+		return;
+	}
+
+	// Get the wg_tcp_transfer_work container
+	struct wg_tcp_transfer_work *work_item = container_of(work, struct wg_tcp_transfer_work, work);
+
+	// Validate the work_item structure
+	if (!work_item) {
+		printk(KERN_ERR "wg_tcp_transfer_worker: work_item is NULL\n");
+		return;
+	}
+
+	// Extract peer and skb from the work item
+	struct wg_peer *peer = work_item->peer;
+	struct sk_buff *skb = work_item->skb;
+
+	// Validate the peer structure
+	if (!peer || IS_ERR(peer)) {
+		printk(KERN_ERR "wg_tcp_transfer_worker: peer is NULL or invalid\n");
+		goto out;
+	}
+	print_peer_socket_info(peer);
+	// Validate the sk_buff structure before processing
+	if (skb) {
+		// Log diagnostic information about the skb
+		printk(KERN_INFO "wg_tcp_transfer_worker: Processing skb with len=%u peer=%p\n", skb->len, peer);
+
+		// Process the packet by passing it to wg_tcp_queuepkt
+		wg_tcp_queuepkt(peer, skb->data, skb->len);
+	} else {
+		printk(KERN_ERR "wg_tcp_transfer_worker: skb is NULL\n");
+	}
+
+out:
+	// Free the skb if it was allocated
+	if (skb) {
+		kfree_skb(skb);
+	}
+
+	// Free the work item structure
+	if (work_item) {
+		kfree(work_item);
+	}
+
+	// Validate and update the peer's tcp_transfer_worker_scheduled flag
+	if (peer && !IS_ERR(peer)) {
+		spin_lock_bh(&peer->tcp_transfer_lock);
+		peer->tcp_transfer_worker_scheduled = false;
+		spin_unlock_bh(&peer->tcp_transfer_lock);
+	} else {
+		printk(KERN_ERR "wg_tcp_transfer_worker: peer is NULL or invalid during cleanup\n");
+	}
+
+	printk(KERN_INFO "Exiting wg_tcp_transfer_worker\n");
 }
 
+
 int wg_socket_send_skb_to_peer(struct wg_peer *peer, struct sk_buff *skb, u8 ds)
 {
+	printk(KERN_INFO "Entering function wg_socket_send_skb_to_peer\n");
 	size_t skb_len = skb->len;
 	int ret = -EAFNOSUPPORT;
 
-	read_lock_bh(&peer->endpoint_lock);
-	if (peer->endpoint.addr.sa_family == AF_INET)
-		ret = send4(peer->device, skb, &peer->endpoint, ds,
-			    &peer->endpoint_cache);
-	else if (peer->endpoint.addr.sa_family == AF_INET6)
-		ret = send6(peer->device, skb, &peer->endpoint, ds,
-			    &peer->endpoint_cache);
-	else
-		dev_kfree_skb(skb);
-	if (likely(!ret))
-		peer->tx_bytes += skb_len;
-	read_unlock_bh(&peer->endpoint_lock);
+	if (unlikely(!peer) || unlikely(IS_ERR(peer))){
+		ret = -EINVAL;
+		goto out;
+	}
+	if (unlikely(!skb)){
+		ret = -ENOMEM;
+		goto out;
+	}
+	
+	print_peer_socket_info(peer);
+	
+        if (peer->device->transport == WG_TRANSPORT_TCP) {
+		struct wg_tcp_transfer_work *work_item;
 
+		/* Allocate the work item */
+		work_item = kmalloc(sizeof(*work_item), GFP_ATOMIC);
+		if (unlikely(!work_item)) {
+			printk(KERN_INFO "Exiting wg_queue_enqueue_per_peer_tx - UNABLE TO ALLOCATE WORK ITEM \n");
+//			wg_peer_put(peer);
+			ret = -ENOMEM;
+			goto out;
+		}
+
+		/* Initialize the work item */
+		INIT_WORK(&work_item->work, wg_tcp_transfer_worker);
+		work_item->skb = skb;
+		work_item->peer = peer;
+
+		printk(KERN_INFO "Work item scheduled peer=%p skb=%p\n", peer, skb);
+		// Check if the worker is already scheduled
+		if (!peer->tcp_transfer_worker_scheduled) {
+			peer->tcp_transfer_worker_scheduled = true;
+			queue_work(peer->tcp_transfer_wq, &work_item->work);
+		}
+		ret = 0;
+	} else {
+		read_lock_bh(&peer->endpoint_lock);	
+		if (peer->endpoint.addr.sa_family == AF_INET)
+			ret = send4(peer->device, skb, &peer->endpoint, ds,
+		    		&peer->endpoint_cache);
+		else if (peer->endpoint.addr.sa_family == AF_INET6)
+			ret = send6(peer->device, skb, &peer->endpoint, ds,
+			    	&peer->endpoint_cache);
+		else {
+			read_unlock_bh(&peer->endpoint_lock);
+			dev_kfree_skb(skb);
+			printk(KERN_INFO "Exiting function wg_socket_send_skb_to_peer\n");
+			return -EAGAIN;
+		}
+		read_unlock_bh(&peer->endpoint_lock);
+	}
+	peer->tx_bytes += skb_len;
+out:
+	printk(KERN_INFO "Exiting function wg_socket_send_skb_to_peer\n");
 	return ret;
+
 }
 
 int wg_socket_send_buffer_to_peer(struct wg_peer *peer, void *buffer,
 				  size_t len, u8 ds)
 {
+	int ret;
+	
+	printk(KERN_INFO "Entering function wg_socket_send_buffer_to_peer peer=%p\n", peer);
+	log_wireguard_endpoint(&peer->endpoint);
 	struct sk_buff *skb = alloc_skb(len + SKB_HEADER_LEN, GFP_ATOMIC);
 
-	if (unlikely(!skb))
-		return -ENOMEM;
+	printk(KERN_INFO "Sending buffer to peer - Length: %zu, Data: %*ph\n",
+		len, (int)len, buffer);
 
+	
+	if (unlikely(!peer) || unlikely(IS_ERR(peer))) {
+		ret = -EINVAL;
+		goto out;
+	}
+	if (unlikely(!skb)){
+		ret = -ENOMEM;
+		goto out;
+	}
+	
 	skb_reserve(skb, SKB_HEADER_LEN);
 	skb_set_inner_network_header(skb, 0);
 	skb_put_data(skb, buffer, len);
-	return wg_socket_send_skb_to_peer(peer, skb, ds);
+	ret = wg_socket_send_skb_to_peer(peer, skb, ds);
+
+out:
+	printk(KERN_INFO "Exiting function wg_socket_send_buffer_to_peer\n");
+	return ret;
 }
 
 int wg_socket_send_buffer_as_reply_to_skb(struct wg_device *wg,
 					  struct sk_buff *in_skb, void *buffer,
 					  size_t len)
 {
+	printk(KERN_INFO "Entering function wg_socket_send_buffer_as_reply_to_skb\n");
 	int ret = 0;
 	struct sk_buff *skb;
 	struct endpoint endpoint;
@@ -229,12 +691,17 @@ int wg_socket_send_buffer_as_reply_to_skb(struct wg_device *wg,
 	 * as we checked above.
 	 */
 
+	printk(KERN_INFO "Exiting function wg_socket_send_buffer_as_reply_to_skb\n");
 	return ret;
 }
 
-int wg_socket_endpoint_from_skb(struct endpoint *endpoint,
-				const struct sk_buff *skb)
+
+int wg_socket_endpoint_from_skb(struct endpoint *endpoint, const struct sk_buff *skb)
 {
+	printk(KERN_INFO "Entering function wg_socket_endpoint_from_skb\n");
+
+	printk(KERN_INFO "skb data: %*ph\n", skb->len, skb->data);
+	
 	memset(endpoint, 0, sizeof(*endpoint));
 	if (skb->protocol == htons(ETH_P_IP)) {
 		endpoint->addr4.sin_family = AF_INET;
@@ -242,21 +709,29 @@ int wg_socket_endpoint_from_skb(struct endpoint *endpoint,
 		endpoint->addr4.sin_addr.s_addr = ip_hdr(skb)->saddr;
 		endpoint->src4.s_addr = ip_hdr(skb)->daddr;
 		endpoint->src_if4 = skb->skb_iif;
+		printk(KERN_INFO "wg_socket_endpoint_from_skb: Extracted IPv4 address %pI4:%d\n",
+		       &endpoint->addr4.sin_addr, ntohs(endpoint->addr4.sin_port));
 	} else if (IS_ENABLED(CONFIG_IPV6) && skb->protocol == htons(ETH_P_IPV6)) {
 		endpoint->addr6.sin6_family = AF_INET6;
 		endpoint->addr6.sin6_port = udp_hdr(skb)->source;
 		endpoint->addr6.sin6_addr = ipv6_hdr(skb)->saddr;
-		endpoint->addr6.sin6_scope_id = ipv6_iface_scope_id(
-			&ipv6_hdr(skb)->saddr, skb->skb_iif);
+		endpoint->addr6.sin6_scope_id = ipv6_iface_scope_id(&ipv6_hdr(skb)->saddr, skb->skb_iif);
 		endpoint->src6 = ipv6_hdr(skb)->daddr;
+		printk(KERN_INFO "wg_socket_endpoint_from_skb: Extracted IPv6 address %pI6c:%d\n",
+		       &endpoint->addr6.sin6_addr, ntohs(endpoint->addr6.sin6_port));
 	} else {
 		return -EINVAL;
 	}
+
+	
+	printk(KERN_INFO "Exiting function wg_socket_endpoint_from_skb\n");
 	return 0;
 }
 
-static bool endpoint_eq(const struct endpoint *a, const struct endpoint *b)
+bool endpoint_eq(const struct endpoint *a, const struct endpoint *b)
 {
+	printk(KERN_INFO "Entering function endpoint_eq\n");
+	printk(KERN_INFO "Exiting function endpoint_eq\n");
 	return (a->addr.sa_family == AF_INET && b->addr.sa_family == AF_INET &&
 		a->addr4.sin_port == b->addr4.sin_port &&
 		a->addr4.sin_addr.s_addr == b->addr4.sin_addr.s_addr &&
@@ -270,88 +745,158 @@ static bool endpoint_eq(const struct endpoint *a, const struct endpoint *b)
 	       unlikely(!a->addr.sa_family && !b->addr.sa_family);
 }
 
-void wg_socket_set_peer_endpoint(struct wg_peer *peer,
-				 const struct endpoint *endpoint)
+static void wg_release_peer_tcp_connection(struct wg_peer *peer);
+
+void wg_socket_set_peer_endpoint(struct wg_peer *peer, const struct endpoint *endpoint)
 {
+	char addr_str[INET6_ADDRSTRLEN];
+	printk(KERN_INFO "Entering function wg_socket_set_peer_endpoint peer=%p\n", peer);
+	if (unlikely(!peer) || unlikely(IS_ERR(peer))){
+		goto out;
+	}
+
 	/* First we check unlocked, in order to optimize, since it's pretty rare
 	 * that an endpoint will change. If we happen to be mid-write, and two
 	 * CPUs wind up writing the same thing or something slightly different,
 	 * it doesn't really matter much either.
 	 */
-	if (endpoint_eq(endpoint, &peer->endpoint))
+	if (endpoint_eq(endpoint, &peer->endpoint)) {
+		printk(KERN_INFO "Exiting function wg_socket_set_peer_endpoint (no change in endpoint)\n");
 		return;
-	write_lock_bh(&peer->endpoint_lock);
+	}
+
+	print_peer_socket_info(peer);
+	
 	if (endpoint->addr.sa_family == AF_INET) {
+		snprintf(addr_str, INET_ADDRSTRLEN, "%pI4", &endpoint->addr4.sin_addr);
+		printk(KERN_INFO "Setting endpoint address: %s:%d\n", addr_str,
+		       ntohs(endpoint->addr4.sin_port));
+		write_lock_bh(&peer->endpoint_lock);
 		peer->endpoint.addr4 = endpoint->addr4;
 		peer->endpoint.src4 = endpoint->src4;
 		peer->endpoint.src_if4 = endpoint->src_if4;
+		write_unlock_bh(&peer->endpoint_lock);  // Unlock before making connection
 	} else if (IS_ENABLED(CONFIG_IPV6) && endpoint->addr.sa_family == AF_INET6) {
+		snprintf(addr_str, INET6_ADDRSTRLEN, "%pI6", &endpoint->addr6.sin6_addr);
+		printk(KERN_INFO "Setting endpoint address: [%s]:%d\n",
+		       addr_str, ntohs(endpoint->addr6.sin6_port));
+		write_lock_bh(&peer->endpoint_lock);
 		peer->endpoint.addr6 = endpoint->addr6;
 		peer->endpoint.src6 = endpoint->src6;
+		write_unlock_bh(&peer->endpoint_lock);  // Unlock before making connection
+
 	} else {
 		goto out;
 	}
 	dst_cache_reset(&peer->endpoint_cache);
+	peer->tcp_reply_endpoint = peer->endpoint;
+	if (peer->endpoint.addr.sa_family == AF_INET) {
+		// For IPv4 address
+		peer->endpoint.addr4.sin_port = htons(51820);
+	} else if (peer->endpoint.addr.sa_family == AF_INET6) {
+		// For IPv6 address
+		peer->endpoint.addr6.sin6_port = htons(51820);
+	} else {
+		pr_err("Unsupported address family\n");
+	}
+
+	printk(KERN_INFO "Peer Endpoint:\n");
+	log_wireguard_endpoint(&peer->endpoint);
+	printk(KERN_INFO "TCP Reply Endpoint:\n");
+	log_wireguard_endpoint(&peer->tcp_reply_endpoint);
+
+	if (!peer->peer_endpoint_set) {
+		peer->peer_endpoint = peer->endpoint;
+		peer->peer_endpoint_set;
+		printk(KERN_INFO "wg_set_peer_endpoint: setting peer->peer_endpoint\n");
+	}
+	if (peer->device->transport == WG_TRANSPORT_TCP && !peer->tcp_established)
+		wg_tcp_connect(peer);
+
 out:
-	write_unlock_bh(&peer->endpoint_lock);
+	printk(KERN_INFO "Exiting function wg_socket_set_peer_endpoint\n");
 }
 
 void wg_socket_set_peer_endpoint_from_skb(struct wg_peer *peer,
 					  const struct sk_buff *skb)
 {
+	printk(KERN_INFO "Entering function wg_socket_set_peer_endpoint_from_skb peer=%p\n", peer);
 	struct endpoint endpoint;
 
+	if (unlikely(!peer) || unlikely(IS_ERR(peer))){
+		goto out;
+	}
+	
 	if (!wg_socket_endpoint_from_skb(&endpoint, skb))
 		wg_socket_set_peer_endpoint(peer, &endpoint);
+	log_wireguard_endpoint(&peer->endpoint);
+	print_peer_socket_info(peer);
+out:
+	printk(KERN_INFO "Exiting function wg_socket_set_peer_endpoint_from_skb\n");
 }
 
 void wg_socket_clear_peer_endpoint_src(struct wg_peer *peer)
 {
+	printk(KERN_INFO "Entering function wg_socket_clear_peer_endpoint_src\n");
 	write_lock_bh(&peer->endpoint_lock);
 	memset(&peer->endpoint.src6, 0, sizeof(peer->endpoint.src6));
 	dst_cache_reset_now(&peer->endpoint_cache);
 	write_unlock_bh(&peer->endpoint_lock);
+	printk(KERN_INFO "Exiting function wg_socket_clear_peer_endpoint_src\n");
 }
 
 static int wg_receive(struct sock *sk, struct sk_buff *skb)
 {
+	printk(KERN_INFO "Entering function wg_receive\n");
 	struct wg_device *wg;
-
+	struct wg_socket_data *socket_data;
+	
 	if (unlikely(!sk))
 		goto err;
-	wg = sk->sk_user_data;
-	if (unlikely(!wg))
+	socket_data = sk->sk_user_data;
+	if (unlikely(!socket_data))
 		goto err;
+	if (unlikely(!socket_data->device))
+ 		goto err;
+	wg = socket_data->device;
 	skb_mark_not_on_list(skb);
 	wg_packet_receive(wg, skb);
+	printk(KERN_INFO "Exiting function wg_receive\n");
 	return 0;
 
 err:
 	kfree_skb(skb);
+	printk(KERN_INFO "Exiting function wg_receive with error.\n");
 	return 0;
 }
 
 static void sock_free(struct sock *sock)
 {
+	printk(KERN_INFO "Entering function sock_free\n");
 	if (unlikely(!sock))
 		return;
 	sk_clear_memalloc(sock);
 	udp_tunnel_sock_release(sock->sk_socket);
+	printk(KERN_INFO "Exiting function sock_free\n");
 }
 
 static void set_sock_opts(struct socket *sock)
 {
+	printk(KERN_INFO "Entering function set_sock_opts\n");
 	sock->sk->sk_allocation = GFP_ATOMIC;
 	sock->sk->sk_sndbuf = INT_MAX;
 	sk_set_memalloc(sock->sk);
+	printk(KERN_INFO "Exiting function set_sock_opts\n");
 }
 
 int wg_socket_init(struct wg_device *wg, u16 port)
 {
+	printk(KERN_INFO "Entering function wg_socket_init\n");
 	struct net *net;
+	struct wg_socket_data *socket_data;
 	int ret;
 	struct udp_tunnel_sock_cfg cfg = {
-		.sk_user_data = wg,
+		.sk_user_data = NULL,  // will set later
 		.encap_type = 1,
 		.encap_rcv = wg_receive
 	};
@@ -379,7 +924,17 @@ int wg_socket_init(struct wg_device *wg, u16 port)
 	rcu_read_unlock();
 	if (unlikely(!net))
 		return -ENONET;
+	
+	socket_data = kzalloc(sizeof(*socket_data), GFP_KERNEL);
+	if (!socket_data) {
+		put_net(net);
+		pr_err("Failed to allocate memory for wg_socket_data\n");
+		return -ENOMEM;
+	}
 
+ 	socket_data->device = wg;
+ 	socket_data->peer = NULL; // Set this to a valid peer where appropriate
+	
 #if IS_ENABLED(CONFIG_IPV6)
 retry:
 #endif
@@ -390,6 +945,11 @@ int wg_socket_init(struct wg_device *wg, u16 port)
 		goto out;
 	}
 	set_sock_opts(new4);
+
+	// Set the socket data in the cfg structure
+	cfg.sk_user_data = socket_data;
+
+	// Now setup the UDP tunnel socket with the updated cfg
 	setup_udp_tunnel_sock(net, new4, &cfg);
 
 #if IS_ENABLED(CONFIG_IPV6)
@@ -405,6 +965,8 @@ int wg_socket_init(struct wg_device *wg, u16 port)
 			goto out;
 		}
 		set_sock_opts(new6);
+
+		// Setup the IPv6 UDP tunnel socket with the same socket data
 		setup_udp_tunnel_sock(net, new6, &cfg);
 	}
 #endif
@@ -413,12 +975,15 @@ int wg_socket_init(struct wg_device *wg, u16 port)
 	ret = 0;
 out:
 	put_net(net);
+	printk(KERN_INFO "Exiting function wg_socket_init\n");
 	return ret;
 }
 
+
 void wg_socket_reinit(struct wg_device *wg, struct sock *new4,
 		      struct sock *new6)
 {
+	printk(KERN_INFO "Entering function wg_socket_reinit\n");
 	struct sock *old4, *old6;
 
 	mutex_lock(&wg->socket_update_lock);
@@ -434,4 +999,2767 @@ void wg_socket_reinit(struct wg_device *wg, struct sock *new4,
 	synchronize_net();
 	sock_free(old4);
 	sock_free(old6);
+	printk(KERN_INFO "Exiting function wg_socket_reinit\n");
+}
+
+static int wg_set_socket_timeouts(struct socket *sock, unsigned long snd_timeout,
+				  unsigned long rcv_timeout)
+{
+	printk(KERN_INFO "Entering function wg_set_socket_timeouts\n");
+	if (!sock || !sock->sk) {
+		pr_err("Invalid socket or sock is NULL\n");
+		return -EINVAL;
+	}
+
+	struct sock *sk = sock->sk;
+
+	sk->sk_sndtimeo = snd_timeout*30;
+	sk->sk_rcvtimeo = rcv_timeout*30;
+
+	printk(KERN_INFO "Exiting function wg_set_socket_timeouts\n");
+	return 0;
+}
+
+static bool wg_endpoints_match(const struct endpoint *a,
+                               const struct endpoint *b)
+{
+	printk(KERN_INFO "Entering function wg_endpoints_match\n");
+	// Compare endpoints
+	if (a->addr.sa_family != b->addr.sa_family) {
+		printk(KERN_INFO "Exiting function wg_endpoints_match\n");
+		return false;
+	}
+
+	if (a->addr.sa_family == AF_INET) {
+		return a->addr4.sin_port == b->addr4.sin_port &&
+		a->addr4.sin_addr.s_addr == b->addr4.sin_addr.s_addr;
+	} else if (a->addr.sa_family == AF_INET6) {
+		// For IPv6, also compare the scope ID if the address is link-local
+		bool is_link_local_a = ipv6_addr_type(&a->addr6.sin6_addr) & IPV6_ADDR_LINKLOCAL;
+		bool is_link_local_b = ipv6_addr_type(&b->addr6.sin6_addr) & IPV6_ADDR_LINKLOCAL;
+        
+		return a->addr6.sin6_port == b->addr6.sin6_port &&
+		ipv6_addr_equal(&a->addr6.sin6_addr, &b->addr6.sin6_addr) &&
+		(!is_link_local_a || !is_link_local_b || a->addr6.sin6_scope_id == b->addr6.sin6_scope_id);
+	}
+	printk(KERN_INFO "Exiting function wg_endpoints_match\n");
+	return false;
+}
+
+void wg_free_peer_socket_data(struct wg_peer *peer);
+
+void wg_free_peer_socket_data(struct wg_peer *peer)
+{
+	if (peer && !IS_ERR(peer))
+		if (peer->peer_socket)
+			if (peer->peer_socket->sk)
+				if (peer->peer_socket->sk->sk_user_data)
+					kfree(peer->peer_socket->sk->sk_user_data);
+}
+
+
+
+void wg_clean_peer_socket(struct wg_peer *peer, bool release, bool destroy, bool inbound)
+{
+	printk(KERN_INFO "Entering function wg_clean_peer_socket peer=%p, inbound=%d\n", peer, inbound);
+	if (!peer || IS_ERR(peer)) {
+		printk(KERN_INFO "wg_clean_peer_socket: No peer or invalid peer.\n");
+		goto out;
+	}
+	print_peer_socket_info(peer);
+	if ((inbound && peer->peer_socket == peer->inbound_socket) ||
+	    (!inbound && peer->peer_socket == peer->outbound_socket)) {
+		// Cleanup partial skb buffer
+		if (peer->partial_skb) {
+			kfree_skb(peer->partial_skb);
+			peer->partial_skb = NULL;
+		}
+	
+		// Cancel and flush the TCP read workqueue
+		if (peer->tcp_read_worker_scheduled) {
+			cancel_work_sync(&peer->tcp_read_work);
+			peer->tcp_read_worker_scheduled = false;
+		}
+		if (peer->tcp_read_wq && destroy) {
+			destroy_workqueue(peer->tcp_read_wq);
+			peer->tcp_read_wq = NULL;
+		}
+	
+		// Cancel and flush the TCP write workqueue
+		if (peer->tcp_write_worker_scheduled) {
+			cancel_work_sync(&peer->tcp_write_work);
+			peer->tcp_write_worker_scheduled = false;
+		}
+		if (peer->tcp_write_wq && destroy) {
+			destroy_workqueue(peer->tcp_write_wq);
+			peer->tcp_write_wq = NULL;
+		}
+	
+		// Clean up packet queues
+		if (!skb_queue_empty(&peer->tcp_packet_queue))
+			skb_queue_purge(&peer->tcp_packet_queue);
+		if (!skb_queue_empty(&peer->send_queue))
+			skb_queue_purge(&peer->send_queue);
+	
+		// Reset TCP state
+		peer->received_len = 0;
+		peer->expected_len = 0;
+		peer->tcp_established = false;
+		peer->tcp_pending = false;
+		peer->tcp_retry_scheduled = false;
+	}
+	
+	// Determine which socket and related resources to clean based on the 'inbound' flag
+	struct socket **socket_to_clean = inbound ? &peer->inbound_socket : &peer->outbound_socket;
+	bool *callbacks_set_flag = inbound ? &peer->tcp_inbound_callbacks_set : &peer->tcp_outbound_callbacks_set;
+	bool *connected_flag = inbound ? &peer->inbound_connected : &peer->outbound_connected;
+	ktime_t *timestamp = inbound ? &peer->inbound_timestamp : &peer->outbound_timestamp;
+	struct delayed_work *remove_work = inbound ? &peer->tcp_inbound_remove_work : &peer->tcp_outbound_remove_work;
+	bool *remove_scheduled_flag = inbound ? &peer->tcp_inbound_remove_scheduled : &peer->tcp_outbound_remove_scheduled;
+
+	// Cleanup socket if necessary
+	if (*socket_to_clean) {
+		if (release) {
+			// Directly free peer socket data as per wg_free_peer_socket_data logic
+			if (*socket_to_clean && (*socket_to_clean)->sk) {
+				if ((*socket_to_clean)->sk->sk_user_data) {
+					kfree((*socket_to_clean)->sk->sk_user_data);
+					(*socket_to_clean)->sk->sk_user_data = NULL;
+				}
+			}
+			kernel_sock_shutdown(*socket_to_clean, SHUT_RDWR);
+			sock_release(*socket_to_clean);
+		}
+		*socket_to_clean = NULL;
+	}
+
+	// Reset callbacks set flag
+	*callbacks_set_flag = false;
+
+	// Reset connection status and timestamp
+	*connected_flag = false;
+	*timestamp = 0;
+
+	// Cancel and clean up remove work if scheduled
+	if (*remove_scheduled_flag) {
+		*remove_scheduled_flag = false;
+		cancel_delayed_work_sync(remove_work);
+	}
+
+	
+	// Check if a retry is scheduled and clean up
+	if (peer->tcp_retry_scheduled && !inbound) {
+		peer->tcp_retry_scheduled = false;
+		cancel_delayed_work_sync(&peer->tcp_retry_work);
+	}
+
+
+out:
+	print_peer_socket_info(peer);
+	printk(KERN_INFO "Exiting wg_clean_peer_socket\n");
+}
+
+
+struct wg_peer *wg_temp_peer_create(struct wg_device *wg);
+void wg_add_tcp_socket_to_list(struct wg_device *wg, struct socket *receive_socket);
+
+
+// Function to copy source and destination addresses from a TCP socket
+
+
+int copy_sock_addresses(struct socket *tcp_socket, struct sockaddr_storage *inbound_source, struct sockaddr_storage *inbound_dest) {
+    struct sock *sk;
+    struct inet_sock *inet;
+    int family;
+
+    // Check if the socket is valid
+    if (!tcp_socket || !tcp_socket->sk) {
+        printk(KERN_INFO "Invalid TCP socket or socket's sk structure.\n");
+        return -1; // Invalid socket
+    }
+
+    sk = tcp_socket->sk; // Retrieve the socket's 'sock' structure
+    family = sk->sk_family;
+
+    if (family == AF_INET) {
+        struct inet_sock *inet = inet_sk(sk);
+
+        // Validate inet_sk
+        if (!inet) {
+            printk(KERN_ERR "inet_sk is NULL for IPv4 socket\n");
+            return -1;
+        }
+
+        // Clear the sockaddr_storage structures
+        memset(inbound_source, 0, sizeof(struct sockaddr_storage));
+        memset(inbound_dest, 0, sizeof(struct sockaddr_storage));
+
+        // Cast to sockaddr_in for IPv4
+        struct sockaddr_in *source_in = (struct sockaddr_in *)inbound_source;
+        struct sockaddr_in *dest_in = (struct sockaddr_in *)inbound_dest;
+
+        // Set the address family to AF_INET
+        source_in->sin_family = AF_INET;
+        dest_in->sin_family = AF_INET;
+
+        // Populate the source and destination information
+        source_in->sin_addr.s_addr = inet->inet_rcv_saddr; // Local IP address
+        source_in->sin_port = inet->inet_sport;            // Local port (already in network byte order)
+        dest_in->sin_addr.s_addr = inet->inet_daddr;       // Remote IP address
+        dest_in->sin_port = inet->inet_dport;              // Remote port (already in network byte order)
+
+        // Diagnostic printouts
+        printk(KERN_INFO "IPv4 Source IP: %pI4, Source Port: %u\n", &source_in->sin_addr, ntohs(source_in->sin_port));
+        printk(KERN_INFO "IPv4 Destination IP: %pI4, Destination Port: %u\n", &dest_in->sin_addr, ntohs(dest_in->sin_port));
+        printk(KERN_INFO "Hexdump of IP and UDP headers: %*ph\n", (int)sizeof(struct sockaddr_in), (void *)source_in);
+
+    } 
+#if IS_ENABLED(CONFIG_IPV6)
+    else if (family == AF_INET6) {
+        struct ipv6_pinfo *np = inet6_sk(sk);
+
+        // Validate ipv6_pinfo
+        if (!np) {
+            printk(KERN_ERR "ipv6_pinfo is NULL for IPv6 socket\n");
+            return -1;
+        }
+
+        // Clear the sockaddr_storage structures
+        memset(inbound_source, 0, sizeof(struct sockaddr_storage));
+        memset(inbound_dest, 0, sizeof(struct sockaddr_storage));
+
+        // Cast to sockaddr_in6 for IPv6
+        struct sockaddr_in6 *source_in6 = (struct sockaddr_in6 *)inbound_source;
+        struct sockaddr_in6 *dest_in6 = (struct sockaddr_in6 *)inbound_dest;
+
+        // Set the address family to AF_INET6
+        source_in6->sin6_family = AF_INET6;
+        dest_in6->sin6_family = AF_INET6;
+
+        // Populate the source and destination information
+        source_in6->sin6_addr = sk->sk_v6_rcv_saddr;       // Local IPv6 address
+        source_in6->sin6_port = inet->inet_sport;          // Local port (already in network byte order)
+        dest_in6->sin6_addr = sk->sk_v6_daddr;             // Remote IPv6 address
+        dest_in6->sin6_port = inet->inet_dport;            // Remote port (already in network byte order)
+        source_in6->sin6_scope_id = ipv6_iface_scope_id(&sk->sk_v6_rcv_saddr, sk->sk_bound_dev_if);
+
+        // Diagnostic printouts
+        printk(KERN_INFO "IPv6 Source IP: %pI6c, Source Port: %u\n", &source_in6->sin6_addr, ntohs(source_in6->sin6_port));
+        printk(KERN_INFO "IPv6 Destination IP: %pI6c, Destination Port: %u\n", &dest_in6->sin6_addr, ntohs(dest_in6->sin6_port));
+        printk(KERN_INFO "Hexdump of IP and UDP headers: %*ph\n", (int)sizeof(struct sockaddr_in6), (void *)source_in6);
+
+    }
+#endif
+    else {
+        printk(KERN_ERR "Unsupported address family: %d\n", family);
+        return -1; // Unsupported address family
+    }
+
+    return 0; // Success
+}
+
+struct wg_peer *wg_find_peer_by_endpoints(struct wg_device *wg, const struct endpoint *endpoint)
+{
+    struct wg_peer *peer = NULL;
+    struct wg_peer *matched_peer = NULL;
+
+    if (!wg || !endpoint) {
+        printk(KERN_ERR "wg_find_peer_by_endpoints: Invalid arguments, wg or endpoint is NULL\n");
+        return NULL;
+    }
+
+    printk(KERN_INFO "Entering function wg_find_peer_by_endpoints\n");
+
+    rcu_read_lock();
+    list_for_each_entry_rcu(peer, &wg->peer_list, peer_list) {
+        // Check if the current peer's endpoint, peer_endpoint, or tcp_reply_endpoint matches the provided endpoint
+        if (endpoint_eq(&peer->endpoint, endpoint) ||
+            endpoint_eq(&peer->peer_endpoint, endpoint) ||
+            endpoint_eq(&peer->tcp_reply_endpoint, endpoint)) {
+            matched_peer = peer;
+            printk(KERN_INFO "wg_find_peer_by_endpoints: Found matching peer %p\n", matched_peer);
+            break;
+        }
+    }
+    rcu_read_unlock();
+
+    if (!matched_peer) {
+        printk(KERN_INFO "wg_find_peer_by_endpoints: No matching peer found\n");
+    }
+
+    printk(KERN_INFO "Exiting function wg_find_peer_by_endpoints peer=%p\n", matched_peer);
+    return matched_peer;
+}
+
+
+int wg_tcp_listener_worker(struct wg_device *wg, struct socket *tcp_socket)
+{
+	bool found = false;
+	printk(KERN_INFO "Entering function wg_tcp_listener_worker\n");
+	struct socket *new_peer_connection = NULL;
+
+	if (!tcp_socket) {
+        	pr_err("tcp_socket is NULL\n");
+        	return -EINVAL;
+    	}
+	if (wg->listener_active) {
+		pr_err("Device TCP listener is already active.");
+		return -EINVAL;
+	}
+	wg->listener_active = true;
+	while (!kthread_should_stop()) {
+		int err;
+
+		err = kernel_accept(tcp_socket, &new_peer_connection, 0);
+		if (err < 0) {
+			if (err == -EAGAIN || err == -ERESTARTSYS)
+				continue;
+			pr_err("Error accepting new connection: %d\n", err);
+        		continue;
+		}
+
+		if (!new_peer_connection) {
+			pr_err("new_peer_connection is NULL after kernel_accept\n");
+			continue;
+		}
+		printk(KERN_INFO "wg_tcp_listener_worker accepted socket: %p new_peer_connection: %p\n", tcp_socket, &new_peer_connection);
+
+	        struct wg_peer *matched_peer = NULL;
+		struct wg_peer *new_temp_peer = NULL;
+	        struct endpoint new_endpoint;
+		struct wg_tcp_socket_list_entry *socket_iter = NULL;
+		struct wg_socket_data *socket_data = NULL;  // New structure for sk_user_data
+
+		
+		new_peer_connection->ops->getname(new_peer_connection, (struct sockaddr *)&new_endpoint, 1);
+
+		if (!list_empty(&wg->peer_list)) {
+			// search device peer list to see if inbound connection is from an established peer address.
+	      	 	rcu_read_lock();
+	       	 	list_for_each_entry_rcu(matched_peer, &wg->peer_list, peer_list) {
+				if (wg_endpoints_match(&matched_peer->endpoint, &new_endpoint)) {
+					// read data if there is any available
+					found = true;
+					printk(KERN_INFO "wg_tcp_listener_worker matched existing endpoint\n");
+					break;
+	        		}
+	       		 }
+			rcu_read_unlock();
+		}
+		if (found)
+			if (!skb_queue_empty(&new_peer_connection->sk->sk_receive_queue)) {
+				printk(KERN_INFO "wg_tcp_listener_worker found lingering data, calling wg_tcp_data_ready()\n");
+				wg_tcp_data_ready(new_peer_connection->sk);
+			}
+
+		
+		// if no matched_peer then this is a new connection and we need to process the packet to see if this is an esiting peer roaming.    
+		if (!matched_peer) {
+			// some kind of martian, toss it.
+			// Perform a graceful shutdown and release the socket
+			printk(KERN_INFO "wg_tcp_listener_worker did not find a matching peer\n");
+			kernel_sock_shutdown(new_peer_connection, SHUT_RDWR);
+			sock_release(new_peer_connection);
+	        } else {
+			printk(KERN_INFO "wg_tcp_listener_worker handling a new connection\n");
+			// We need to search if there is already a pendign connection and remove the old pending connection if there.
+			  // Check if the peer list is empty before proceeding
+			if (!list_empty(&wg->peer_list)) {
+				rcu_read_lock();
+				// check device pending connections in tcp_connection_list
+				list_for_each_entry_rcu(socket_iter, &wg->tcp_connection_list, tcp_connection_ll) {
+					// Defensive checks to ensure all relevant fields are populated
+					// Skip to the next entry if any critical field is NULL
+					if (!socket_iter) {
+						printk(KERN_INFO "socket_iter is NULL\n");
+						continue;
+					}	
+					if (!socket_iter->tcp_socket) {
+						printk(KERN_INFO "socket_iter->tcp_socket is NULL\n");
+						continue;
+					}
+					if (!socket_iter->tcp_socket->sk) {
+						printk(KERN_INFO "socket_iter->tcp_socket->sk is NULL\n");
+						continue;
+					}	
+
+					if (endpoint_eq(&new_endpoint, (struct endpoint *)&socket_iter->src_addr)) {
+						found = true;
+						break;
+					}
+				}
+				rcu_read_unlock();
+			}
+			if (found) {
+				printk(KERN_INFO "wg_tcp_listener_worker new connection was for an existing peer\n");
+				// Remove the older socket from the pending TCP connection list
+				spin_lock_bh(&wg->tcp_connection_list_lock);
+				list_del_rcu(&socket_iter->tcp_connection_ll);
+				spin_unlock_bh(&wg->tcp_connection_list_lock);
+				synchronize_rcu(); // Ensure safe removal
+				// nuke old socket
+				wg_clean_peer_socket(socket_iter->temp_peer, true, true, true);
+				// clean up old temp_peer
+				if (!IS_ERR(socket_iter->temp_peer) && socket_iter->temp_peer) {
+					kfree(socket_iter->temp_peer);
+				}
+				// Free the old entry
+				kfree(socket_iter);
+			}	
+				
+			// we have a new peer end point roaming potentially, 
+			// add to pending connection list and hand packets to upper layer for verificaiton
+	
+			new_temp_peer = wg_temp_peer_create(wg);
+			printk(KERN_INFO "wg_tcp_listener_worker created temp peer for inbound new connection temp_peer=%p\n", new_temp_peer);
+			if (!IS_ERR(new_temp_peer) && new_temp_peer) {
+				// Allocate memory for the new socket data structure
+				socket_data = kzalloc(sizeof(*socket_data), GFP_KERNEL);
+				if (!socket_data) {
+					pr_err("Failed to allocate memory for socket_data\n");
+					kernel_sock_shutdown(new_peer_connection, SHUT_RDWR);
+					sock_release(new_peer_connection);
+					continue;
+				}
+
+				// Initialize the socket data with the device and the temp peer
+				socket_data->device = wg;
+				socket_data->peer = new_temp_peer;
+				socket_data->inbound = true;
+
+				// Set the socket data as sk_user_data
+				new_peer_connection->sk->sk_user_data = socket_data;
+				
+				new_temp_peer->peer_socket = new_peer_connection;
+				new_temp_peer->inbound_socket = new_peer_connection;
+				wg_get_endpoint_from_socket(new_peer_connection, &new_temp_peer->tcp_reply_endpoint);
+				new_temp_peer->endpoint = new_temp_peer->tcp_reply_endpoint;
+				
+				new_temp_peer->tcp_established = true;
+				new_temp_peer->inbound_connected = true;
+				new_temp_peer->inbound_timestamp = ktime_get();
+				new_temp_peer->clean_inbound = false;
+				new_temp_peer->tcp_inbound_callbacks_set = false;
+				copy_sock_addresses(new_peer_connection, &new_temp_peer->inbound_source, &new_temp_peer->inbound_dest);
+				printk(KERN_INFO "new_temp_peer Peer endpoint:");
+				log_wireguard_endpoint(&new_temp_peer->endpoint);
+				new_temp_peer->peer_endpoint = new_temp_peer->endpoint;
+				new_temp_peer->peer_endpoint_set = true;
+				// Set the port to 51820 in network byte order (0xC71C)
+				if (new_temp_peer->peer_endpoint.addr.sa_family == AF_INET) {
+        			// IPv4 address
+        				new_temp_peer->peer_endpoint.addr4.sin_port = htons(51820);
+    				} else if (new_temp_peer->peer_endpoint.addr.sa_family == AF_INET6) {
+        			// IPv6 address
+        				new_temp_peer->peer_endpoint.addr6.sin6_port = htons(51820);
+    				} else {
+        				// Unsupported address family, handle error if necessary
+        				printk(KERN_WARNING "Unsupported address family in WireGuard peer endpoint.\n");
+    				}
+				printk(KERN_INFO "new_temp_peer Peer endpoint:");
+				log_wireguard_endpoint(&new_temp_peer->endpoint);
+				
+				wg_add_tcp_socket_to_list(wg, new_peer_connection);
+				//  we need to set up a data reader for pending connections
+				wg_setup_tcp_socket_callbacks(new_temp_peer, true);  // ready to read data from pending connection and hand handshake to upper layers
+				// read data if there is some pending
+				if (!skb_queue_empty(&new_peer_connection->sk->sk_receive_queue)) {
+					printk(KERN_INFO "wg_tcp_listener_worker calling wg_tcp_data_ready() for temp peer\n");
+					wg_tcp_data_ready(new_peer_connection->sk);
+				print_peer_socket_info(new_temp_peer);
+				}
+			}
+		}
+	}	
+	printk(KERN_INFO "Exiting function wg_tcp_listener_worker\n");
+	return 0;
+}
+	
+int wg_tcp_listener4_thread(void *data)
+{
+	printk(KERN_INFO "Entering function wg_tcp_listener4_thread\n");
+	struct wg_device *wg = data;
+	struct socket *listen_socket;
+
+	// Check if tcp_socket4_ready is set
+	if (!wg->tcp_socket4_ready) {
+		printk(KERN_INFO "tcp_socket4 is not ready, exiting wg_tcp_listener4_thread\n");
+		return 0;
+	}
+	listen_socket = wg->tcp_listen_socket4;
+
+	printk(KERN_INFO "Exiting function wg_tcp_listener4_thread\n");
+	return wg_tcp_listener_worker(wg, listen_socket);
+}
+
+int wg_tcp_listener6_thread(void *data)
+{
+	printk(KERN_INFO "Entering function wg_tcp_listener6_thread\n");
+	struct wg_device *wg = data;
+	struct socket *listen_socket;
+
+	if (!wg->tcp_socket6_ready) {
+		printk(KERN_INFO "tcp_socket6 is not ready, exiting wg_tcp_listener6_thread\n");
+		return 0;
+	}
+
+	listen_socket = wg->tcp_listen_socket6;
+
+	printk(KERN_INFO "Exiting function wg_tcp_listener6_thread\n");
+	return wg_tcp_listener_worker(wg, listen_socket);
+}
+
+void wg_tcp_listener_socket_release(struct wg_device *wg)
+{
+	printk(KERN_INFO "Entering function wg_tcp_socket_release\n");
+
+	wg->listener_active = false;
+	// Signal listener threads to stop
+	if (wg->tcp_listener4_thread) {
+		printk(KERN_INFO "Stopping IPv4 listener thread\n");
+        	kthread_stop(wg->tcp_listener4_thread);
+        	wg->tcp_listener4_thread = NULL;
+	}
+
+#if IS_ENABLED(CONFIG_IPV6)
+    	if (wg->tcp_listener6_thread) {
+        	printk(KERN_INFO "Stopping IPv6 listener thread\n");
+        	kthread_stop(wg->tcp_listener6_thread);
+        	wg->tcp_listener6_thread = NULL;
+    	}
+#endif
+
+	// Release IPv4 socket
+    	if (wg->tcp_listen_socket4) {
+        	printk(KERN_INFO "Releasing IPv4 socket\n");
+        	sock_release(wg->tcp_listen_socket4);
+        	wg->tcp_listen_socket4 = NULL;
+        	wg->tcp_socket4_ready = false;
+    	}
+
+#if IS_ENABLED(CONFIG_IPV6)
+    	// Release IPv6 socket
+    	if (wg->tcp_listen_socket6) {
+		printk(KERN_INFO "Releasing IPv6 socket\n");
+        	sock_release(wg->tcp_listen_socket6);
+        	wg->tcp_listen_socket6 = NULL;
+        	wg->tcp_socket6_ready = false;
+    	}
+#endif
+
+	printk(KERN_INFO "Exiting function wg_tcp_socket_release\n");
+}
+
+struct socket *wg_setup_tcp_listen4(struct wg_device *wg, struct net *net, u16 port)
+{
+	if (!wg || !net || port == 0) {
+		printk(KERN_ERR "wg_setup_tcp_listen4: Invalid arguments\n");
+		return NULL;
+	}
+	printk(KERN_INFO "Entering function wg_setup_tcp_listen4\n");
+
+	int ret = -EINVAL; // Initialize ret with an invalid argument error
+	struct socket *listen_socket4 = NULL;
+	struct sockaddr_in addr4 = {
+		.sin_family = AF_INET,
+		.sin_port = htons(port),
+		.sin_addr = { htonl(INADDR_ANY) }
+	};
+
+	printk(KERN_INFO "Creating IPv4 socket\n");
+	ret = sock_create_kern(net, AF_INET, SOCK_STREAM, IPPROTO_TCP, &listen_socket4);
+	if (ret < 0) {
+		pr_err("%s: Could not create IPv4 TCP socket, error: %d\n", wg->dev->name, ret);
+		goto release_ipv4;
+	}
+	printk(KERN_INFO "IPv4 socket created successfully\n");
+
+	// Set socket options to reuse port
+	sock_set_reuseport(listen_socket4->sk);
+
+	printk(KERN_INFO "Binding IPv4 socket\n");
+	ret = kernel_bind(listen_socket4, (struct sockaddr *)&addr4, sizeof(addr4));
+	if (ret < 0) {
+		pr_err("%s: Could not bind IPv4 TCP socket, error: %d\n", wg->dev->name, ret);
+		goto release_ipv4;
+	}
+	printk(KERN_INFO "IPv4 socket bound successfully\n");
+
+	printk(KERN_INFO "Starting to listen on IPv4 socket\n");
+	ret = kernel_listen(listen_socket4, SOMAXCONN);
+	if (ret < 0) {
+		pr_err("%s: Could not listen on IPv4 TCP socket, error: %d\n", wg->dev->name, ret);
+		goto release_ipv4;
+	}
+	printk(KERN_INFO "IPv4 socket is now listening\n");
+	goto out;
+
+
+release_ipv4:
+	if (ret < 0 && listen_socket4) {
+		sock_release(listen_socket4);
+		printk(KERN_INFO "Exiting function wg_setup_tcp_listen4 with ret=%d\n", ret);
+		return NULL;
+	}
+
+out:
+	put_net(net);
+	printk(KERN_INFO "Exiting function wg_setup_tcp_listen4 with ret=%d\n", ret);
+	return listen_socket4;
+}
+
+struct socket *wg_setup_tcp_listen6(struct wg_device *wg, struct net *net, u16 port)
+{
+	if (!wg || !net || port == 0) {
+		printk(KERN_ERR "wg_setup_tcp_listen6: Invalid arguments\n");
+		return NULL;
+	}
+	printk(KERN_INFO "Entering function wg_setup_tcp_listen6\n");
+
+#if IS_ENABLED(CONFIG_IPV6)
+	int ret = -EINVAL; // Initialize ret with an invalid argument error
+	struct socket *listen_socket6 = NULL;
+	struct sockaddr_in6 addr6 = {
+		.sin6_family = AF_INET6,
+		.sin6_port = htons(port),
+		.sin6_addr = IN6ADDR_ANY_INIT,
+	};
+	printk(KERN_INFO "Creating IPv6 socket\n");
+	ret = sock_create_kern(net, AF_INET6, SOCK_STREAM, IPPROTO_TCP, &listen_socket6);
+	if (ret < 0) {
+		pr_err("%s: Could not create IPv6 TCP socket, error: %d\n", wg->dev->name, ret);
+		goto release_ipv6;
+	}
+	printk(KERN_INFO "IPv6 socket created successfully\n");
+
+	printk(KERN_INFO "Binding IPv6 socket\n");
+	ret = kernel_bind(listen_socket6, (struct sockaddr *)&addr6, sizeof(addr6));
+	if (ret < 0) {
+		pr_err("%s: Could not bind IPv6 TCP socket, error: %d\n", wg->dev->name, ret);
+		goto release_ipv6;
+	}
+	printk(KERN_INFO "IPv6 socket bound successfully\n");
+
+	printk(KERN_INFO "Starting to listen on IPv6 socket\n");
+	ret = kernel_listen(listen_socket6, SOMAXCONN);
+	if (ret < 0) {
+		pr_err("%s: Could not listen on IPv6 TCP socket, error: %d\n", wg->dev->name, ret);
+		goto release_ipv6;
+	}
+	printk(KERN_INFO "IPv6 socket is now listening\n");
+	goto out;
+
+release_ipv6:
+	if (ret < 0 && listen_socket6) {
+		sock_release(listen_socket6);
+		printk(KERN_INFO "Exiting function wg_setup_tcp_listen6 with ret=%d\n", ret);
+		return NULL;
+	}
+
+out:
+	put_net(net);
+	printk(KERN_INFO "Exiting function wg_setup_tcp_listen6 with ret=%d\n", ret);
+	return listen_socket6;
+#endif
+}
+
+int wg_tcp_listener_socket_init(struct wg_device *wg, u16 port)
+{
+	if (!wg || port == 0) {
+		printk(KERN_ERR "wg_tcp_listener_socket_init: Invalid arguments\n");
+		return -EINVAL;
+	}
+	printk(KERN_INFO "Entering function wg_tcp_listener_socket_init\n");
+
+	if (wg->tcp_socket4_ready || wg->tcp_socket6_ready) {
+		printk(KERN_INFO "TCP sockets are already initialized, exiting\n");
+		return 0;
+	}
+
+	if (!wg->dev) {
+		printk(KERN_INFO "Net Device not initialized in wg_device, exiting\n");
+		return -EINVAL;
+	}
+	
+	struct in_device *dev_v4 = __in_dev_get_rtnl(wg->dev);
+	struct inet6_dev *dev_v6 = __in6_dev_get(wg->dev);
+	struct net *net;
+	bool ipv4_configured = false, ipv6_configured = false;
+
+	printk(KERN_INFO "Locking RCU and dereferencing wg->creating_net\n");
+	rcu_read_lock();
+	net = rcu_dereference(wg->creating_net);
+	net = net ? maybe_get_net(net) : NULL;
+	rcu_read_unlock();
+	printk(KERN_INFO "RCU lock released\n");
+
+	if (unlikely(!net)) {
+		printk(KERN_ERR "Error: net is NULL, exiting wg_tcp_listener_socket_init\n");
+		return -ENONET;
+	}
+
+
+
+
+	// Use the default interface info to set up the IPv4 listener
+	if (default_iface_info.ipv4_available) {
+		wg->tcp_listen_socket4 = wg_setup_tcp_listen4(wg, net, port);
+		if (wg->tcp_listen_socket4) {
+			wg->tcp_socket4_ready = true;
+			ipv4_configured = true;
+
+			// Set the device endpoint using the global structure
+			wg->device_endpoint.addr4.sin_family = AF_INET;
+			wg->device_endpoint.addr4.sin_addr.s_addr = default_iface_info.ipv4_address;
+			wg->device_endpoint.addr4.sin_port = htons(port);
+			wg->device_endpoint.src4.s_addr = default_iface_info.ipv4_address;
+			wg->device_endpoint.src_if4 = default_iface_info.dev->ifindex; // Interface index
+			printk(KERN_INFO "Set default IPv4 device endpoint: %pI4\n", &wg->device_endpoint.addr4.sin_addr);
+		}
+	}
+
+#if IS_ENABLED(CONFIG_IPV6)
+	// Use the default interface info to set up the IPv6 listener
+	if (default_iface_info.ipv6_available) {
+		wg->tcp_listen_socket6 = wg_setup_tcp_listen6(wg, net, port);
+		if (wg->tcp_listen_socket6) {
+			wg->tcp_socket6_ready = true;
+			ipv6_configured = true;
+
+			// Set the device endpoint using the global structure
+			wg->device_endpoint.addr6.sin6_family = AF_INET6;
+			wg->device_endpoint.addr6.sin6_addr = default_iface_info.ipv6_address;
+			wg->device_endpoint.addr6.sin6_port = htons(port);
+			wg->device_endpoint.src6 = default_iface_info.ipv6_address;
+			printk(KERN_INFO "Set default IPv6 device endpoint: %pI6\n", &wg->device_endpoint.addr6.sin6_addr);
+		}
+	}
+#endif
+
+
+	printk(KERN_INFO "Listener Endpoint:\n");
+	log_wireguard_endpoint(&wg->device_endpoint);
+	
+	// Start the IPv4 listener thread if IPv4 is configured
+	if (dev_v4 && ipv4_configured && !wg->tcp_listener4_thread) {
+		printk(KERN_INFO "Starting IPv4 listener thread\n");
+		wg->tcp_listener4_thread = kthread_run(wg_tcp_listener4_thread, (void *)wg, "wg_listener");
+		if (IS_ERR(wg->tcp_listener4_thread)) {
+		pr_err("Failed to establish IPv4 TCP listener thread\n");
+		} else {
+			printk(KERN_INFO "IPv4 listener thread started successfully\n");
+		}
+	}
+
+    // Start the IPv6 listener thread if IPv6 is configured
+#if IS_ENABLED(CONFIG_IPV6)
+	if (dev_v6 && ipv6_configured && !wg->tcp_listener6_thread) {
+		printk(KERN_INFO "Starting IPv6 listener thread\n");
+		wg->tcp_listener6_thread = kthread_run(wg_tcp_listener6_thread, (void *)wg, "wg_listener");
+		if (IS_ERR(wg->tcp_listener6_thread)) {
+			pr_err("Failed to establish IPv6 TCP listener thread\n");
+		} else {
+			printk(KERN_INFO "IPv6 listener thread started successfully\n");
+		}
+	}
+#endif
+
+	// Schedule TCP cleanup work if not already scheduled
+#ifdef NOTTEST
+        if (!wg->tcp_cleanup_scheduled) {
+                pr_info("Scheduling TCP cleanup work.\n");
+		spin_lock_bh(&wg->tcp_cleanup_lock);
+                wg->tcp_cleanup_scheduled = true;
+	        spin_unlock_bh(&wg->tcp_cleanup_lock);
+		schedule_delayed_work(&wg->tcp_cleanup_work, msecs_to_jiffies(5000));
+	 	printk(KERN_INFO "Delayed work scheduled\n");
+	}
+#endif
+	printk(KERN_INFO "Exiting function wg_tcp_listener_socket_init\n");
+	return 0;
+}
+
+// Attempt to establish a TCP connection
+int wg_tcp_connect(struct wg_peer *peer)
+{
+    	struct wg_socket_data *socket_data;
+	struct sockaddr_storage src_addr_storage;
+	struct sockaddr *src_addr = (struct sockaddr *)&src_addr_storage; // Correctly define src_addr pointer
+
+	printk(KERN_INFO "Entering function wg_tcp_connect peer=%p\n", peer);
+	print_peer_socket_info(peer);
+	// Ensure wg_tcp_listener_socket_init is called
+	if (!peer->device->tcp_socket4_ready && !peer->device->tcp_socket6_ready) {
+		int ret = wg_tcp_listener_socket_init(peer->device, peer->device->incoming_port);
+        	if (ret < 0) {
+            		printk(KERN_ERR "Failed to initialize TCP sockets, exiting wg_tcp_connect\n");
+            		return ret;
+        	}
+    	}
+
+	// Check if the connection has already been established or is pending
+	if (peer->peer_socket || peer->tcp_pending || peer->inbound_connected) {
+        	printk(KERN_INFO "TCP connection already established or pending\n");
+        	return 0;
+    	}
+
+	// Print initial diagnostics
+	printk(KERN_INFO "(Device) Peer transport: %d, TCP established: %d\n", peer->device->transport, peer->tcp_established);
+	printk(KERN_INFO "Peer endpoint address family: %d\n", peer->endpoint.addr.sa_family);
+	printk(KERN_INFO "Endpoint ");
+	log_wireguard_endpoint(&peer->endpoint);
+	printk(KERN_INFO "Peer Endpoint");
+	log_wireguard_endpoint(&peer->peer_endpoint);
+
+	// Check if endpoint is properly set before attempting to connect
+	if (peer->peer_endpoint.addr.sa_family != AF_INET && peer->peer_endpoint.addr.sa_family != AF_INET6) {
+        	printk(KERN_ERR "Invalid address family for connection: %d\n", peer->peer_endpoint.addr.sa_family);
+       		return -EAFNOSUPPORT;
+	}
+
+	struct sockaddr_storage addr_storage;
+    	struct sockaddr *addr = (struct sockaddr *)&addr_storage;
+	unsigned long timeout = 30 * HZ; // 5 seconds in jiffies
+	int ret;
+
+	if (peer->device->transport != WG_TRANSPORT_TCP || peer->tcp_established || peer->outbound_connected) {
+		pr_err("Invalid state for TCP connection attempt.\n");
+		printk(KERN_INFO "Exiting function wg_tcp_connect\n");
+		return -EINVAL;
+    	}
+
+	memset(&addr_storage, 0, sizeof(addr_storage));
+
+	if (peer->peer_endpoint.addr.sa_family == AF_INET) {
+        	struct sockaddr_in *addr4 = (struct sockaddr_in *)&addr_storage;
+		addr4->sin_family = AF_INET;
+		addr4->sin_port = peer->peer_endpoint.addr4.sin_port; // Use correct port from endpoint
+		addr4->sin_addr.s_addr = peer->peer_endpoint.addr4.sin_addr.s_addr;
+		addr = (struct sockaddr *)addr4;
+		printk(KERN_INFO "Setting up IPv4 connection to %pI4:%d\n", &addr4->sin_addr, ntohs(addr4->sin_port));
+	}
+#ifdef CONFIG_IPV6
+	else if (peer->peer_endpoint.addr.sa_family == AF_INET6) {
+		struct sockaddr_in6 *addr6 = (struct sockaddr_in6 *)&addr_storage;
+		addr6->sin6_family = AF_INET6;
+		addr6->sin6_port = peer->peer_endpoint.addr6.sin6_port; // Use correct port from endpoint
+		memcpy(&addr6->sin6_addr, &peer->peer_endpoint.addr6.sin6_addr, sizeof(peer->peer_endpoint.addr6.sin6_addr));
+		addr = (struct sockaddr *)addr6;
+		printk(KERN_INFO "Setting up IPv6 connection to [%pI6c]:%d\n", &addr6->sin6_addr, ntohs(addr6->sin6_port));
+    	}
+#endif
+	else {
+        	pr_err("Unsupported address family: %d\n", peer->endpoint.addr.sa_family);
+		printk(KERN_INFO "Exiting function wg_tcp_connect\n");
+		return -EAFNOSUPPORT;
+    	}
+
+	// Create the socket
+	printk(KERN_INFO "Creating socket for address family: %d\n", peer->endpoint.addr.sa_family);
+	ret = sock_create_kern(&init_net, peer->peer_endpoint.addr.sa_family, SOCK_STREAM, IPPROTO_TCP, &peer->peer_socket);
+	if (ret) {
+        	pr_err("Failed to create TCP socket for address family %d: %d\n", peer->peer_endpoint.addr.sa_family, ret);
+		printk(KERN_INFO "Exiting function wg_tcp_connect\n");
+		return ret;
+	}
+
+	
+	// ** New code to bind the socket to the default interface's IP address **
+	memset(&src_addr_storage, 0, sizeof(src_addr_storage));
+
+	if (peer->peer_endpoint.addr.sa_family == AF_INET) {
+		struct sockaddr_in *src_addr4 = (struct sockaddr_in *)&src_addr_storage;
+		src_addr4->sin_family = AF_INET;
+		src_addr4->sin_port = 0; // Let the system choose the port
+		src_addr4->sin_addr.s_addr = default_iface_info.ipv4_address; // Use the default interface's IP address
+		src_addr = (struct sockaddr *)src_addr4;
+		printk(KERN_INFO "Binding socket to source address %pI4\n", &src_addr4->sin_addr);
+	}
+#ifdef CONFIG_IPV6
+	else if (peer->peer_endpoint.addr.sa_family == AF_INET6) {
+		struct sockaddr_in6 *src_addr6 = (struct sockaddr_in6 *)&src_addr_storage;
+		src_addr6->sin6_family = AF_INET6;
+		src_addr6->sin6_port = 0; // Let the system choose the port
+		src_addr6->sin6_addr = default_iface_info.ipv6_address; // Use the default interface's IPv6 address
+		src_addr = (struct sockaddr *)src_addr6;
+		printk(KERN_INFO "Binding socket to source address [%pI6c]\n", &src_addr6->sin6_addr);
+	}
+ #endif
+
+
+	peer->tcp_established = false;
+	peer->tcp_pending = false;
+	peer->outbound_connected = false;
+	peer->tcp_outbound_callbacks_set = false;
+	peer->outbound_timestamp = ktime_set(0, 0);
+	peer->outbound_socket = peer->peer_socket;
+
+	struct inet_sock *inet = inet_sk(peer->peer_socket->sk);
+
+	// Set up outbound source and destination using sockaddr_storage
+	memset(&peer->outbound_source, 0, sizeof(struct sockaddr_storage));
+	memset(&peer->outbound_dest, 0, sizeof(struct sockaddr_storage));
+
+	if (peer->peer_endpoint.addr.sa_family == AF_INET) {
+        	struct sockaddr_in *source = (struct sockaddr_in *)&peer->outbound_source;
+		struct sockaddr_in *dest = (struct sockaddr_in *)&peer->outbound_dest;
+
+		source->sin_family = AF_INET;
+		source->sin_port = inet->inet_sport;  // Source port from socket
+		source->sin_addr.s_addr = inet->inet_saddr; // Source IP from socket
+
+		dest->sin_family = AF_INET;
+		dest->sin_port = peer->peer_endpoint.addr4.sin_port; // Destination port from endpoint
+		dest->sin_addr = peer->peer_endpoint.addr4.sin_addr; // Destination IP from endpoint
+	}
+#ifdef CONFIG_IPV6
+	else if (peer->peer_endpoint.addr.sa_family == AF_INET6) {
+		struct sockaddr_in6 *source6 = (struct sockaddr_in6 *)&peer->outbound_source;
+		struct sockaddr_in6 *dest6 = (struct sockaddr_in6 *)&peer->outbound_dest;
+
+		source6->sin6_family = AF_INET6;
+		source6->sin6_port = inet->inet_sport;  // Source port from socket
+		memcpy(&source6->sin6_addr, &inet6_sk(peer->peer_socket->sk)->saddr, sizeof(struct in6_addr)); // Source IP from socket
+
+		dest6->sin6_family = AF_INET6;
+		dest6->sin6_port = peer->peer_endpoint.addr6.sin6_port; // Destination port from endpoint
+		memcpy(&dest6->sin6_addr, &peer->endpoint.addr6.sin6_addr, sizeof(struct in6_addr)); // Destination IP from endpoint
+    	}
+#endif
+
+	printk(KERN_INFO "Allocating socket data\n");
+	socket_data = kzalloc(sizeof(*socket_data), GFP_KERNEL);
+	if (!socket_data) {
+		pr_err("Failed to allocate memory for wg_socket_data\n");
+		sock_release(peer->peer_socket);
+		peer->peer_socket = NULL;
+		printk(KERN_INFO "Exiting function wg_tcp_connect\n");
+		return -ENOMEM;
+    	}
+	socket_data->device = peer->device;
+	socket_data->peer = peer;
+	socket_data->inbound = false;
+	peer->peer_socket->sk->sk_user_data = socket_data;
+
+	// Print diagnostic information about the created socket
+	printk(KERN_INFO "Socket created, sk=%p, family=%d, state=%d\n", 
+        peer->peer_socket->sk, peer->peer_socket->sk->sk_family, peer->peer_socket->sk->sk_state);
+
+	// Set up the socket callbacks before initiating the connect
+	printk(KERN_INFO "Setting up socket callbacks\n");
+	wg_setup_tcp_socket_callbacks(peer, false); // set outbound callbacks
+
+	// Set socket timeouts for send and receive operations
+	printk(KERN_INFO "Setting socket timeouts\n");
+    	ret = wg_set_socket_timeouts(peer->peer_socket, timeout, timeout);
+    	if (ret) {
+        	pr_err("Failed to set socket timeouts: %d\n", ret);
+        	sock_release(peer->peer_socket);
+        	peer->peer_socket = NULL;
+        	printk(KERN_INFO "Exiting function wg_tcp_connect\n");
+        	return ret;
+    	}
+
+    	// Print diagnostic information before initiating the connect
+    	printk(KERN_INFO "Ready to initiate connection, sk_state=%d\n", peer->peer_socket->sk->sk_state);
+
+	// Initiate the non-blocking connect
+    	printk(KERN_INFO "Initiating non-blocking connect\n");
+	ret = kernel_connect(peer->peer_socket, addr, addr->sa_family == AF_INET ? sizeof(struct sockaddr_in) : sizeof(struct sockaddr_in6), O_NONBLOCK);
+	if (ret != -EINPROGRESS && ret != 0) {
+		pr_err("TCP connection attempt failed: %d\n", ret);
+		sock_release(peer->peer_socket);
+		peer->peer_socket = NULL;
+        	printk(KERN_INFO "Exiting function wg_tcp_connect\n");
+		return ret;
+    	}
+
+	pr_info("TCP connection attempt initiated\n");
+	spin_lock_bh(&peer->tcp_lock);
+	peer->tcp_pending = true;
+	spin_unlock_bh(&peer->tcp_lock);
+
+	if (!peer->tcp_retry_scheduled) {
+		printk(KERN_INFO "Scheduling TCP retry work.\n");
+		peer->tcp_retry_scheduled = true;
+		schedule_delayed_work(&peer->tcp_retry_work, msecs_to_jiffies(10000));
+	}
+
+	printk(KERN_INFO "Exiting function wg_tcp_connect\n");
+	return 0;
+}
+
+
+// Function to release and clean up an old peer TCP connection - clean the active connection
+static void wg_release_peer_tcp_connection(struct wg_peer *peer)
+{
+	bool inbound = false;
+	printk(KERN_INFO "Entering function wg_release_old_peer_tcp_connection\n");
+	if (unlikely(!peer) || unlikely(IS_ERR(peer))){
+		printk(KERN_INFO "Exiting function wg_release_old_peer_tcp_connection - no peer to tear down.\n");
+		goto out;
+	}
+	print_peer_socket_info(peer);
+	if (!peer->peer_socket || !(peer->tcp_established || peer->tcp_pending)){
+		printk(KERN_INFO "Exiting function wg_release_old_peer_tcp_connection - no connection to tear down.\n");
+		goto out;
+	}
+	if (peer->peer_socket == peer->inbound_socket)
+		inbound = true;
+	// Reset socket callbacks and release the socket
+	wg_reset_tcp_socket_callbacks(peer, inbound);
+
+	// Perform a graceful shutdown and release the socket
+	kernel_sock_shutdown(peer->peer_socket, SHUT_RDWR);
+	sock_release(peer->peer_socket);
+	
+	// Lock to safely modify the peer's TCP connection state
+	spin_lock_bh(&peer->tcp_lock);
+	peer->peer_socket = NULL;
+	if (inbound)
+		peer->inbound_socket = NULL;
+	else
+		peer->outbound_socket = NULL;
+	// Clear TCP connection flags
+	peer->tcp_pending = true;
+	peer->tcp_established = false;
+	spin_unlock_bh(&peer->tcp_lock);
+	// flush any partial data before we switch and free the held buffer
+	if (peer->partial_skb) {
+                kfree_skb(peer->partial_skb);
+		peer->partial_skb = NULL;
+	}
+		
+	// Check if a retry is scheduled and clean up
+    	if (peer->tcp_retry_scheduled) {
+        	peer->tcp_retry_scheduled = false;
+        	cancel_delayed_work_sync(&peer->tcp_retry_work);
+	}
+
+	// Clean up packet queues
+    	skb_queue_purge(&peer->tcp_packet_queue);
+    	skb_queue_purge(&peer->send_queue);
+
+
+out:
+	printk(KERN_INFO "Exiting function wg_release_old_peer_tcp_connection\n");
+}
+
+
+void wg_extract_endpoint_from_sock(struct sock *sk,
+                                   struct endpoint *endpoint)
+{
+	printk(KERN_INFO "Entering function wg_extract_endpoint_from_sock\n");
+	if (!sk || !endpoint) {
+		pr_warn("Socket or endpoint is NULL.\n");
+		return;
+	}
+	memset(endpoint, 0, sizeof(*endpoint)); // Clear the endpoint structure
+
+	if (sk->sk_family == AF_INET) {
+		// IPv4
+		struct inet_sock *inet = inet_sk(sk);
+
+		endpoint->addr4.sin_family = AF_INET;
+		endpoint->addr4.sin_port = inet->inet_dport; // Destination port
+		endpoint->addr4.sin_addr.s_addr = inet->inet_daddr; // Destination IP address
+	} else if (sk->sk_family == AF_INET6) {
+#if IS_ENABLED(CONFIG_IPV6)
+		// IPv6
+		endpoint->addr6.sin6_family = AF_INET6;
+		endpoint->addr6.sin6_port = sk->sk_dport; // Destination port
+		endpoint->addr6.sin6_addr = sk->sk_v6_daddr; // Destination IP address
+
+		if (ipv6_addr_type((struct in6_addr *)&sk->sk_v6_daddr) & IPV6_ADDR_LINKLOCAL) {
+			// The destination address is link-local; use the socket's bound device for the scope ID
+			endpoint->addr6.sin6_scope_id = sk->sk_bound_dev_if;
+		} else {
+			// Not a link-local address; no scope ID required
+			endpoint->addr6.sin6_scope_id = 0;
+		}
+	} else {
+#endif
+		pr_warn("Unsupported socket family: %d.\n", sk->sk_family);
+	}
+	printk(KERN_INFO "Exiting function wg_extract_endpoint_from_sock\n");
+}
+
+
+void wg_tcp_state_change(struct sock *sk)
+{
+	printk(KERN_INFO "Entering function wg_tcp_state_change\n");
+
+	// Check if the socket is valid
+	if (!sk || IS_ERR(sk)) {
+		pr_err("wg_tcp_state_change: Invalid socket passed to the function\n");
+		goto out;
+	}
+
+	// Retrieve the socket user data
+	struct wg_socket_data *socket_data = sk->sk_user_data;
+
+	// Check if socket_data is valid
+	if (!socket_data || IS_ERR(socket_data)) {
+		pr_err("wg_tcp_state_change: Invalid or NULL socket_data for socket %p\n", sk);
+		goto out;
+	}
+
+	// Retrieve the peer from the socket_data
+	struct wg_peer *peer = socket_data->peer;
+
+	// Check if peer is valid
+	if (!peer || IS_ERR(peer)) {
+		pr_err("wg_tcp_state_change: Invalid or NULL peer in socket_data for socket %p\n", sk);
+		goto out;
+	}
+	print_peer_socket_info(peer);
+	// Diagnostic information about the current state
+	pr_info("wg_tcp_state_change: Socket state=%d, Socket error=%d\n", sk->sk_state, sk->sk_err);
+	pr_info("wg_tcp_state_change: Peer=%p, Device=%p\n", peer, socket_data->device);
+
+	// Additional diagnostic information for peer-specific data
+	pr_info("wg_tcp_state_change: Peer TCP established=%d, TCP pending=%d\n",
+	        peer->tcp_established, peer->tcp_pending);
+
+
+	
+	// Log detailed state information
+	pr_info("wg_tcp_state_change: sk=%p, sk_state=%d, sk_err=%d, sk_shutdown=%d, sk_send_head=%p\n", 
+	 	sk, sk->sk_state, sk->sk_err, sk->sk_shutdown, sk->sk_send_head);
+	// Log TCP specific state information if available
+	const char *tcp_state_name;
+
+	switch (sk->sk_state) {
+    		case TCP_ESTABLISHED:
+        		tcp_state_name = "TCP_ESTABLISHED";
+			break;
+		case TCP_SYN_SENT:
+			tcp_state_name = "TCP_SYN_SENT";
+			break;
+		case TCP_SYN_RECV:
+			tcp_state_name = "TCP_SYN_RECV";
+			break;
+		case TCP_FIN_WAIT1:
+			tcp_state_name = "TCP_FIN_WAIT1";
+			break;
+		case TCP_FIN_WAIT2:
+			tcp_state_name = "TCP_FIN_WAIT2";
+			break;
+		case TCP_TIME_WAIT:
+			tcp_state_name = "TCP_TIME_WAIT";
+			break;
+		case TCP_CLOSE:
+			tcp_state_name = "TCP_CLOSE";
+			break;
+		case TCP_CLOSE_WAIT:
+			tcp_state_name = "TCP_CLOSE_WAIT";
+			break;
+		case TCP_LAST_ACK:
+			tcp_state_name = "TCP_LAST_ACK";
+			break;
+		case TCP_LISTEN:
+			tcp_state_name = "TCP_LISTEN";
+			break;
+		case TCP_CLOSING:
+			tcp_state_name = "TCP_CLOSING";
+			break;
+		case TCP_NEW_SYN_RECV:
+			tcp_state_name = "TCP_NEW_SYN_RECV";
+			break;
+		default:
+			tcp_state_name = "UNKNOWN_STATE";
+        		break;
+	}
+
+	printk(KERN_INFO "TCP state: %s (%d)\n", tcp_state_name, sk->sk_state);
+
+	if (sk->sk_state == TCP_ESTABLISHED) {
+		struct tcp_sock *tp = tcp_sk(sk);
+		printk(KERN_INFO "TCP_ESTABLISHED: snd_una=%u, snd_nxt=%u, snd_wnd=%u, rcv_wnd=%u, rcv_nxt=%u\n", 
+			tp->snd_una, tp->snd_nxt, tp->snd_wnd, tp->rcv_wnd, tp->rcv_nxt);
+	}
+
+	// first lets figure out if this is an inbound connect
+	
+	switch (sk->sk_state) {
+    		case TCP_ESTABLISHED:
+			if (peer->temp_peer) {
+				pr_err("Wireguard: Inbound peer connection previously established.\n");
+				break;
+			}
+			if (!peer->tcp_established && !peer->outbound_connected) {
+				peer->tcp_pending = false;
+        			peer->tcp_established = true;
+				peer->outbound_connected = true;
+				peer->outbound_timestamp = ktime_get();
+				peer->tcp_outbound_remove_scheduled = false;
+				// Check if a retry is scheduled and clean up
+    				if (peer->tcp_retry_scheduled) {
+       		 			peer->tcp_retry_scheduled = false;
+        				cancel_delayed_work_sync(&peer->tcp_retry_work);
+				}
+				peer->tcp_retry_scheduled = false;  // Clear the retry flag upon successful connection
+				pr_info("TCP connection established.\n");
+				break;
+			} else
+				pr_err("Wireguard: Outbound connection previously established.\n");
+			break;
+		case TCP_CLOSE:
+		case TCP_CLOSE_WAIT:
+		case TCP_CLOSING:
+		case TCP_FIN_WAIT1:
+		case TCP_FIN_WAIT2:
+		case TCP_LAST_ACK:
+			if (peer->tcp_established || peer->tcp_pending) {
+                		// Connection failed or closed unexpectedly
+                		pr_info("TCP connection failed or closed, handling state.\n");
+				// first we have to figure out if this is inbound or outbound connection;
+				struct endpoint *ep;
+				bool inbound = false;
+				if (sk->sk_user_data)
+					if (((struct wg_socket_data *)sk->sk_user_data)->inbound) {
+						inbound = true;
+						if (peer->tcp_established && !peer->outbound_connected)
+							peer->tcp_established = false;
+						peer->inbound_timestamp = ktime_set(0, 0);
+						peer->inbound_connected = false;
+					} else {
+						if (peer->tcp_established && !peer->inbound_connected)
+							peer->tcp_established = false;
+						peer->outbound_timestamp = ktime_set(0, 0);
+						peer->outbound_connected = false;
+						peer->tcp_pending - false;
+					}
+				else
+					pr_err("Wireguard: TCP State Change, malformed socket state user data.\n");
+                		
+				// if this is a real peer and both connections down schedule a connection retry
+				if (!peer->tcp_established && !peer->tcp_retry_scheduled && !peer->temp_peer) {
+                    			printk(KERN_INFO "Scheduling TCP retry work.\n");
+                    			peer->tcp_retry_scheduled = true;
+                    			schedule_delayed_work(&peer->tcp_retry_work, msecs_to_jiffies(10000));
+                		}
+				
+				// Schedule TCP socket removal work if not already scheduled	
+ 				if (inbound) {
+					if (!peer->tcp_inbound_remove_scheduled) {
+						printk(KERN_INFO "Setting up socket remove work.\n");
+						peer->tcp_inbound_remove_scheduled = true;
+						schedule_delayed_work(&peer->tcp_inbound_remove_work, 0);
+					}
+				else
+					if (!peer->tcp_outbound_remove_scheduled) {
+						printk(KERN_INFO "Setting up socket remove work.\n");
+						peer->tcp_outbound_remove_scheduled = true;
+						schedule_delayed_work(&peer->tcp_inbound_remove_work, 0);
+					}
+				}
+				if (!peer->inbound_connected && !peer->outbound_connected)
+					peer->tcp_established = false;
+			}
+		default:
+			break;
+    	}
+out:
+	// Call the original state change callback if it exists
+	if (((struct wg_socket_data *)sk->sk_user_data)->inbound) {
+	    	if (peer->original_inbound_state_change) {
+        		peer->original_inbound_state_change(sk);
+   		}
+	} else {
+		if (peer->original_outbound_state_change) {
+        		peer->original_outbound_state_change(sk);
+   		}
+	}
+	printk(KERN_INFO "Exiting function wg_tcp_state_change\n");
+}
+
+
+
+void log_wireguard_endpoint(struct endpoint *ep)
+{
+    char addr_str[INET6_ADDRSTRLEN];
+
+    if (!ep) {
+        printk(KERN_INFO "WireGuard: Endpoint is NULL.\n");
+        return;
+    }
+
+    switch (ep->addr.sa_family) {
+    case AF_INET: {
+        // Handle IPv4 address
+        struct sockaddr_in *sin = &ep->addr4;
+        snprintf(addr_str, sizeof(addr_str), "%pI4", &sin->sin_addr);
+        printk(KERN_INFO "Endpoint IPv4: %s:%u\n",
+               addr_str, ntohs(sin->sin_port));
+        if (ep->src_if4 != 0) {
+            snprintf(addr_str, sizeof(addr_str), "%pI4", &ep->src4);
+            printk(KERN_INFO "Source IPv4: %s, Source Interface: %d\n",
+                   addr_str, ep->src_if4);
+        }
+        break;
+    }
+    case AF_INET6: {
+        // Handle IPv6 address
+        struct sockaddr_in6 *sin6 = &ep->addr6;
+        snprintf(addr_str, sizeof(addr_str), "%pI6", &sin6->sin6_addr);
+        printk(KERN_INFO "Endpoint IPv6: [%s]:%u, Scope ID: %u\n",
+               addr_str, ntohs(sin6->sin6_port), sin6->sin6_scope_id);
+        snprintf(addr_str, sizeof(addr_str), "%pI6", &ep->src6);
+        printk(KERN_INFO "Source IPv6: [%s]\n", addr_str);
+        break;
+    }
+    default:
+        printk(KERN_INFO "Unsupported address family: %d\n", ep->addr.sa_family);
+        break;
+    }
+}
+
+
+
+void wg_get_endpoint_from_socket(struct socket *epsocket, struct endpoint *ep)
+{
+    // Validate input parameters
+    if (!epsocket || !ep) {
+        printk(KERN_ERR "Invalid input: epsocket or ep is NULL\n");
+        return;
+    }
+
+    // Validate the socket's `sock` structure
+    if (!epsocket->sk) {
+        printk(KERN_ERR "Invalid socket: epsocket->sk is NULL\n");
+        return;
+    }
+
+    struct sock *sk = epsocket->sk;
+    int family = sk->sk_family;
+
+    if (family == AF_INET) {
+        struct inet_sock *inet = inet_sk(sk);
+
+        // Validate inet_sk
+        if (!inet) {
+            printk(KERN_ERR "inet_sk is NULL for IPv4 socket\n");
+            return;
+        }
+
+        // Ensure that the inet_daddr and inet_dport are valid before accessing
+        if (inet->inet_daddr == 0 || inet->inet_dport == 0) {
+            printk(KERN_ERR "Invalid IPv4 address or port\n");
+            return;
+        }
+
+        // Populate the endpoint with IPv4 address and port
+        ep->addr4.sin_family = AF_INET;
+        ep->addr4.sin_addr.s_addr = inet->inet_daddr; // Remote IPv4 address
+        ep->addr4.sin_port = inet->inet_dport; // Remote port
+
+        // Populate src4 fields with local information
+        ep->src4.s_addr = inet->inet_saddr; // Local IPv4 address
+        ep->src_if4 = sk->sk_bound_dev_if; // Interface index
+
+        // Diagnostics
+        printk(KERN_INFO "IPv4 endpoint: remote %pI4:%u, local %pI4:%u\n",
+               &ep->addr4.sin_addr.s_addr, ntohs(ep->addr4.sin_port),
+               &ep->src4.s_addr, ntohs(inet->inet_sport));
+
+    }
+#if IS_ENABLED(CONFIG_IPV6)
+    else if (family == AF_INET6) {
+        struct ipv6_pinfo *np = inet6_sk(sk);
+
+        // Validate ipv6_pinfo
+        if (!np) {
+            printk(KERN_ERR "ipv6_pinfo is NULL for IPv6 socket\n");
+            return;
+        }
+
+        // Ensure that the IPv6 address and port are valid before accessing
+        if (ipv6_addr_any(&sk->sk_v6_daddr) || inet_sk(sk)->inet_dport == 0) {
+            printk(KERN_ERR "Invalid IPv6 address or port\n");
+            return;
+        }
+
+        // Populate the endpoint with IPv6 address and port
+        ep->addr6.sin6_family = AF_INET6;
+        ep->addr6.sin6_addr = sk->sk_v6_daddr; // Remote IPv6 address
+        ep->addr6.sin6_port = inet_sk(sk)->inet_dport; // Remote port
+        ep->addr6.sin6_scope_id = ipv6_iface_scope_id(&sk->sk_v6_rcv_saddr, sk->sk_bound_dev_if);
+
+        // Populate src6 fields with local information
+        ep->src6 = sk->sk_v6_rcv_saddr; // Local IPv6 address
+
+        // Diagnostics
+        printk(KERN_INFO "IPv6 endpoint: remote %pI6c:%u, local %pI6c:%u\n",
+               &ep->addr6.sin6_addr, ntohs(ep->addr6.sin6_port),
+               &ep->src6, ntohs(inet_sk(sk)->inet_sport));
+    }
+#endif
+    else {
+        printk(KERN_ERR "Unsupported address family: %d\n", family);
+        return;
+    }
+}
+
+int wg_tcp_queuepkt(struct wg_peer *peer, const void *data,
+                           size_t len)
+{
+	printk(KERN_INFO "Entering function wg_tcp_queuepkt peer=%p\n", peer);
+
+	struct endpoint current_endpoint;
+	struct wg_tcp_socket_list_entry *socket_iter;
+	bool found = false;
+	bool inbound = false;
+
+	if (!peer || IS_ERR(peer)) {
+		printk(KERN_INFO "Exiting function wg_tcp_queuepkt, no peer.\n");
+		return -EINVAL;
+	}	
+	print_peer_socket_info(peer);
+	if (!data || len == 0) {
+		printk(KERN_INFO "Exiting function wg_tcp_queuepkt, invalid parameters\n");
+		return -EINVAL;
+	}	
+
+	/* Print TCP-related flags */
+	printk(KERN_INFO "wg_peer: temp_peer = %d\n", peer->temp_peer);
+	printk(KERN_INFO "wg_peer: tcp_established = %d\n", peer->tcp_established);
+	printk(KERN_INFO "wg_peer: tcp_pending = %d\n", peer->tcp_pending);
+	printk(KERN_INFO "wg_peer: outbound_connected = %d\n", peer->outbound_connected);
+	printk(KERN_INFO "wg_peer: inbound_connected = %d\n", peer->inbound_connected);
+	printk(KERN_INFO "wg_peer: tcp_outbound_callbacks_set = %d\n", peer->tcp_outbound_callbacks_set);
+	printk(KERN_INFO "wg_peer: tcp_inbound_callbacks_set = %d\n", peer->tcp_inbound_callbacks_set);
+	log_wireguard_endpoint(&peer->endpoint);
+
+    	// Find the peer matching the endpoint, peer_endpoint, or tcp_reply_endpoint
+	peer = wg_find_peer_by_endpoints(peer->device, &peer->endpoint);
+    	if (!peer || IS_ERR(peer)) {
+        	printk(KERN_INFO "wg_queuepkt: No matching peer found for endpoint\n");
+        	return -ENOENT;
+    	}
+	
+	struct sk_buff *skb = alloc_skb(len + SKB_HEADER_LEN, GFP_ATOMIC);
+	if (!skb) {
+		printk(KERN_INFO "Exiting function wg_tcp_queuepkt\n");
+		return -ENOMEM;
+	}
+
+	skb_reserve(skb, SKB_HEADER_LEN);
+	skb_put_data(skb, data, len);
+
+	if (!peer->peer_socket) {
+		// peer connenction is down reconnect
+		if (wg_tcp_connect(peer) < 0) {
+			kfree_skb(skb);
+			printk(KERN_INFO "Exiting function wg_tcp_queuepkt due to connection failure\n");
+			return -ECONNREFUSED; // Connection attempt failed
+		}
+	}	
+
+	// Check if the current destination matches the peer's destination address, if not check pending connections
+	printk(KERN_INFO "Current endpoint:");
+	log_wireguard_endpoint(&current_endpoint);
+	printk(KERN_INFO "Peer endpoint:");
+	log_wireguard_endpoint(&peer->endpoint);
+	printk(KERN_INFO "Peer peer_endpoint:");
+	log_wireguard_endpoint(&peer->peer_endpoint);
+
+	if (!peer->tcp_established) {
+		// peer connenction is down reconnect
+		if (wg_tcp_connect(peer) < 0) {
+			kfree_skb(skb);
+			printk(KERN_INFO "Exiting function wg_tcp_queuepkt due to connection failure\n");
+			return -ECONNREFUSED; // Connection attempt failed
+		}
+	}
+	spin_lock_bh(&peer->send_queue_lock);
+	skb_queue_tail(&peer->send_queue, skb);
+	spin_unlock_bh(&peer->send_queue_lock);
+	// Trigger sending if possible
+	if (peer->peer_socket && peer->tcp_established) {
+		if (sk_stream_is_writeable(peer->peer_socket->sk)) {
+			wg_tcp_write_space(peer->peer_socket->sk);
+		} 
+	} 	
+	print_peer_socket_info(peer);
+	printk(KERN_INFO "Exiting function wg_tcp_queuepkt\n");
+	return 0;
+}
+
+// Simple checksum function for TCP encapsulation header
+static __be16 wg_header_checksum(const struct wg_tcp_encap_header *hdr)
+{
+	printk(KERN_INFO "Entering function wg_header_checksum\n");
+    	uint16_t checksum = 0;
+    	uint32_t length = ntohl(hdr->length); // Ensure network byte order is converted to host byte order for calculation
+
+    	// Break the length into two 16-bit halves and XOR them with the flags and type
+    	checksum ^= (length >> 16) & 0xFFFF;
+    	checksum ^= length & 0xFFFF;
+    	checksum ^= (hdr->flags << 8) | hdr->type;
+
+    	// Simple rotate to mix bits a bit more
+    	checksum = (checksum << 5) | (checksum >> (16 - 5));
+
+	// XOR the checksum with a constant to prevent trivial values like all zeros or all ones passing the checksum
+	const uint16_t constant = 0xA5A5;  // constant pattern
+	checksum ^= constant;
+	
+    	return htons(checksum); // Convert back to network byte order
+	printk(KERN_INFO "Exiting function wg_header_checksum\n");
+}
+
+// Function to validate the header checksum
+static bool wg_validate_header_checksum(const struct wg_tcp_encap_header *hdr)
+{
+	printk(KERN_INFO "Entering function wg_validate_header_checksum\n");
+	printk(KERN_INFO "Exiting function wg_validate_header_checksum\n");
+    	return wg_header_checksum(hdr) == hdr->checksum;
+}
+
+
+static int wg_tcp_send(struct socket *sock, const void *buff, size_t len,
+		       __u8 type, __u8 flags)
+{
+	struct wg_tcp_encap_header header;
+    	struct msghdr msg = { .msg_flags = MSG_DONTWAIT | MSG_NOSIGNAL };
+    	struct kvec vec[2];
+    	int sent;
+
+    	// Logging entry into the function
+    	printk(KERN_INFO "wg_tcp_send: Entering function\n");
+
+    	// Prepare the header
+	header.length = htonl(len + WG_TCP_ENCAP_HDR_LEN); // Include the payload length and header length
+    	header.type = type;
+    	header.flags = flags;
+    	header.checksum = wg_header_checksum(&header); // Compute checksum for the header
+
+	// Log header information
+	printk(KERN_INFO "wg_tcp_send: Header - Length: %u, Type: %u, Flags: %u, Checksum: 0x%x\n",
+		ntohl(header.length), header.type, header.flags, ntohs(header.checksum));
+
+	// Set up the vector for the header and the payload
+    	vec[0].iov_base = &header;
+	vec[0].iov_len = WG_TCP_ENCAP_HDR_LEN;
+    	vec[1].iov_base = (void *)buff; // Cast away const
+    	vec[1].iov_len = len;
+
+	// Log payload information
+	printk(KERN_INFO "wg_tcp_send: Payload - Length: %zu, First 16 Bytes: %*ph\n", len, 16, buff);
+
+	// Send the message including the header and the payload
+	sent = kernel_sendmsg(sock, &msg, vec, 2, WG_TCP_ENCAP_HDR_LEN + len);
+	if (sent >= 0) {
+		// Successfully sent some or all data
+		printk(KERN_INFO "wg_tcp_send: Sent %d bytes\n", sent);
+		printk(KERN_INFO "wg_tcp_send: Exiting function successfully\n");
+		return sent;
+	} else {
+		// An error occurred; return the error code
+		switch (sent) {
+			case -EAGAIN:
+				printk(KERN_WARNING "wg_tcp_send: Send would block, socket buffer full (EAGAIN)\n");
+				break;
+			case -EPIPE:
+				printk(KERN_ERR "wg_tcp_send: Broken pipe (EPIPE)\n");
+				break;
+			case -EINVAL:
+				printk(KERN_ERR "wg_tcp_send: Invalid argument (EINVAL)\n");
+				break;
+			case -ENOMEM:
+				printk(KERN_ERR "wg_tcp_send: Out of memory (ENOMEM)\n");
+				break;
+			case -ENOTCONN:
+				printk(KERN_ERR "wg_tcp_send: Socket is not connected (ENOTCONN)\n");
+				break;
+			default:
+				printk(KERN_ERR "wg_tcp_send: Error %d\n", sent);
+				break;
+		}
+		printk(KERN_INFO "wg_tcp_send: Exiting function with error\n");
+		return sent;
+	}
+}
+void wg_tcp_write_worker(struct work_struct *work)
+{
+	
+	struct wg_peer *peer = container_of(work, struct wg_peer, tcp_write_work);
+	struct sock *sk = peer->peer_socket->sk;    
+    	struct sk_buff *skb;
+    	int sent;
+
+	printk(KERN_INFO "Entering function wg_tcp_write_worker\n");
+
+	if (!peer) {
+		printk(KERN_INFO "wg_tcp_write_worker peer is NULL\n");
+		goto out;
+	}
+	if (!peer->peer_socket) {
+		printk(KERN_INFO "wg_tcp_write_worker peer->peer_socker is NULL\n");
+		goto out;
+	}
+	
+    	if (!sk_stream_is_writeable(sk)) {
+        	// Socket is not ready for writing, exit and wait for sk_write_space activation
+		printk(KERN_INFO "wg_tcp_write_worker sk stream is NOT writeable\n");
+        	goto out;
+	}
+
+    	while ((skb = skb_peek(&peer->send_queue)) != NULL && sk_stream_is_writeable(sk)) {
+		sent = wg_tcp_send(peer->peer_socket, skb->data, skb->len, 0, 0);  // no type or flags for now
+		printk(KERN_INFO "wg_tcp_write_worker sent %d bytes\n", sent);
+        	if (sent > 0) {
+            		if (sent < skb->len) {
+                		// Handle partial send by trimming the skb and leaving it in the queue
+                		skb_pull(skb, sent);
+			} else {
+				// Full send successful, dequeue and free the skb
+				spin_lock_bh(&peer->send_queue_lock);
+				__skb_unlink(skb, &peer->tcp_packet_queue);
+				spin_unlock_bh(&peer->send_queue_lock);
+				kfree_skb(skb);
+			}
+        	} else if (sent == 0) {
+            		// Socket buffer is full, stop sending and wait for sk_write_space
+			printk(KERN_INFO "wg_tcp_write_worker socket buffer is full\n");
+            		break;
+        	} else {
+			// An error occurred, dequeue and free the skb
+			spin_lock_bh(&peer->send_queue_lock);
+			__skb_unlink(skb, &peer->tcp_packet_queue);
+			spin_unlock_bh(&peer->send_queue_lock);
+            		kfree_skb(skb);
+            			break;
+        	}
+    	}
+
+out:
+	spin_lock_bh(&peer->tcp_write_lock);
+	peer->tcp_write_worker_scheduled = false;
+	spin_unlock_bh(&peer->tcp_write_lock);
+	printk(KERN_INFO "Exiting function wg_tcp_write_work\n");
+}
+
+void wg_peer_discard_partial_read(struct wg_peer *peer);
+
+void wg_peer_discard_partial_read(struct wg_peer *peer)
+{
+	if (peer->partial_skb)
+		kfree_skb(peer->partial_skb);
+	peer->partial_skb = NULL;
+	peer->expected_len = 0;
+	peer->received_len = 0;
+}
+
+bool wg_sync_header(struct wg_peer *peer);
+
+bool wg_sync_header(struct wg_peer *peer)
+{
+	struct sk_buff *read_skb = NULL;
+	struct msghdr msg = { .msg_flags = MSG_DONTWAIT };
+	struct kvec vec;
+	int read_bytes;
+	bool found = false;
+	// Attempt to read as much data as available from the socket
+	printk(KERN_INFO "Entering function wg_sync_header\n");
+
+	// Now attempt to find the next valid header within the data we already have
+	printk(KERN_INFO "wg_sync_header: Trying to synchonize to new header.\n");
+	if (peer->partial_skb && peer->received_len > WG_TCP_ENCAP_HDR_LEN) {
+		// If there are less then 8 bytes left, give up (there's no room for a wg_tcp_encap_header)
+		for (size_t i = 0; i <= peer->received_len - WG_TCP_ENCAP_HDR_LEN; ++i) {
+			// Attempt to validate the header starting from the current byte
+			struct wg_tcp_encap_header *potential_hdr = (struct wg_tcp_encap_header *)(peer->partial_skb + i);
+			if (wg_validate_header_checksum(potential_hdr)) {
+				printk(KERN_INFO "wg_sync_header: Found new header.\n");
+				found = true;
+				// Adjust the skb to start from the found valid header
+				skb_pull(peer->partial_skb, i);
+				peer->received_len -= i; // Update received_len to remaining data length
+				peer->expected_len = ntohl(potential_hdr->length); // Set expected length from valid header
+				goto out; // Exit as we've found a starting point
+			}		
+		}
+	}
+	// not in the existing buffer, try to read more
+	read_skb = alloc_skb(WG_MAX_PACKET_SIZE + NET_IP_ALIGN, GFP_ATOMIC); // Allocate buffer for bulk read
+	if (!read_skb) {
+					pr_err("WireGuard: Failed to allocate skb for bulk data read\n");
+	}
+	skb_reserve(read_skb, NET_IP_ALIGN);
+	
+	// Perform the read operation
+	vec.iov_base = skb_put(read_skb,0); // Prepare space
+	vec.iov_len = skb_tailroom(read_skb);
+	read_bytes = kernel_recvmsg(peer->peer_socket, &msg, &vec, 1, vec.iov_len,
+						MSG_DONTWAIT );
+
+	// Print the number of bytes read and the actual data
+	printk(KERN_INFO "wg_sync_header: kernel_recvmsg read %d bytes: %*ph\n", (int)read_bytes, (int)read_bytes, vec.iov_base);
+	
+	if (read_bytes <= 0) {
+		if (read_bytes == -EAGAIN) {
+			// No more data available, exit
+			kfree_skb(read_skb);
+			goto out;
+		}
+		pr_err("WireGuard: Error receiving bulk data from socket\n");
+		kfree_skb(read_skb);
+		goto out;
+	}
+	skb_trim(read_skb, read_bytes); // Trim skb to actual size of received data
+	
+	// Now attempt to find the next valid header within the newly read data
+	printk(KERN_INFO "wg_sync_header: Trying to synchonize to new header.\n");
+	for (size_t i = 0; i <= read_skb->len - WG_TCP_ENCAP_HDR_LEN; ++i) {
+		// Attempt to validate the header starting from the current byte
+		struct wg_tcp_encap_header *potential_hdr = (struct wg_tcp_encap_header *)(read_skb->data + i);
+		if (wg_validate_header_checksum(potential_hdr)) {
+			printk(KERN_INFO "wg_sync_header: Found new header.\n");
+			found = true;
+			// Adjust the skb to start from the found valid header
+			skb_pull(read_skb, i);
+			if (peer->partial_skb)
+					kfree_skb(peer->partial_skb);  // free discarded data buffer
+			peer->partial_skb = read_skb; // Transfer ownership of the buffer to partial_skb for further processing
+			peer->received_len = read_bytes - i; // Update received_len to remaining data length
+			peer->expected_len = ntohl(potential_hdr->length); // Set expected length from valid header
+			break; // Exit the loop as we've found a starting point
+		}		
+	}
+	if (!found){
+		wg_peer_discard_partial_read(peer);
+		kfree_skb(read_skb);
+	}
+out:
+	printk(KERN_INFO "Exiting function wg_sync_header\n");
+	return found;
+}
+
+// Function to check if the given data pointer has a valid WireGuard TCP encapsulation header
+bool wg_check_potential_header_validity(struct wg_tcp_encap_header *hdr, size_t remaining_len)
+{
+    printk(KERN_INFO "Entering function wg_check_potential_header_validity\n");
+
+    if (remaining_len < WG_TCP_ENCAP_HDR_LEN) {
+        printk(KERN_INFO "Not enough data for a header, remaining length: %zu\n", remaining_len);
+        printk(KERN_INFO "Exiting function wg_check_potential_header_validity\n");
+        return false;
+    }
+
+    // Perform checksum validation
+    bool valid = wg_header_checksum(hdr) == hdr->checksum;
+
+    printk(KERN_INFO "Header Checksum Validation - Expected: 0x%x, Actual: 0x%x, Valid: %d\n",
+           ntohs(hdr->checksum), ntohs(wg_header_checksum(hdr)), valid);
+    printk(KERN_INFO "Header Hexdump: %*ph\n", (int)sizeof(*hdr), hdr);
+
+    printk(KERN_INFO "Exiting function wg_check_potential_header_validity\n");
+    return valid;
+}
+
+int wg_tcp_build_fake_headers(struct sk_buff *skb, struct wg_peer *peer)
+{
+	struct ethhdr *ethh;
+	struct iphdr *iph;
+	struct udphdr *udph;
+	int payload_len;
+	int ret;
+
+	// Diagnostic: Print SKB state on entry
+	printk(KERN_INFO "Entering wg_tcp_build_fake_headers. SKB state on entry: "
+	       "skb=%p, len=%d, head=%p, data=%p, tail=%p, end=%p, headroom=%d, tailroom=%d\n",
+	       skb, skb->len, skb->head, skb->data, skb->tail, skb->end, skb_headroom(skb), skb_tailroom(skb));
+
+	log_wireguard_endpoint(&peer->endpoint);
+
+	// Initialize address pointers
+	struct sockaddr_in *source = NULL;
+	struct sockaddr_in *dest = NULL;
+#if IS_ENABLED(CONFIG_IPV6)
+	struct sockaddr_in6 *source6 = NULL;
+	struct sockaddr_in6 *dest6 = NULL;
+#endif
+
+	// Determine source and destination addresses based on socket association
+	if (peer->peer_socket == peer->inbound_socket) {
+		if (peer->inbound_source.ss_family == AF_INET) {
+			source = (struct sockaddr_in *)&peer->inbound_dest;
+			dest = (struct sockaddr_in *)&peer->inbound_source;
+#if IS_ENABLED(CONFIG_IPV6)
+		} else if (peer->inbound_source.ss_family == AF_INET6) {
+			source6 = (struct sockaddr_in6 *)&peer->inbound_dest;
+			dest6 = (struct sockaddr_in6 *)&peer->inbound_source;
+#endif
+		}
+	} else {
+		if (peer->outbound_source.ss_family == AF_INET) {
+			source = (struct sockaddr_in *)&peer->outbound_dest;
+			dest = (struct sockaddr_in *)&peer->outbound_source;
+#if IS_ENABLED(CONFIG_IPV6)
+		} else if (peer->outbound_source.ss_family == AF_INET6) {
+			source6 = (struct sockaddr_in6 *)&peer->outbound_dest;
+			dest6 = (struct sockaddr_in6 *)&peer->outbound_source;
+#endif
+		}
+	}
+
+	// Ensure the SKB is linearized
+	if (skb_linearize(skb) != 0) {
+		printk(KERN_ERR "wg_tcp_build_fake_headers: Failed to linearize SKB.\n");
+		return -ENOMEM;
+	}
+
+	// Diagnostic: Print SKB state after linearization
+	printk(KERN_INFO "After skb_linearize: skb=%p, len=%d, head=%p, data=%p, tail=%p, end=%p, skb->len=%d, headroom=%d, tailroom=%d\n",
+	       skb, skb->len, skb->head, skb->data, skb->tail, skb->end, skb->len, skb_headroom(skb), skb_tailroom(skb));
+
+	// Calculate the payload length: initial length of skb before any header is added
+	payload_len = skb->len;
+
+	// Push and reset for UDP header
+	skb_push(skb, sizeof(struct udphdr));
+	skb_reset_transport_header(skb);
+
+	// Diagnostic: Print UDP header location
+	printk(KERN_INFO "UDP header location: %p, length: %zu\n",
+	       skb_transport_header(skb), sizeof(struct udphdr));
+
+	// Push and reset for IP header
+	if (peer->endpoint.addr.sa_family == AF_INET) {
+		skb_push(skb, sizeof(struct iphdr));
+		skb_reset_network_header(skb);
+		printk(KERN_INFO "IPv4 header location: %p, length: %zu\n",
+		       skb_network_header(skb), sizeof(struct iphdr));
+#if IS_ENABLED(CONFIG_IPV6)
+	} else if (peer->endpoint.addr.sa_family == AF_INET6) {
+		skb_push(skb, sizeof(struct ipv6hdr));
+		skb_reset_network_header(skb);
+		printk(KERN_INFO "IPv6 header location: %p, length: %zu\n",
+		       skb_network_header(skb), sizeof(struct ipv6hdr));
+#endif
+	} else {
+		printk(KERN_ERR "wg_tcp_build_fake_headers: Unsupported address family.\n");
+		return -EAFNOSUPPORT;
+	}
+
+	// Push and reset for Ethernet header
+	skb_push(skb, sizeof(struct ethhdr));
+	skb_reset_mac_header(skb);
+
+	// Diagnostic: Print Ethernet header location
+	printk(KERN_INFO "Ethernet header location: %p, length: %zu\n",
+	       skb_mac_header(skb), sizeof(struct ethhdr));
+
+	// Diagnostic: Print SKB state after header manipulation
+	printk(KERN_INFO "After header manipulation: skb=%p, len=%d, head=%p, data=%p, tail=%p, end=%p, skb->len=%d, headroom=%d, tailroom=%d\n",
+	       skb, skb->len, skb->head, skb->data, skb->tail, skb->end, skb->len, skb_headroom(skb), skb_tailroom(skb));
+
+	// Set Ethernet header (ethh) fields
+	ethh = eth_hdr(skb);
+	ethh->h_proto = htons(peer->endpoint.addr.sa_family == AF_INET ? ETH_P_IP : ETH_P_IPV6);
+
+	// Set UDP header fields
+	udph = udp_hdr(skb);
+	if (source) { // IPv4 case
+		udph->source = source->sin_port;
+		udph->dest = dest->sin_port;
+#if IS_ENABLED(CONFIG_IPV6)
+	} else if (source6) { // IPv6 case
+		udph->source = source6->sin6_port;
+		udph->dest = dest6->sin6_port;
+#endif
+	}
+	udph->len = htons(sizeof(struct udphdr) + payload_len);
+	udph->check = 0; // Checksum will be calculated later
+
+	if (peer->endpoint.addr.sa_family == AF_INET) {
+		// Fill in the IPv4 header
+		iph = ip_hdr(skb);
+		iph->version = 4;
+		iph->ihl = 5;
+		iph->tos = 0;
+		iph->tot_len = htons(sizeof(struct iphdr) + sizeof(struct udphdr) + payload_len);
+		iph->id = 0;
+		iph->frag_off = 0;
+		iph->ttl = 64;
+		iph->protocol = IPPROTO_UDP;
+		iph->check = 0;
+		iph->saddr = source->sin_addr.s_addr;
+		iph->daddr = dest->sin_addr.s_addr;
+
+		// Calculate IP checksum
+		iph->check = ip_fast_csum((u8 *)iph, iph->ihl);
+
+		// Calculate UDP checksum for IPv4
+		__wsum csum = csum_partial(udph, ntohs(udph->len), 0);
+		udph->check = htons(csum_tcpudp_magic(iph->saddr, iph->daddr, udph->len, IPPROTO_UDP, csum));
+		if (udph->check == 0)
+			udph->check = CSUM_MANGLED_0;
+
+		skb->protocol = htons(ETH_P_IP);
+#if IS_ENABLED(CONFIG_IPV6)
+	} else if (peer->endpoint.addr.sa_family == AF_INET6) {
+		struct ipv6hdr *ip6h = ipv6_hdr(skb);
+
+		// Fill in the IPv6 header
+		ip6h->version = 6;
+		ip6h->priority = 0;
+		memset(ip6h->flow_lbl, 0, sizeof(ip6h->flow_lbl));
+		ip6h->payload_len = htons(sizeof(struct udphdr) + payload_len);
+		ip6h->nexthdr = IPPROTO_UDP;
+		ip6h->hop_limit = 64;
+		ip6h->saddr = source6->sin6_addr;
+		ip6h->daddr = dest6->sin6_addr;
+
+		// Calculate UDP checksum for IPv6
+		__wsum csum = csum_partial(udph, ntohs(udph->len), 0);
+		csum = csum_partial(&ip6h->saddr, sizeof(struct in6_addr), csum);
+		csum = csum_partial(&ip6h->daddr, sizeof(struct in6_addr), csum);
+		csum = csum_add(csum, htons(ntohs(udph->len)));
+		csum = csum_add(csum, htons(IPPROTO_UDP));
+
+		udph->check = csum_fold(csum);
+		if (udph->check == 0)
+			udph->check = CSUM_MANGLED_0;
+
+		skb->protocol = htons(ETH_P_IPV6);
+#endif
+	} else {
+		printk(KERN_ERR "wg_tcp_build_fake_headers: Unsupported address family.\n");
+		return -EAFNOSUPPORT;
+	}
+
+	// Pull to reset skb->data pointer back to original payload start
+	skb_pull(skb, sizeof(struct ethhdr));
+	skb_pull(skb, (peer->endpoint.addr.sa_family == AF_INET) ? sizeof(struct iphdr) : sizeof(struct ipv6hdr));
+	skb_pull(skb, sizeof(struct udphdr));
+
+	// Diagnostic: Print SKB state after header manipulation
+	printk(KERN_INFO "After header pull on exit: skb=%p, len=%d, head=%p, data=%p, tail=%p, end=%p, headroom=%d, tailroom=%d\n",
+	       skb, skb->len, skb->head, skb->data, skb->tail, skb->end, skb_headroom(skb), skb_tailroom(skb));
+
+	return 0;
+}
+
+
+
+void wg_tcp_read_worker(struct work_struct *work)
+{
+	
+	printk(KERN_INFO "Entering function wg_tcp_read_worker\n");
+	struct wg_peer *peer = container_of(work, struct wg_peer, tcp_read_work);
+	struct sock *sk = peer->peer_socket->sk;    
+	struct msghdr msg = { .msg_flags = MSG_DONTWAIT };
+	struct kvec vec;
+	ssize_t read_bytes;
+	unsigned maxpacket;
+	struct sk_buff *new_skb = NULL;
+
+
+	if (!peer || IS_ERR(peer))
+		goto out;
+	if (!peer->peer_socket)
+		goto out;
+	print_peer_socket_info(peer);
+// XXX not sure needed	lock_sock(sk); // Lock the socket for reading
+	maxpacket = 8192;
+	while (true) {
+			printk(KERN_INFO "wg_peer diagnostic: partial_skb=%p, expected_len=%zu, received_len=%zu\n",
+       				peer->partial_skb, peer->expected_len, peer->received_len);
+			if (!peer->partial_skb) {
+				printk(KERN_INFO "wg_tcp_read_worker: Allocating new skb.\n");
+				// Allocate buffer for the maximum packet size initially, including space for ethernet, IP and UDP headers
+				new_skb = alloc_skb(maxpacket*3 + NET_IP_ALIGN + sizeof(struct iphdr) + sizeof(struct udphdr) + ETH_HLEN + 32, GFP_ATOMIC);
+				if (!new_skb) {
+					pr_err("WireGuard: Failed to allocate skb\n");
+					break;
+				}
+				// Reserve space for headers and align the data correctly
+				skb_reserve(new_skb, NET_IP_ALIGN + sizeof(struct iphdr) + sizeof(struct udphdr)  + ETH_HLEN + 32);
+
+				peer->expected_len = 0;
+				peer->partial_skb = new_skb;
+			} 
+			// Make sure we hav enough room for at least an encapsulation header
+			if (skb_tailroom(peer->partial_skb) < WG_TCP_ENCAP_HDR_LEN) {
+				printk(KERN_INFO "wg_tcp_read_worker: Reallocating skb to fit the encapsulation header.\n");
+				// Check if the current skb has enough room; if not, reallocate a new skb with sufficient space;
+				new_skb = skb_copy_expand(peer->partial_skb, skb_headroom(peer->partial_skb), WG_MAX_PACKET_SIZE + NET_IP_ALIGN + 
+				       					sizeof(struct iphdr) + sizeof(struct udphdr) + ETH_HLEN, GFP_ATOMIC);
+				if (!new_skb) {
+					pr_err("WireGuard: Failed to reallocate skb\n");
+					wg_peer_discard_partial_read(peer);
+					break;
+				}
+				// Free the old skb and replace it with the new one
+				kfree_skb(peer->partial_skb);
+				peer->partial_skb = new_skb;
+			} 
+			// Read as much data as fits into the skb buffer
+			vec.iov_base = peer->partial_skb->data;
+			vec.iov_len = skb_tailroom(peer->partial_skb);
+			if (vec.iov_len > 0) {
+				read_bytes = kernel_recvmsg(peer->peer_socket, &msg, &vec, 1, vec.iov_len, msg.msg_flags);
+				printk(KERN_INFO "wg_tcp_read_worker: kernel_recvmsg read %ld bytes: %*ph\n", read_bytes, (int)read_bytes, vec.iov_base);
+				if (read_bytes <= 0) {
+					if (read_bytes == -EAGAIN) {
+						printk(KERN_INFO "wg_tcp_read_worker: No more data available.\n");
+						break; // No more data available, exit the loop
+					} else {
+						pr_err("WireGuard: Error receiving data from socket\n");
+						wg_peer_discard_partial_read(peer);
+		   				break;
+					}
+				}
+				skb_put(peer->partial_skb, read_bytes);
+				peer->received_len += read_bytes;
+			} 
+			// check header
+			if (peer->received_len >= WG_TCP_ENCAP_HDR_LEN) {
+	            		// Complete header received, validate and prepare for packet data
+				printk("wg_tcp_read_worker: We have a header, let's check it.\n");
+				struct wg_tcp_encap_header *hdr = (struct wg_tcp_encap_header *)peer->partial_skb->data;
+				// Check header validity
+				// Use wg_validate_header_checksum as the criteria for checking header validity
+				if (!wg_check_potential_header_validity((struct wg_tcp_encap_header *)hdr, peer->received_len)) {
+					pr_err("WireGuard: Invalid packet header detected, attempting to resynchronize\n");
+					if (!wg_sync_header(peer)) {
+						pr_err("WireGuard: Failed to find valid header in bulk read data\n");
+						wg_peer_discard_partial_read(peer);
+						break;	
+					}
+				}
+				peer->expected_len = ntohl(hdr->length);
+			} else {
+				// not enough data
+				break;
+			}
+			printk(KERN_INFO "wg_tcp_read_worker: We have a header, let's process the packet body.\n");
+			// If received_len is greater than expected_len (which includes WG_TCP_ENCAP_HDR_LEN),
+			// it implies there's more data potentially for another packet or part of the current
+			//packet beyond what was expected.
+			if (peer->received_len < peer->expected_len) {
+				printk(KERN_INFO "wg_tcp_read_worker: We need more data for a full packet expected len=%d received_len=%d\n", (int)peer->expected_len, (int)peer->received_len);
+				if ((skb_tailroom(peer->partial_skb) < peer->expected_len) &&
+						  (peer->received_len < peer->expected_len)) {
+					printk(KERN_INFO "wg_tcp_read_worker: Expanding buffer to fit whole packet.\n");
+					// check if need a bigger buffer
+					struct sk_buff *resized_skb = skb_copy_expand(peer->partial_skb, 0,
+									peer->expected_len - skb_tailroom(peer->partial_skb),
+									GFP_ATOMIC);
+					if (!resized_skb) {
+						pr_err("WireGuard: Failed to resize skb\n");
+						wg_peer_discard_partial_read(peer);
+						break;
+					}
+					if (peer->partial_skb)
+						kfree_skb(peer->partial_skb);
+					peer->partial_skb = resized_skb;
+				}
+	            
+			}
+			printk(KERN_INFO "Expected Length: %d Received Length: %d\n", peer->expected_len, peer->received_len);
+   			// Check if we've received the complete packet now
+			if (peer->received_len >= peer->expected_len && peer->received_len > WG_TCP_ENCAP_HDR_LEN) {
+				printk(KERN_INFO "wg_tcp_read_worker: We have a complete packet.\n");
+
+				// Remove the encapsulation header from the skb
+				skb_pull(peer->partial_skb, WG_TCP_ENCAP_HDR_LEN);
+				peer->received_len -= WG_TCP_ENCAP_HDR_LEN;
+				peer->expected_len -= WG_TCP_ENCAP_HDR_LEN;
+				printk(KERN_INFO "Packet: %*ph\n", peer->received_len, peer->partial_skb->data);
+				printk(KERN_INFO "skb->len=%d received_len=%d expected_len=%d\n", peer->partial_skb->len, peer->expected_len, peer->received_len);
+				// Check if the skb has a valid length
+				if (unlikely(peer->partial_skb->len <= 0)) {
+					pr_warn("wg_receive: Dropped packet with invalid length %d\n", peer->partial_skb->len);
+					wg_peer_discard_partial_read(peer);  // Reset for the next packet
+					break;
+				}
+				// Calculate leftover data length
+				size_t leftover_len = peer->received_len - peer->expected_len;
+				struct sk_buff *leftover_skb = NULL;
+				if (leftover_len > 0) {
+					// Trim the partial_skb to exclude the leftover data
+					skb_trim(peer->partial_skb, peer->expected_len);
+					leftover_skb = alloc_skb(maxpacket*3 + NET_IP_ALIGN + sizeof(struct iphdr) + sizeof(struct udphdr) + ETH_HLEN + 32, GFP_ATOMIC);
+					if (!new_skb) {
+						pr_err("WireGuard: Failed to allocate skb\n");
+						break;
+					}
+					// Reserve space for headers and align the data correctly
+					skb_reserve(new_skb, NET_IP_ALIGN + sizeof(struct iphdr) + sizeof(struct udphdr)  + ETH_HLEN + 32);
+
+
+					// Diagnostic: Check skb pointers and lengths after skb_reserve
+					printk(KERN_INFO "Diagnostic after skb_reserve:\n");
+					printk(KERN_INFO "skb=%p, len=%d, headroom=%d, tailroom=%d, head=%p, data=%p, tail=%p, end=%p\n",
+       							new_skb, new_skb->len, skb_headroom(new_skb), skb_tailroom(new_skb), new_skb->head,
+       							new_skb->data, new_skb->tail, new_skb->end);
+					// Error checking: Verify the buffer pointers are set correctly
+#ifdef BROKENCHECK
+					if (unlikely(new_skb->data != new_skb->head + NET_IP_ALIGN + sizeof(struct iphdr) + sizeof(struct udphdr) + ETH_HLEN + 32)) {
+					pr_err("Error: skb_reserve did not set the data pointer correctly. Expected offset: %lu, Actual offset: %lu\n",
+           								(unsigned long)(new_skb->head + NET_IP_ALIGN + sizeof(struct iphdr) + sizeof(struct udphdr) + ETH_HLEN + 32),
+           								(unsigned long)new_skb->data);
+    						kfree_skb(new_skb);
+						new_skb = NULL;
+    						wg_peer_discard_partial_read(peer);
+    						return;
+					}
+#endif // BROKENCHECK
+					if (peer->expected_len + leftover_len <= peer->partial_skb->len) {
+						if (skb_copy_bits(peer->partial_skb, peer->expected_len, leftover_skb->data, leftover_len) < 0) {
+							pr_err("wg_tcp_read_worker: Failed to copy leftover data.\n");
+								kfree_skb(leftover_skb);
+								leftover_skb = NULL;
+								wg_peer_discard_partial_read(peer);
+								break;
+						}
+					} else {
+   						pr_err("wg_tcp_read_worker: Invalid leftover length, expected_len=%d, received_len=%d, skb_len=%d\n",
+           					(int)peer->expected_len, (int)peer->received_len, (int)peer->partial_skb->len);
+    						wg_peer_discard_partial_read(peer);
+    						break;
+					}
+	
+					printk(KERN_INFO "wg_tcp_read_worker: Leftover data at end of packet, leftover_len=%d\n", (int)leftover_len);
+					// Use skb_copy_bits to copy data from the end of partial_skb to the new leftover_skb
+					if (skb_copy_bits(peer->partial_skb, peer->expected_len, leftover_skb->data, leftover_len) < 0) {
+						pr_err("wg_tcp_read_worker: Failed to copy leftover data.\n");
+						kfree_skb(leftover_skb);
+						leftover_skb = NULL;
+						wg_peer_discard_partial_read(peer);
+						break;
+					}
+
+					skb_set_tail_pointer(leftover_skb, leftover_len);
+	   				printk(KERN_INFO "wg_tcp_read_worker: leftover_skb after copy, leftover_skb=%p, len=%d, headroom=%d, data=%p, tail=%p, end=%p\n",
+						leftover_skb, leftover_skb->len, skb_headroom(leftover_skb), leftover_skb->data, leftover_skb->tail, leftover_skb->end);
+				}
+				skb_set_tail_pointer(peer->partial_skb, peer->expected_len); // should be redundant
+				// Build the UDP and IP headers
+				if (wg_tcp_build_fake_headers(peer->partial_skb, peer)) {
+					pr_err("WireGuard: Failed to build UDP/IP headers\n");
+					wg_peer_discard_partial_read(peer);
+					break;
+				}
+				// Process the complete packet
+				printk(KERN_INFO "wg_tcp_read_worker: partial_skb after trim, partial_skb=%p, len=%d, head=%p, data=%p, tail=%p, end=%p\n",
+								peer->partial_skb, peer->partial_skb->len, peer->partial_skb->head,
+								peer->partial_skb->data, peer->partial_skb->tail, peer->partial_skb->end);
+
+				wg_receive(sk, peer->partial_skb); // wg_receive consumes the skb
+
+				peer->partial_skb = NULL;  // wg_receive ate the data skb
+				if (leftover_len > 0) {
+					// Store the leftover skb (if any) in peer->partial_skb
+					peer->partial_skb = leftover_skb;
+					peer->received_len = leftover_len;
+
+				} else
+					peer->received_len = 0;
+				peer->expected_len = 0; // Reset for the next packet
+			}
+	}
+// XXX not sure needed	release_sock(sk); // Unlock the socket
+	
+out:
+	// Reset the flag to indicate the worker has finished processing
+	spin_lock_bh(&peer->tcp_read_lock);
+	peer->tcp_read_worker_scheduled = false;
+	spin_unlock_bh(&peer->tcp_read_lock);
+	printk(KERN_INFO "Exiting function wg_tcp_read_worker\n");
+}
+
+void wg_tcp_data_ready(struct sock *sk)
+{
+	printk(KERN_INFO "Entering function wg_tcp_data_ready\n");
+	
+	// Ensure the socket is valid
+	if (!sk || IS_ERR(sk)) {
+		printk(KERN_ERR "wg_tcp_data_ready: Invalid socket\n");
+		goto out;
+	}
+
+	// Retrieve the socket user data
+	struct wg_socket_data *socket_data = sk->sk_user_data;
+
+	// Check if socket_data is valid
+	if (!socket_data || IS_ERR(socket_data)) {
+		printk(KERN_ERR "wg_tcp_data_ready: Invalid or NULL socket_data\n");
+		goto out;
+	}
+
+	// Retrieve the peer from the socket_data
+	struct wg_peer *peer = socket_data->peer;
+
+	// Check if peer is valid
+	if (!peer || IS_ERR(peer)) {
+		printk(KERN_ERR "wg_tcp_data_Ready: Invalid or NULL peer\n");
+		goto out;
+	}
+
+	
+	spin_lock_bh(&peer->tcp_read_lock);
+
+	// Check if the worker is already scheduled
+	if (!peer->tcp_read_worker_scheduled) {
+        	peer->tcp_read_worker_scheduled = true;
+		queue_work(peer->tcp_read_wq, &peer->tcp_read_work);
+	}
+
+	spin_unlock_bh(&peer->tcp_read_lock);
+
+out:	
+    	// Call the original data_ready callback if it exists
+	if (((struct wg_socket_data *)sk->sk_user_data)->inbound) {
+	    	if (peer->original_inbound_data_ready) {
+        		peer->original_inbound_data_ready(sk);
+   		}
+	} else {
+		if (peer->original_outbound_data_ready) {
+        		peer->original_outbound_data_ready(sk);
+   		}
+	}
+	printk(KERN_INFO "Exiting function wg_tcp_data_ready\n");
+}
+
+void wg_tcp_write_space(struct sock *sk)
+{
+	printk(KERN_INFO "Entering function wg_tcp_write_space\n");
+	struct wg_peer *peer;
+	struct wg_socket_data *socket_data;
+	if (!sk)
+		goto out;
+	socket_data = sk->sk_user_data;
+	if (!socket_data || IS_ERR(socket_data))
+		goto out;
+	peer = socket_data->peer;
+	if (!peer || IS_ERR(peer)) {
+		printk(KERN_INFO "wg_tcp_write_space peer is NULL\n");
+		goto out;
+	}
+	if (!peer->tcp_write_wq) {
+		printk(KERN_INFO "wg_tcp_write_space peer->tcp_write_wq is NULL\n");
+		goto out;
+	}
+	
+	spin_lock_bh(&peer->tcp_write_lock);
+
+	// Check if the worker is already scheduled
+	if (!peer->tcp_write_worker_scheduled) {
+		printk(KERN_INFO "wg_tcp_write_space setting peer->tcp_write_worker_scheduled = true\n");
+        	peer->tcp_write_worker_scheduled = true;
+		printk(KERN_INFO "wg_tcp_write_space calling queue_work()\n");
+		queue_work(peer->tcp_write_wq, &peer->tcp_write_work);
+	}
+
+	spin_unlock_bh(&peer->tcp_write_lock);
+out:
+    	// Call the original write_space callback if it exists
+	if (((struct wg_socket_data *)sk->sk_user_data)->inbound) {
+	    	if (peer->original_inbound_write_space) {
+        		peer->original_inbound_write_space(sk);
+   		}
+	} else {
+		if (peer->original_outbound_write_space) {
+        		peer->original_outbound_write_space(sk);
+   		}
+	}
+	printk(KERN_INFO "Exiting function wg_tcp_write_space\n");
+}
+
+void wg_setup_tcp_socket_callbacks(struct wg_peer *peer, bool inbound)
+{
+	printk(KERN_INFO "Entering function wg_setup_tcp_socket_callbacks\n");
+	if (!peer || IS_ERR(peer)) {
+		printk(KERN_INFO "Exiting function wg_setup_tcp_socket_callbacks, no peer.\n");
+		return;
+	}
+	struct socket *target_socket = inbound ? peer->inbound_socket : peer->outbound_socket;
+
+	if (!target_socket || (inbound ? peer->tcp_inbound_callbacks_set : peer->tcp_outbound_callbacks_set)) {
+		printk(KERN_INFO "Exiting function wg_setup_tcp_socket_callbacks, nothing to do.\n");
+		return;
+	}
+
+	struct sock *sk = target_socket->sk;
+	struct wg_socket_data *socket_data;
+
+	if (inbound)
+		peer->tcp_inbound_callbacks_set = true;
+	else
+		peer->tcp_outbound_callbacks_set = true;
+
+	// Acquire lock to safely modify socket callbacks
+	write_lock_bh(&sk->sk_callback_lock);
+
+	// Check if sk_user_data is already allocated
+	socket_data = sk->sk_user_data;
+	if (socket_data) {
+		// If already allocated, update the peer
+		printk(KERN_INFO "wg_setup_tcp_socket_callbacks: sk_user_data already exists, updating peer.\n");
+		socket_data->device = peer->device;
+		socket_data->peer = peer;
+	} else {
+		// Allocate memory for wg_socket_data
+		socket_data = kzalloc(sizeof(*socket_data), GFP_KERNEL);
+		if (!socket_data) {
+			printk(KERN_ERR "Failed to allocate memory for wg_socket_data\n");
+			write_unlock_bh(&sk->sk_callback_lock);
+			return;
+		}
+
+		// Initialize wg_socket_data with device and peer
+		socket_data->device = peer->device;
+		socket_data->peer = peer;
+		socket_data->inbound = inbound;
+
+		// Set sk_user_data to the newly allocated socket_data
+		sk->sk_user_data = socket_data;
+	}
+
+	// Save the original callbacks based on the direction (inbound or outbound)
+	if (inbound) {
+		peer->original_inbound_state_change = sk->sk_state_change;
+		peer->original_inbound_write_space = sk->sk_write_space;
+		peer->original_inbound_data_ready = sk->sk_data_ready;
+	} else {
+		peer->original_outbound_state_change = sk->sk_state_change;
+		peer->original_outbound_write_space = sk->sk_write_space;
+		peer->original_outbound_data_ready = sk->sk_data_ready;
+	}
+
+	// Assign new callbacks and pass `peer` as user data for callback functions
+	sk->sk_state_change = wg_tcp_state_change;
+	sk->sk_write_space = wg_tcp_write_space;
+	sk->sk_data_ready = wg_tcp_data_ready;
+
+	write_unlock_bh(&sk->sk_callback_lock);
+	printk(KERN_INFO "Exiting function wg_setup_tcp_socket_callbacks\n");
+}
+
+void wg_reset_tcp_socket_callbacks(struct wg_peer *peer, bool inbound)
+{
+	printk(KERN_INFO "Entering function wg_reset_tcp_socket_callbacks\n");
+	struct sock *sk;
+	struct socket *target_socket = inbound ? peer->inbound_socket : peer->outbound_socket;
+
+	if (!peer || IS_ERR(peer)) {
+		printk(KERN_INFO "Exiting function wg_reset_tcp_socket_callbacks, no peer.\n");
+		return;
+	}
+	if (!target_socket || (inbound ? !peer->tcp_inbound_callbacks_set : !peer->tcp_outbound_callbacks_set)) {
+		printk(KERN_INFO "Exiting function wg_reset_tcp_socket_callbacks, nothing to do.\n");
+		return;
+	}
+
+	if (inbound)
+		peer->tcp_inbound_callbacks_set = false;
+	else
+		peer->tcp_outbound_callbacks_set = false;
+
+	sk = target_socket->sk;
+
+	// Lock the socket to safely update callback pointers
+	write_lock_bh(&sk->sk_callback_lock);
+
+	// Check if we previously saved original callbacks and restore them
+	if (inbound) {
+		if (peer->original_inbound_state_change) {
+			sk->sk_state_change = peer->original_inbound_state_change;
+			peer->original_inbound_state_change = NULL;
+		}
+		if (peer->original_inbound_write_space) {
+			sk->sk_write_space = peer->original_inbound_write_space;
+			peer->original_inbound_write_space = NULL;
+		}
+		if (peer->original_inbound_data_ready) {
+			sk->sk_data_ready = peer->original_inbound_data_ready;
+			peer->original_inbound_data_ready = NULL;
+		}
+	} else {
+		if (peer->original_outbound_state_change) {
+			sk->sk_state_change = peer->original_outbound_state_change;
+			peer->original_outbound_state_change = NULL;
+		}
+		if (peer->original_outbound_write_space) {
+			sk->sk_write_space = peer->original_outbound_write_space;
+			peer->original_outbound_write_space = NULL;
+		}
+		if (peer->original_outbound_data_ready) {
+			sk->sk_data_ready = peer->original_outbound_data_ready;
+			peer->original_outbound_data_ready = NULL;
+		}
+	}
+
+	// Clear the user data to avoid any dangling references
+	if (sk->sk_user_data)
+		kfree(sk->sk_user_data);
+	sk->sk_user_data = NULL;
+
+	write_unlock_bh(&sk->sk_callback_lock);
+	printk(KERN_INFO "Exiting function wg_reset_tcp_socket_callbacks\n");
+}
+
+void wg_tcp_retry_worker(struct work_struct *work)
+{
+	struct wg_peer *peer = container_of(work, struct wg_peer, tcp_retry_work.work);
+
+	printk(KERN_INFO "Entering function wg_tcp_retry_worker peer=%p\n", peer);
+
+	if (peer->tcp_established == false) {
+		if (peer->tcp_pending) {
+			// Check the state of the socket
+			struct sock *sk = peer->outbound_socket->sk;
+			// Connection still pending, perform cleanup
+			printk(KERN_INFO "TCP connection still pending, releasing socket\n");
+
+			// Reset connection state
+			peer->tcp_pending = false;
+			peer->tcp_established = false;
+			wg_reset_tcp_socket_callbacks(peer, false);
+			// Release the socket
+			if (peer->peer_socket == peer->outbound_socket)
+				peer->peer_socket = NULL;
+			if (peer->outbound_socket) {
+				if (peer->outbound_socket->sk->sk_user_data) {
+					kfree(peer->outbound_socket->sk->sk_user_data);
+					peer->peer_socket->sk->sk_user_data = NULL;
+				}
+				sock_release(peer->outbound_socket);
+				peer->outbound_socket = NULL;
+			}
+		}
+	}
+		
+	int ret = wg_tcp_connect(peer);
+	if (ret < 0) {
+		// Reschedule the work if the connection attempt fails
+		schedule_delayed_work(&peer->tcp_retry_work, msecs_to_jiffies(30*HZ));
+		peer->tcp_retry_scheduled = true;
+	} else {
+		peer->tcp_retry_scheduled = false;
+	}
+
+	printk(KERN_INFO "Exiting function wg_tcp_retry_worker\n");
+}
+
+void wg_add_tcp_socket_to_list(struct wg_device *wg, struct socket *receive_socket)
+{
+	printk(KERN_INFO "Entering function wg_add_tcp_socket_to_list\n");
+	struct wg_tcp_socket_list_entry *entry;
+	struct sockaddr_storage addr;
+
+	entry = kmalloc(sizeof(*entry), GFP_KERNEL);
+	if (!entry) {
+		pr_err("Failed to allocate wg_tcp_socket_list_entry\n");
+        	printk(KERN_INFO "Exiting function wg_add_tcp_socket_to_list\n");
+        	return;
+    	}
+
+    	entry->tcp_socket = receive_socket;
+    	entry->timestamp = ktime_get();
+
+    	// Initialize addr structure to zero
+    	memset(&addr, 0, sizeof(addr));
+
+    	// Get the source address from the socket
+    	if (receive_socket->ops->getname(receive_socket, (struct sockaddr *)&addr,  1) < 0) {
+        	pr_err("Failed to get peer address from socket\n");
+        	kfree(entry);
+        	printk(KERN_INFO "Exiting function wg_add_tcp_socket_to_list\n");
+        	return;
+    	}
+
+    	// Copy the obtained address to the entry's src_addr
+    	memcpy(&entry->src_addr, &addr, sizeof(addr));
+	
+	spin_lock_bh(&wg->tcp_connection_list_lock);
+    	// Add the entry to the tcp_connection_list
+    	list_add_tail_rcu(&entry->tcp_connection_ll, &wg->tcp_connection_list);
+	spin_unlock_bh(&wg->tcp_connection_list_lock);
+
+	printk(KERN_INFO "Exiting function wg_add_tcp_socket_to_list\n");
+}
+
+void wg_remove_from_tcp_connection_list(struct wg_device *wg, struct socket *pending_socket)
+{
+	printk(KERN_INFO "Entering function wg_remove_from_tcp_connection_list\n");
+	struct wg_tcp_socket_list_entry *entry;
+
+	if (!pending_socket)
+		goto out;
+
+
+	// Check if the connection list is empty
+	if (list_empty(&wg->tcp_connection_list)) {
+		printk(KERN_INFO "TCP connection list is empty, nothing to destroy\n");
+		return;
+	}
+	
+    	list_for_each_entry_rcu(entry, &wg->tcp_connection_list, tcp_connection_ll) {
+        	if (entry->tcp_socket == pending_socket) {
+			spin_lock_bh(&wg->tcp_connection_list_lock);
+            		list_del_rcu(&entry->tcp_connection_ll);
+			spin_unlock_bh(&wg->tcp_connection_list_lock);
+            		synchronize_rcu();
+            		if (entry->tcp_socket) {
+				kernel_sock_shutdown(entry->tcp_socket, SHUT_RDWR);
+				sock_release(entry->tcp_socket);
+           		}
+			// clean up old temp_peer
+			if (!IS_ERR(entry->temp_peer) && entry->temp_peer) {
+				// flush any partial data free the held buffer
+				if (entry->temp_peer->partial_skb) {
+        	        		kfree_skb(entry->temp_peer->partial_skb);
+				}
+				// Clean up packet queues
+    				skb_queue_purge(&entry->temp_peer->tcp_packet_queue);
+				
+				// Check if the TCP read work is scheduled before canceling it
+    				if (entry->temp_peer->tcp_read_worker_scheduled) {
+        				cancel_work_sync(&entry->temp_peer->tcp_read_work);
+   			     		entry->temp_peer->tcp_read_worker_scheduled = false;  // Reset the flag after canceling
+    				}
+
+    				// Destroy the TCP read workqueue if it exists
+    				if (entry->temp_peer->tcp_read_wq) {
+       			 		destroy_workqueue(entry->temp_peer->tcp_read_wq);
+        				entry->temp_peer->tcp_read_wq = NULL; // Avoid dangling pointers
+		    		}
+
+
+				kfree(entry->temp_peer);
+			}
+			// Free the old entry
+            		kfree(entry);
+            		break;
+        	}
+    	}
+out:
+    	printk(KERN_INFO "Exiting function wg_remove_from_tcp_connection_list\n");
+}
+
+void wg_tcp_outbound_remove_worker(struct work_struct *work)
+{
+	struct wg_peer *peer = container_of(work, struct wg_peer, tcp_outbound_remove_work.work);
+
+	printk(KERN_INFO "Entering function wg_tcp_outbound_remove _worker\n");
+
+	wg_reset_tcp_socket_callbacks(peer, false);
+	wg_clean_peer_socket(peer, true, false, false); // clean and release
+	
+    	printk(KERN_INFO "Exiting function wg_tcp_outbound_remove_worker\n");
+}
+
+void wg_tcp_inbound_remove_worker(struct work_struct *work)
+{
+	struct wg_peer *peer = container_of(work, struct wg_peer, tcp_inbound_remove_work.work);
+
+	printk(KERN_INFO "Entering function wg_tcp_inbound_remove _worker\n");
+
+	if (peer->temp_peer){
+		wg_remove_from_tcp_connection_list(peer->device, peer->peer_socket);
+	} else {
+		wg_reset_tcp_socket_callbacks(peer, true);
+		wg_clean_peer_socket(peer, true, false, true); // clean and release
+	}
+    	printk(KERN_INFO "Exiting function wg_inbound_remove_worker\n");
+}
+
+void wg_destruct_tcp_connection_list(struct wg_device *wg)
+{
+	printk(KERN_INFO "Entering function wg_destruct_tcp_connection_list\n");
+	struct wg_tcp_socket_list_entry *entry, *tmp;
+
+	// Iterate over the entire list and free each entry
+	list_for_each_entry_safe(entry, tmp, &wg->tcp_connection_list, tcp_connection_ll) {
+		spin_lock_bh(&wg->tcp_connection_list_lock);
+		list_del(&entry->tcp_connection_ll); // Removes the entry from the list
+        	spin_unlock_bh(&wg->tcp_connection_list_lock);
+		// Release the socket
+		if (entry->tcp_socket) {
+			kernel_sock_shutdown(entry->tcp_socket, SHUT_RDWR);
+			sock_release(entry->tcp_socket); // Release the socket
+		}
+		// Check if the TCP read work is scheduled before canceling it
+    		if (entry->temp_peer->tcp_read_worker_scheduled) {
+        		cancel_work_sync(&entry->temp_peer->tcp_read_work);
+        		entry->temp_peer->tcp_read_worker_scheduled = false;  // Reset the flag after canceling
+    		}
+
+    		// Destroy the TCP read workqueue if it exists
+    		if (entry->temp_peer->tcp_read_wq) {
+        		destroy_workqueue(entry->temp_peer->tcp_read_wq);
+        		entry->temp_peer->tcp_read_wq = NULL; // Avoid dangling pointers
+    		}
+
+		// clean up old temp_peer
+		if (!IS_ERR(entry->temp_peer) && entry->temp_peer) 
+			kfree(entry->temp_peer);
+		kfree(entry); // Free the memory allocated for the list entry
+	}
+
+	printk(KERN_INFO "Exiting function wg_destruct_tcp_connection_list\n");
+}
+
+void wg_tcp_cleanup_worker(struct work_struct *work)
+{
+	printk(KERN_INFO "Entering function wg_tcp_cleanup_worker\n");
+	struct wg_device *wg = container_of(work, struct wg_device, tcp_cleanup_work.work);
+	struct wg_tcp_socket_list_entry *entry, *tmp;
+	struct wg_peer *peer = NULL;
+	
+	ktime_t now = ktime_get();
+
+	// Cleanup logic: Remove old entries from the TCP connection list
+
+	list_for_each_entry_safe(entry, tmp, &wg->tcp_connection_list, tcp_connection_ll) {
+		if (ktime_ms_delta(now, entry->timestamp) > 5000) { // Check if older than 5 seconds
+			wg_remove_from_tcp_connection_list(wg, entry->tcp_socket);
+		}
+	}
+
+#ifdef WRONG
+	// Walk through the wg_dev peer list and call wg_tcp_write_space for each socket
+	rcu_read_lock();
+	list_for_each_entry_rcu(peer, &wg->peer_list, peer_list) {
+		// Check and call wg_tcp_write_space for socket if not null
+		if (peer->peer_socket) {
+			rcu_read_unlock();
+			wg_tcp_write_space(peer->peer_socket->sk);
+			rcu_read_lock();
+		}
+	}
+	rcu_read_unlock();
+#endif
+	
+	// Reschedule the worker
+	peer->device->tcp_cleanup_scheduled = true;
+	schedule_delayed_work(&wg->tcp_cleanup_work, msecs_to_jiffies(5000));
+	printk(KERN_INFO "Exiting function wg_tcp_cleanup_worker\n");
+}
+
+struct wg_peer *wg_temp_peer_create(struct wg_device *wg)
+{
+	struct wg_peer *peer;
+	int ret = -ENOMEM;
+	
+	printk(KERN_INFO "wg_peer_create: entry with wg=%p\n", wg);
+	
+	peer = kmalloc(sizeof(struct wg_peer), GFP_KERNEL);
+	if (unlikely(!peer)) {
+		printk(KERN_INFO "wg_temp_peer_create: exit with ERR_PTR(ret)\n");
+		return ERR_PTR(ret);
+	}
+	if (unlikely(dst_cache_init(&peer->endpoint_cache, GFP_KERNEL))) {
+		goto err;
+	}
+
+	
+	struct wg_socket_data *socket_data = kmalloc(sizeof(struct wg_socket_data), GFP_KERNEL);
+	if (unlikely(!socket_data)) {
+		pr_err("Failed to allocate memory for wg_socket_data\n");
+		goto err;
+	}
+
+	// Initialize the socket_data structure
+	socket_data->device = wg;
+	socket_data->peer = peer;
+	
+	peer->device = wg;
+	peer->internal_id = (u64)NULL;
+	peer->serial_work_cpu = (int)nr_cpumask_bits;
+	wg_timers_init(peer);
+	wg_prev_queue_init(&peer->tx_queue);
+	wg_prev_queue_init(&peer->rx_queue);
+	rwlock_init(&peer->endpoint_lock);
+	kref_init(&peer->refcount);
+	skb_queue_head_init(&peer->staged_packet_queue);
+	wg_noise_reset_last_sent_handshake(&peer->last_sent_handshake);
+	set_bit(NAPI_STATE_NO_BUSY_POLL, &peer->napi.state);
+	netif_napi_add(wg->dev, &peer->napi, wg_packet_rx_poll);
+	napi_enable(&peer->napi);
+	INIT_LIST_HEAD(&peer->allowedips_list);
+
+	// initialize TCP fields
+	peer->peer_socket = NULL;  // Initialize the peer socket to NULL
+
+	// Initialize the original socket callbacks to NULL
+	peer->original_outbound_state_change = NULL;
+	peer->original_outbound_write_space = NULL;
+	peer->original_outbound_data_ready = NULL;
+	peer->original_outbound_error_report = NULL;
+	peer->original_outbound_destruct = NULL;
+
+	peer->original_inbound_state_change = NULL;
+	peer->original_inbound_write_space = NULL;
+	peer->original_inbound_data_ready = NULL;
+	peer->original_inbound_error_report = NULL;
+	peer->original_inbound_destruct = NULL;
+
+	peer->partial_skb = NULL;  // Initialize the partial skb pointer to NULL
+	peer->expected_len = 0;    // Initialize expected length to 0
+	peer->received_len = 0;    // Initialize received length to 0
+
+	// Initialize the skb queue for queuing TCP packets
+	skb_queue_head_init(&peer->tcp_packet_queue);
+
+	// Initialize the delayed work for TCP connection retry
+	INIT_DELAYED_WORK(&peer->tcp_retry_work, wg_tcp_retry_worker);
+
+	// Initialize the delayed work for TCP socket removal
+	INIT_DELAYED_WORK(&peer->tcp_inbound_remove_work, wg_tcp_inbound_remove_worker);
+	INIT_DELAYED_WORK(&peer->tcp_outbound_remove_work, wg_tcp_outbound_remove_worker);
+	
+	// Initialize TCP connection status flags
+	peer->tcp_established = false;
+	peer->tcp_pending = false;
+	peer->tcp_inbound_callbacks_set = false;
+	peer->tcp_outbound_callbacks_set = false;
+	peer->clean_inbound = false;
+	peer->clean_outbound = false;
+	peer->inbound_connected = false;
+	peer->outbound_connected = false;
+	peer->tcp_retry_scheduled = false;
+	peer->tcp_inbound_remove_scheduled = false;
+	peer->tcp_outbound_remove_scheduled = false;
+
+	// Initialize the spinlock for protecting TCP-related state
+	spin_lock_init(&peer->tcp_lock);
+
+	// Initialize the skb queue for the TX send queue
+	skb_queue_head_init(&peer->send_queue);
+
+	// Initialize the spinlock for the TX send queue
+	spin_lock_init(&peer->send_queue_lock);
+
+	// Initialize the list head for pending connection list
+	INIT_LIST_HEAD(&peer->pending_connection_list);
+
+	// Initialize the work structure, associating it with the worker functions
+	INIT_WORK(&peer->tcp_read_work, wg_tcp_read_worker);
+	// Create a workqueue for processing TCP read data
+	peer->tcp_read_wq = alloc_workqueue("tcp_read_wq", WQ_UNBOUND | WQ_MEM_RECLAIM, 0);
+	if (!peer->tcp_read_wq) {
+        	pr_err("Failed to allocate read workqueue\n");
+		goto err;
+	}
+
+	INIT_WORK(&peer->tcp_write_work, wg_tcp_write_worker);
+
+	// Note this is a temp peer
+	peer->temp_peer = true;
+
+	pr_debug("%s: Temp Peer %llu created\n", wg->dev->name, peer->internal_id);
+	printk(KERN_INFO "wg_temp_peer_create: exit with peer=%p\n", peer);
+	return peer;
+
+err:
+	kfree(peer);
+	printk(KERN_INFO "wg_temp_peer_create: exit with ERR_PTR(ret) on err\n");
+	return ERR_PTR(ret);
 }
diff --git a/wireguard-linux/drivers/net/wireguard/socket.h b/wireguard-linux/drivers/net/wireguard/socket.h
index bab5848efbcd..e3b236abaa1d 100644
--- a/wireguard-linux/drivers/net/wireguard/socket.h
+++ b/wireguard-linux/drivers/net/wireguard/socket.h
@@ -6,6 +6,7 @@
 #ifndef _WG_SOCKET_H
 #define _WG_SOCKET_H
 
+#include <linux/net.h>
 #include <linux/netdevice.h>
 #include <linux/udp.h>
 #include <linux/if_vlan.h>
@@ -29,6 +30,17 @@ void wg_socket_set_peer_endpoint(struct wg_peer *peer,
 void wg_socket_set_peer_endpoint_from_skb(struct wg_peer *peer,
 					  const struct sk_buff *skb);
 void wg_socket_clear_peer_endpoint_src(struct wg_peer *peer);
+void wg_destruct_tcp_connection_list(struct wg_device *wg);
+
+struct wg_tcp_encap_header {
+	__be32 length;
+	__u8 type;
+	__u8 flags;
+	__be16 checksum;
+};
+
+#define WG_TCP_ENCAP_HDR_LEN sizeof(struct wg_tcp_encap_header)
+#define WG_MAX_PACKET_SIZE 65535 + WG_TCP_ENCAP_HDR_LEN
 
 #if defined(CONFIG_DYNAMIC_DEBUG) || defined(DEBUG)
 #define net_dbg_skb_ratelimited(fmt, dev, skb, ...) do {                       \
@@ -41,4 +53,45 @@ void wg_socket_clear_peer_endpoint_src(struct wg_peer *peer);
 #define net_dbg_skb_ratelimited(fmt, skb, ...)
 #endif
 
+/* Forward declarations of functions */
+int wg_socket_send_skb_to_peer(struct wg_peer *peer, struct sk_buff *skb, u8 ds);
+int wg_socket_send_buffer_to_peer(struct wg_peer *peer, void *buffer, size_t len, u8 ds);
+int wg_socket_send_buffer_as_reply_to_skb(struct wg_device *wg, struct sk_buff *in_skb, void *buffer, size_t len);
+int wg_socket_endpoint_from_skb(struct endpoint *endpoint, const struct sk_buff *skb);
+void wg_socket_set_peer_endpoint(struct wg_peer *peer, const struct endpoint *endpoint);
+void wg_socket_set_peer_endpoint_from_skb(struct wg_peer *peer, const struct sk_buff *skb);
+void wg_socket_clear_peer_endpoint_src(struct wg_peer *peer);
+void wg_socket_reinit(struct wg_device *wg, struct sock *new4, struct sock *new6);
+void wg_tcp_state_change(struct sock *sk);
+void wg_extract_endpoint_from_sock(struct sock *sk, struct endpoint *endpoint);
+bool wg_check_potential_header_validity(struct wg_tcp_encap_header *hdr, size_t remaining_len);
+
+int wg_tcp_queuepkt(struct wg_peer *, const void *, size_t);
+void wg_tcp_write_space(struct sock *sk);
+void wg_tcp_data_ready(struct sock *sk);
+
+void wg_add_tcp_socket_to_list(struct wg_device *wg, struct socket *sock);
+void wg_remove_from_tcp_connection_list(struct wg_device *wg, struct socket *sock);
+void wg_destruct_tcp_connection_list(struct wg_device *wg);
+
+int wg_tcp_listener_socket_init(struct wg_device *wg, u16 port);
+void wg_tcp_listener_socket_release(struct wg_device *wg);
+
+void wg_tcp_connection_retry_timer(struct timer_list *);
+int wg_tcp_connect(struct wg_peer *);
+
+int wg_tcp_listener_worker(struct wg_device *wg, struct socket *tcp_socket);
+struct socket *wg_setup_tcp_listen4(struct wg_device *wg, struct net *net, u16 port);
+struct socket *wg_setup_tcp_listen6(struct wg_device *wg, struct net *net, u16 port);
+int wg_tcp_listener4_thread(void *data);
+int wg_tcp_listener6_thread(void *data);
+
+void wg_clean_peer_socket(struct wg_peer *peer, bool release, bool destroy, bool inbound);
+void wg_timers_init(struct wg_peer *peer);
+void wg_tcp_write_worker(struct work_struct *work);
+void wg_tcp_read_worker(struct work_struct *work);
+void wg_tcp_cleanup_worker(struct work_struct *work);
+
+void lookup_default_interface(void);
+
 #endif /* _WG_SOCKET_H */
diff --git a/wireguard-linux/drivers/net/wireguard/timers.c b/wireguard-linux/drivers/net/wireguard/timers.c
index 968bdb4df0b3..c6622590b0c6 100644
--- a/wireguard-linux/drivers/net/wireguard/timers.c
+++ b/wireguard-linux/drivers/net/wireguard/timers.c
@@ -31,15 +31,18 @@ static inline void mod_peer_timer(struct wg_peer *peer,
 				  struct timer_list *timer,
 				  unsigned long expires)
 {
+	printk(KERN_INFO "Entering mod_peer_timer: peer=%p, timer=%p, expires=%lu\n", peer, timer, expires);
 	rcu_read_lock_bh();
 	if (likely(netif_running(peer->device->dev) &&
 		   !READ_ONCE(peer->is_dead)))
 		mod_timer(timer, expires);
 	rcu_read_unlock_bh();
+	printk(KERN_INFO "Exiting mod_peer_timer: peer=%p, timer=%p, expires=%lu\n", peer, timer, expires);
 }
 
 static void wg_expired_retransmit_handshake(struct timer_list *timer)
 {
+	printk(KERN_INFO "Entering wg_expired_retransmit_handshake: timer=%p\n", timer);
 	struct wg_peer *peer = from_timer(peer, timer,
 					  timer_retransmit_handshake);
 
@@ -74,10 +77,12 @@ static void wg_expired_retransmit_handshake(struct timer_list *timer)
 
 		wg_packet_send_queued_handshake_initiation(peer, true);
 	}
+	printk(KERN_INFO "Exiting wg_expired_retransmit_handshake: timer=%p\n", timer);
 }
 
 static void wg_expired_send_keepalive(struct timer_list *timer)
 {
+	printk(KERN_INFO "Entering wg_expired_send_keepalive: timer=%p\n", timer);
 	struct wg_peer *peer = from_timer(peer, timer, timer_send_keepalive);
 
 	wg_packet_send_keepalive(peer);
@@ -86,10 +91,12 @@ static void wg_expired_send_keepalive(struct timer_list *timer)
 		mod_peer_timer(peer, &peer->timer_send_keepalive,
 			       jiffies + KEEPALIVE_TIMEOUT * HZ);
 	}
+	printk(KERN_INFO "Exiting wg_expired_send_keepalive: timer=%p\n", timer);
 }
 
 static void wg_expired_new_handshake(struct timer_list *timer)
 {
+	printk(KERN_INFO "Entering wg_expired_new_handshake: timer=%p\n", timer);
 	struct wg_peer *peer = from_timer(peer, timer, timer_new_handshake);
 
 	pr_debug("%s: Retrying handshake with peer %llu (%pISpfsc) because we stopped hearing back after %d seconds\n",
@@ -100,10 +107,12 @@ static void wg_expired_new_handshake(struct timer_list *timer)
 	 */
 	wg_socket_clear_peer_endpoint_src(peer);
 	wg_packet_send_queued_handshake_initiation(peer, false);
+	printk(KERN_INFO "Exiting wg_expired_new_handshake: timer=%p\n", timer);
 }
 
 static void wg_expired_zero_key_material(struct timer_list *timer)
 {
+	printk(KERN_INFO "Entering wg_expired_zero_key_material: timer=%p\n", timer);
 	struct wg_peer *peer = from_timer(peer, timer, timer_zero_key_material);
 
 	rcu_read_lock_bh();
@@ -117,10 +126,12 @@ static void wg_expired_zero_key_material(struct timer_list *timer)
 			wg_peer_put(peer);
 	}
 	rcu_read_unlock_bh();
+	printk(KERN_INFO "Exiting wg_expired_zero_key_material: timer=%p\n", timer);
 }
 
 static void wg_queued_expired_zero_key_material(struct work_struct *work)
 {
+	printk(KERN_INFO "Entering wg_queued_expired_zero_key_material: work=%p\n", work);
 	struct wg_peer *peer = container_of(work, struct wg_peer,
 					    clear_peer_work);
 
@@ -130,29 +141,35 @@ static void wg_queued_expired_zero_key_material(struct work_struct *work)
 	wg_noise_handshake_clear(&peer->handshake);
 	wg_noise_keypairs_clear(&peer->keypairs);
 	wg_peer_put(peer);
+	printk(KERN_INFO "Exiting wg_queued_expired_zero_key_material: work=%p\n", work);
 }
 
 static void wg_expired_send_persistent_keepalive(struct timer_list *timer)
 {
+	printk(KERN_INFO "Entering wg_expired_send_persistent_keepalive: timer=%p\n", timer);
 	struct wg_peer *peer = from_timer(peer, timer,
 					  timer_persistent_keepalive);
 
 	if (likely(peer->persistent_keepalive_interval))
 		wg_packet_send_keepalive(peer);
+	printk(KERN_INFO "Exiting wg_expired_send_persistent_keepalive: timer=%p\n", timer);
 }
 
 /* Should be called after an authenticated data packet is sent. */
 void wg_timers_data_sent(struct wg_peer *peer)
 {
+	printk(KERN_INFO "Entering wg_timers_data_sent: peer=%p\n", peer);
 	if (!timer_pending(&peer->timer_new_handshake))
 		mod_peer_timer(peer, &peer->timer_new_handshake,
 			jiffies + (KEEPALIVE_TIMEOUT + REKEY_TIMEOUT) * HZ +
 			get_random_u32_below(REKEY_TIMEOUT_JITTER_MAX_JIFFIES));
+	printk(KERN_INFO "Exiting wg_timers_data_sent: peer=%p\n", peer);
 }
 
 /* Should be called after an authenticated data packet is received. */
 void wg_timers_data_received(struct wg_peer *peer)
 {
+	printk(KERN_INFO "Entering wg_timers_data_received: peer=%p\n", peer);
 	if (likely(netif_running(peer->device->dev))) {
 		if (!timer_pending(&peer->timer_send_keepalive))
 			mod_peer_timer(peer, &peer->timer_send_keepalive,
@@ -160,6 +177,7 @@ void wg_timers_data_received(struct wg_peer *peer)
 		else
 			peer->timer_need_another_keepalive = true;
 	}
+	printk(KERN_INFO "Exiting wg_timers_data_received: peer=%p\n", peer);
 }
 
 /* Should be called after any type of authenticated packet is sent, whether
@@ -167,7 +185,9 @@ void wg_timers_data_received(struct wg_peer *peer)
  */
 void wg_timers_any_authenticated_packet_sent(struct wg_peer *peer)
 {
+	printk(KERN_INFO "Entering wg_timers_any_authenticated_packet_sent: peer=%p\n", peer);
 	del_timer(&peer->timer_send_keepalive);
+	printk(KERN_INFO "Exiting wg_timers_any_authenticated_packet_sent: peer=%p\n", peer);
 }
 
 /* Should be called after any type of authenticated packet is received, whether
@@ -175,15 +195,19 @@ void wg_timers_any_authenticated_packet_sent(struct wg_peer *peer)
  */
 void wg_timers_any_authenticated_packet_received(struct wg_peer *peer)
 {
+	printk(KERN_INFO "Entering wg_timers_any_authenticated_packet_received: peer=%p\n", peer);
 	del_timer(&peer->timer_new_handshake);
+	printk(KERN_INFO "Exiting wg_timers_any_authenticated_packet_received: peer=%p\n", peer);
 }
 
 /* Should be called after a handshake initiation message is sent. */
 void wg_timers_handshake_initiated(struct wg_peer *peer)
 {
+	printk(KERN_INFO "Entering wg_timers_handshake_initiated: peer=%p\n", peer);
 	mod_peer_timer(peer, &peer->timer_retransmit_handshake,
 		       jiffies + REKEY_TIMEOUT * HZ +
 		       get_random_u32_below(REKEY_TIMEOUT_JITTER_MAX_JIFFIES));
+	printk(KERN_INFO "Exiting wg_timers_handshake_initiated: peer=%p\n", peer);
 }
 
 /* Should be called after a handshake response message is received and processed
@@ -191,10 +215,12 @@ void wg_timers_handshake_initiated(struct wg_peer *peer)
  */
 void wg_timers_handshake_complete(struct wg_peer *peer)
 {
+	printk(KERN_INFO "Entering wg_timers_handshake_complete: peer=%p\n", peer);
 	del_timer(&peer->timer_retransmit_handshake);
 	peer->timer_handshake_attempts = 0;
 	peer->sent_lastminute_handshake = false;
 	ktime_get_real_ts64(&peer->walltime_last_handshake);
+	printk(KERN_INFO "Exiting wg_timers_handshake_complete: peer=%p\n", peer);
 }
 
 /* Should be called after an ephemeral key is created, which is before sending a
@@ -202,22 +228,27 @@ void wg_timers_handshake_complete(struct wg_peer *peer)
  */
 void wg_timers_session_derived(struct wg_peer *peer)
 {
+	printk(KERN_INFO "Entering wg_timers_session_derived: peer=%p\n", peer);
 	mod_peer_timer(peer, &peer->timer_zero_key_material,
 		       jiffies + REJECT_AFTER_TIME * 3 * HZ);
+	printk(KERN_INFO "Exiting wg_timers_session_derived: peer=%p\n", peer);
 }
 
 /* Should be called before a packet with authentication, whether
- * keepalive, data, or handshakem is sent, or after one is received.
+ * keepalive, data, or handshake is sent, or after one is received.
  */
 void wg_timers_any_authenticated_packet_traversal(struct wg_peer *peer)
 {
+	printk(KERN_INFO "Entering wg_timers_any_authenticated_packet_traversal: peer=%p\n", peer);
 	if (peer->persistent_keepalive_interval)
 		mod_peer_timer(peer, &peer->timer_persistent_keepalive,
 			jiffies + peer->persistent_keepalive_interval * HZ);
+	printk(KERN_INFO "Exiting wg_timers_any_authenticated_packet_traversal: peer=%p\n", peer);
 }
 
 void wg_timers_init(struct wg_peer *peer)
 {
+	printk(KERN_INFO "Entering wg_timers_init: peer=%p\n", peer);
 	timer_setup(&peer->timer_retransmit_handshake,
 		    wg_expired_retransmit_handshake, 0);
 	timer_setup(&peer->timer_send_keepalive, wg_expired_send_keepalive, 0);
@@ -230,14 +261,17 @@ void wg_timers_init(struct wg_peer *peer)
 	peer->timer_handshake_attempts = 0;
 	peer->sent_lastminute_handshake = false;
 	peer->timer_need_another_keepalive = false;
+	printk(KERN_INFO "Exiting wg_timers_init: peer=%p\n", peer);
 }
 
 void wg_timers_stop(struct wg_peer *peer)
 {
+	printk(KERN_INFO "Entering wg_timers_stop: peer=%p\n", peer);
 	timer_delete_sync(&peer->timer_retransmit_handshake);
 	timer_delete_sync(&peer->timer_send_keepalive);
 	timer_delete_sync(&peer->timer_new_handshake);
 	timer_delete_sync(&peer->timer_zero_key_material);
 	timer_delete_sync(&peer->timer_persistent_keepalive);
 	flush_work(&peer->clear_peer_work);
+	printk(KERN_INFO "Exiting wg_timers_stop: peer=%p\n", peer);
 }
diff --git a/wireguard-linux/include/uapi/linux/wireguard.h b/wireguard-linux/include/uapi/linux/wireguard.h
index ae88be14c947..5cde6ad9303f 100644
--- a/wireguard-linux/include/uapi/linux/wireguard.h
+++ b/wireguard-linux/include/uapi/linux/wireguard.h
@@ -136,6 +136,9 @@
 
 #define WG_KEY_LEN 32
 
+#define WG_TRANSPORT_UDP 0
+#define WG_TRANSPORT_TCP 1
+
 enum wg_cmd {
 	WG_CMD_GET_DEVICE,
 	WG_CMD_SET_DEVICE,
@@ -157,6 +160,7 @@ enum wgdevice_attribute {
 	WGDEVICE_A_LISTEN_PORT,
 	WGDEVICE_A_FWMARK,
 	WGDEVICE_A_PEERS,
+	WGDEVICE_A_TRANSPORT,
 	__WGDEVICE_A_LAST
 };
 #define WGDEVICE_A_MAX (__WGDEVICE_A_LAST - 1)
diff --git a/wireguard-tools/src/Makefile b/wireguard-tools/src/Makefile
index 0533910bd13d..2ec09d54c63b 100644
--- a/wireguard-tools/src/Makefile
+++ b/wireguard-tools/src/Makefile
@@ -46,7 +46,7 @@ CFLAGS += -Wall -Wextra
 CFLAGS += -MMD -MP
 CFLAGS += -DRUNSTATEDIR="\"$(RUNSTATEDIR)\""
 ifeq ($(DEBUG),yes)
-CFLAGS += -g
+CFLAGS += -g -DDEBUG=$(DEBUG)
 endif
 WIREGUARD_TOOLS_VERSION = $(patsubst v%,%,$(shell GIT_DIR="$(PWD)/../.git" git describe --dirty 2>/dev/null))
 ifneq ($(WIREGUARD_TOOLS_VERSION),)
diff --git a/wireguard-tools/src/config.c b/wireguard-tools/src/config.c
index 81ccb479c367..e5540fc8349a 100644
--- a/wireguard-tools/src/config.c
+++ b/wireguard-tools/src/config.c
@@ -22,22 +22,39 @@
 
 #define COMMENT_CHAR '#'
 
+#ifdef DEBUG
+#define DEBUG_PRINT(fmt, ...) fprintf(stderr, fmt, ##__VA_ARGS__)
+#else
+#define DEBUG_PRINT(fmt, ...) (void)0
+#endif
+
 static const char *get_value(const char *line, const char *key)
 {
+	DEBUG_PRINT("Entering get_value: line: %s, key: %s\n", line, key);
 	size_t linelen = strlen(line);
 	size_t keylen = strlen(key);
 
-	if (keylen >= linelen)
+	if (keylen >= linelen) {
+		DEBUG_PRINT("Error in get_value: key length >= line length\n");
+		DEBUG_PRINT("Exiting get_value\n");
 		return NULL;
+	}
 
-	if (strncasecmp(line, key, keylen))
+	if (strncasecmp(line, key, keylen)) {
+		DEBUG_PRINT("Error in get_value: key does not match line start\n");
+		DEBUG_PRINT("Exiting get_value\n");
 		return NULL;
+	}
 
-	return line + keylen;
+	const char *value = line + keylen;
+	DEBUG_PRINT("get_value: value = %s\n", value);
+	DEBUG_PRINT("Exiting get_value\n");
+	return value;
 }
 
 static inline bool parse_port(uint16_t *port, uint32_t *flags, const char *value)
 {
+	DEBUG_PRINT("Entering parse_port: port: %p, flags: %p, value: %s\n", port, flags, value);
 	int ret;
 	struct addrinfo *resolved;
 	struct addrinfo hints = {
@@ -49,12 +66,16 @@ static inline bool parse_port(uint16_t *port, uint32_t *flags, const char *value
 
 	if (!strlen(value)) {
 		fprintf(stderr, "Unable to parse empty port\n");
+		DEBUG_PRINT("Error in parse_port: empty port value\n");
+		DEBUG_PRINT("Exiting parse_port\n");
 		return false;
 	}
 
 	ret = getaddrinfo(NULL, value, &hints, &resolved);
 	if (ret) {
 		fprintf(stderr, "%s: `%s'\n", ret == EAI_SYSTEM ? strerror(errno) : gai_strerror(ret), value);
+		DEBUG_PRINT("Error in parse_port: %s: `%s'\n", ret == EAI_SYSTEM ? strerror(errno) : gai_strerror(ret), value);
+		DEBUG_PRINT("Exiting parse_port\n");
 		return false;
 	}
 
@@ -62,20 +83,28 @@ static inline bool parse_port(uint16_t *port, uint32_t *flags, const char *value
 	if (resolved->ai_family == AF_INET && resolved->ai_addrlen == sizeof(struct sockaddr_in)) {
 		*port = ntohs(((struct sockaddr_in *)resolved->ai_addr)->sin_port);
 		ret = 0;
+		DEBUG_PRINT("Parsed IPv4 port: %u\n", *port);
 	} else if (resolved->ai_family == AF_INET6 && resolved->ai_addrlen == sizeof(struct sockaddr_in6)) {
 		*port = ntohs(((struct sockaddr_in6 *)resolved->ai_addr)->sin6_port);
 		ret = 0;
-	} else
+		DEBUG_PRINT("Parsed IPv6 port: %u\n", *port);
+	} else {
 		fprintf(stderr, "Neither IPv4 nor IPv6 address found: `%s'\n", value);
+		DEBUG_PRINT("Error in parse_port: Neither IPv4 nor IPv6 address found: `%s'\n", value);
+	}
 
 	freeaddrinfo(resolved);
-	if (!ret)
+	if (!ret) {
 		*flags |= WGDEVICE_HAS_LISTEN_PORT;
+		DEBUG_PRINT("Flag WGDEVICE_HAS_LISTEN_PORT set\n");
+	}
+	DEBUG_PRINT("Exiting parse_port with status: %s\n", ret == 0 ? "success" : "failure");
 	return ret == 0;
 }
 
 static inline bool parse_fwmark(uint32_t *fwmark, uint32_t *flags, const char *value)
 {
+	DEBUG_PRINT("Entering parse_fwmark: fwmark: %p, flags: %p, value: %s\n", fwmark, flags, value);
 	unsigned long ret;
 	char *end;
 	int base = 10;
@@ -83,39 +112,55 @@ static inline bool parse_fwmark(uint32_t *fwmark, uint32_t *flags, const char *v
 	if (!strcasecmp(value, "off")) {
 		*fwmark = 0;
 		*flags |= WGDEVICE_HAS_FWMARK;
+		DEBUG_PRINT("Parsed fwmark as off. Flag WGDEVICE_HAS_FWMARK set\n");
+		DEBUG_PRINT("Exiting parse_fwmark with status: success\n");
 		return true;
 	}
 
-	if (!char_is_digit(value[0]))
+	if (!char_is_digit(value[0])) {
+		DEBUG_PRINT("Error in parse_fwmark: Value is not a digit\n");
 		goto err;
+	}
 
-	if (strlen(value) > 2 && value[0] == '0' && value[1] == 'x')
+	if (strlen(value) > 2 && value[0] == '0' && value[1] == 'x') {
 		base = 16;
+	}
 
 	ret = strtoul(value, &end, base);
-	if (*end || ret > UINT32_MAX)
+	if (*end || ret > UINT32_MAX) {
+		DEBUG_PRINT("Error in parse_fwmark: Invalid fwmark value or out of range\n");
 		goto err;
+	}
 
 	*fwmark = ret;
 	*flags |= WGDEVICE_HAS_FWMARK;
+	DEBUG_PRINT("Parsed fwmark: %u. Flag WGDEVICE_HAS_FWMARK set\n", *fwmark);
+	DEBUG_PRINT("Exiting parse_fwmark with status: success\n");
 	return true;
 err:
 	fprintf(stderr, "Fwmark is neither 0/off nor 0-0xffffffff: `%s'\n", value);
+	DEBUG_PRINT("Error in parse_fwmark: Fwmark is neither 0/off nor 0-0xffffffff: `%s'\n", value);
+	DEBUG_PRINT("Exiting parse_fwmark with status: failure\n");
 	return false;
 }
 
 static inline bool parse_key(uint8_t key[static WG_KEY_LEN], const char *value)
 {
+	DEBUG_PRINT("Entering parse_key: key: %p, value: %s\n", key, value);
 	if (!key_from_base64(key, value)) {
-		fprintf(stderr, "Key is not the correct length or format: `%s'\n", value);
+		DEBUG_PRINT("Error in parse_key: Key is not the correct length or format: `%s'\n", value);
 		memset(key, 0, WG_KEY_LEN);
+		DEBUG_PRINT("Exiting parse_key with status: failure\n");
 		return false;
 	}
+	DEBUG_PRINT("Parsed key successfully\n");
+	DEBUG_PRINT("Exiting parse_key with status: success\n");
 	return true;
 }
 
 static bool parse_keyfile(uint8_t key[static WG_KEY_LEN], const char *path)
 {
+	DEBUG_PRINT("Entering parse_keyfile: key: %p, path: %s\n", key, path);
 	FILE *f;
 	int c;
 	char dst[WG_KEY_LEN_BASE64];
@@ -124,18 +169,20 @@ static bool parse_keyfile(uint8_t key[static WG_KEY_LEN], const char *path)
 	f = fopen(path, "r");
 	if (!f) {
 		perror("fopen");
+		DEBUG_PRINT("Exiting parse_keyfile with status: failure\n");
 		return false;
 	}
 
 	if (fread(dst, WG_KEY_LEN_BASE64 - 1, 1, f) != 1) {
-		/* If we're at the end and we didn't read anything, we're /dev/null or an empty file. */
 		if (!ferror(f) && feof(f) && !ftell(f)) {
 			memset(key, 0, WG_KEY_LEN);
 			ret = true;
+			DEBUG_PRINT("Empty key file\n");
 			goto out;
 		}
 
 		fprintf(stderr, "Invalid length key in key file\n");
+		DEBUG_PRINT("Error in parse_keyfile: Invalid length key in key file\n");
 		goto out;
 	}
 	dst[WG_KEY_LEN_BASE64 - 1] = '\0';
@@ -143,6 +190,7 @@ static bool parse_keyfile(uint8_t key[static WG_KEY_LEN], const char *path)
 	while ((c = getc(f)) != EOF) {
 		if (!char_is_space(c)) {
 			fprintf(stderr, "Found trailing character in key file: `%c'\n", c);
+			DEBUG_PRINT("Error in parse_keyfile: Found trailing character in key file: `%c'\n", c);
 			goto out;
 		}
 	}
@@ -152,48 +200,68 @@ static bool parse_keyfile(uint8_t key[static WG_KEY_LEN], const char *path)
 	}
 	ret = parse_key(key, dst);
 
-out:
+	out:
 	fclose(f);
+	DEBUG_PRINT("Exiting parse_keyfile with status: %s\n", ret ? "success" : "failure");
 	return ret;
 }
 
 static inline bool parse_ip(struct wgallowedip *allowedip, const char *value)
 {
+	DEBUG_PRINT("Entering parse_ip: allowedip: %p, value: %s\n", allowedip, value);
 	allowedip->family = AF_UNSPEC;
 	if (strchr(value, ':')) {
-		if (inet_pton(AF_INET6, value, &allowedip->ip6) == 1)
+		if (inet_pton(AF_INET6, value, &allowedip->ip6) == 1) {
 			allowedip->family = AF_INET6;
+			DEBUG_PRINT("Parsed IPv6 address: %s\n", value);
+		}
 	} else {
-		if (inet_pton(AF_INET, value, &allowedip->ip4) == 1)
+		if (inet_pton(AF_INET, value, &allowedip->ip4) == 1) {
 			allowedip->family = AF_INET;
+			DEBUG_PRINT("Parsed IPv4 address: %s\n", value);
+		}
 	}
 	if (allowedip->family == AF_UNSPEC) {
 		fprintf(stderr, "Unable to parse IP address: `%s'\n", value);
+		DEBUG_PRINT("Error in parse_ip: Unable to parse IP address: `%s'\n", value);
+		DEBUG_PRINT("Exiting parse_ip with status: failure\n");
 		return false;
 	}
+	DEBUG_PRINT("Exiting parse_ip with status: success\n");
 	return true;
 }
 
 static inline int parse_dns_retries(void)
 {
+	DEBUG_PRINT("Entering parse_dns_retries\n");
 	unsigned long ret;
 	char *retries = getenv("WG_ENDPOINT_RESOLUTION_RETRIES"), *end;
 
-	if (!retries)
+	if (!retries) {
+		DEBUG_PRINT("Default DNS retries: 15\n");
+		DEBUG_PRINT("Exiting parse_dns_retries\n");
 		return 15;
-	if (!strcmp(retries, "infinity"))
+	}
+	if (!strcmp(retries, "infinity")) {
+		DEBUG_PRINT("DNS retries set to infinity\n");
+		DEBUG_PRINT("Exiting parse_dns_retries\n");
 		return -1;
+	}
 
 	ret = strtoul(retries, &end, 10);
 	if (*end || ret > INT_MAX) {
 		fprintf(stderr, "Unable to parse WG_ENDPOINT_RESOLUTION_RETRIES: `%s'\n", retries);
+		DEBUG_PRINT("Error in parse_dns_retries: Unable to parse WG_ENDPOINT_RESOLUTION_RETRIES: `%s'\n", retries);
 		exit(1);
 	}
+	DEBUG_PRINT("Parsed DNS retries: %lu\n", ret);
+	DEBUG_PRINT("Exiting parse_dns_retries\n");
 	return (int)ret;
 }
 
 static inline bool parse_endpoint(struct sockaddr *endpoint, const char *value)
 {
+	DEBUG_PRINT("Entering parse_endpoint: endpoint: %p, value: %s\n", endpoint, value);
 	char *mutable = strdup(value);
 	char *begin, *end;
 	int ret, retries = parse_dns_retries();
@@ -205,11 +273,14 @@ static inline bool parse_endpoint(struct sockaddr *endpoint, const char *value)
 	};
 	if (!mutable) {
 		perror("strdup");
+		DEBUG_PRINT("Exiting parse_endpoint with status: failure\n");
 		return false;
 	}
 	if (!strlen(value)) {
 		free(mutable);
 		fprintf(stderr, "Unable to parse empty endpoint\n");
+		DEBUG_PRINT("Error in parse_endpoint: empty endpoint value\n");
+		DEBUG_PRINT("Exiting parse_endpoint with status: failure\n");
 		return false;
 	}
 	if (mutable[0] == '[') {
@@ -218,12 +289,16 @@ static inline bool parse_endpoint(struct sockaddr *endpoint, const char *value)
 		if (!end) {
 			free(mutable);
 			fprintf(stderr, "Unable to find matching brace of endpoint: `%s'\n", value);
+			DEBUG_PRINT("Error in parse_endpoint: Unable to find matching brace of endpoint: `%s'\n", value);
+			DEBUG_PRINT("Exiting parse_endpoint with status: failure\n");
 			return false;
 		}
 		*end++ = '\0';
 		if (*end++ != ':' || !*end) {
 			free(mutable);
 			fprintf(stderr, "Unable to find port of endpoint: `%s'\n", value);
+			DEBUG_PRINT("Error in parse_endpoint: Unable to find port of endpoint: `%s'\n", value);
+			DEBUG_PRINT("Exiting parse_endpoint with status: failure\n");
 			return false;
 		}
 	} else {
@@ -232,6 +307,8 @@ static inline bool parse_endpoint(struct sockaddr *endpoint, const char *value)
 		if (!end || !*(end + 1)) {
 			free(mutable);
 			fprintf(stderr, "Unable to find port of endpoint: `%s'\n", value);
+			DEBUG_PRINT("Error in parse_endpoint: Unable to find port of endpoint: `%s'\n", value);
+			DEBUG_PRINT("Exiting parse_endpoint with status: failure\n");
 			return false;
 		}
 		*end++ = '\0';
@@ -240,18 +317,19 @@ static inline bool parse_endpoint(struct sockaddr *endpoint, const char *value)
 	#define min(a, b) ((a) < (b) ? (a) : (b))
 	for (unsigned int timeout = 1000000;; timeout = min(20000000, timeout * 6 / 5)) {
 		ret = getaddrinfo(begin, end, &hints, &resolved);
-		if (!ret)
+		if (!ret) {
 			break;
+		}
 		/* The set of return codes that are "permanent failures". All other possibilities are potentially transient.
-		 *
-		 * This is according to https://sourceware.org/glibc/wiki/NameResolver which states:
-		 *	"From the perspective of the application that calls getaddrinfo() it perhaps
-		 *	 doesn't matter that much since EAI_FAIL, EAI_NONAME and EAI_NODATA are all
-		 *	 permanent failure codes and the causes are all permanent failures in the
-		 *	 sense that there is no point in retrying later."
-		 *
-		 * So this is what we do, except FreeBSD removed EAI_NODATA some time ago, so that's conditional.
-		 */
+-		 *
+-		 * This is according to https://sourceware.org/glibc/wiki/NameResolver which states:
+-		 *	"From the perspective of the application that calls getaddrinfo() it perhaps
+-		 *	 doesn't matter that much since EAI_FAIL, EAI_NONAME and EAI_NODATA are all
+-		 *	 permanent failure codes and the causes are all permanent failures in the
+-		 *	 sense that there is no point in retrying later."
+-		 *
+-		 * So this is what we do, except FreeBSD removed EAI_NODATA some time ago, so that's conditional.
+-		 */
 		if (ret == EAI_NONAME || ret == EAI_FAIL ||
 			#ifdef EAI_NODATA
 				ret == EAI_NODATA ||
@@ -259,54 +337,73 @@ static inline bool parse_endpoint(struct sockaddr *endpoint, const char *value)
 				(retries >= 0 && !retries--)) {
 			free(mutable);
 			fprintf(stderr, "%s: `%s'\n", ret == EAI_SYSTEM ? strerror(errno) : gai_strerror(ret), value);
+			DEBUG_PRINT("Error in parse_endpoint: %s: `%s'\n", ret == EAI_SYSTEM ? strerror(errno) : gai_strerror(ret), value);
+			DEBUG_PRINT("Exiting parse_endpoint with status: failure\n");
 			return false;
 		}
-		fprintf(stderr, "%s: `%s'. Trying again in %.2f seconds...\n", ret == EAI_SYSTEM ? strerror(errno) : gai_strerror(ret), value, timeout / 1000000.0);
+		DEBUG_PRINT("Transient error in parse_endpoint: %s: `%s'. Trying again in %.2f seconds...\n", ret == EAI_SYSTEM ? strerror(errno) : gai_strerror(ret), value, timeout / 1000000.0);
 		usleep(timeout);
 	}
 
 	if ((resolved->ai_family == AF_INET && resolved->ai_addrlen == sizeof(struct sockaddr_in)) ||
-	    (resolved->ai_family == AF_INET6 && resolved->ai_addrlen == sizeof(struct sockaddr_in6)))
+	    (resolved->ai_family == AF_INET6 && resolved->ai_addrlen == sizeof(struct sockaddr_in6))) {
 		memcpy(endpoint, resolved->ai_addr, resolved->ai_addrlen);
-	else {
+		DEBUG_PRINT("Parsed endpoint address successfully\n");
+	} else {
 		freeaddrinfo(resolved);
 		free(mutable);
 		fprintf(stderr, "Neither IPv4 nor IPv6 address found: `%s'\n", value);
+		DEBUG_PRINT("Error in parse_endpoint: Neither IPv4 nor IPv6 address found: `%s'\n", value);
+		DEBUG_PRINT("Exiting parse_endpoint with status: failure\n");
 		return false;
 	}
 	freeaddrinfo(resolved);
 	free(mutable);
+	DEBUG_PRINT("Exiting parse_endpoint with status: success\n");
 	return true;
 }
 
 static inline bool parse_persistent_keepalive(uint16_t *interval, uint32_t *flags, const char *value)
 {
+	DEBUG_PRINT("Entering parse_persistent_keepalive: interval: %p, flags: %p, value: %s\n", interval, flags, value);
 	unsigned long ret;
 	char *end;
 
 	if (!strcasecmp(value, "off")) {
 		*interval = 0;
 		*flags |= WGPEER_HAS_PERSISTENT_KEEPALIVE_INTERVAL;
+		DEBUG_PRINT("Parsed persistent keepalive interval as off. Flag WGPEER_HAS_PERSISTENT_KEEPALIVE_INTERVAL set\n");
+		DEBUG_PRINT("Exiting parse_persistent_keepalive with status: success\n");
 		return true;
 	}
 
-	if (!char_is_digit(value[0]))
+	if (!char_is_digit(value[0])) {
+		DEBUG_PRINT("Error in parse_persistent_keepalive: Value is not a digit\n");
 		goto err;
+	}
 
 	ret = strtoul(value, &end, 10);
-	if (*end || ret > 65535)
+	if (*end || ret > 65535) {
+		DEBUG_PRINT("Error in parse_persistent_keepalive: Invalid interval value or out of range\n");
 		goto err;
+	}
 
 	*interval = (uint16_t)ret;
 	*flags |= WGPEER_HAS_PERSISTENT_KEEPALIVE_INTERVAL;
+	
+	DEBUG_PRINT("Parsed persistent keepalive interval: %u. Flag WGPEER_HAS_PERSISTENT_KEEPALIVE_INTERVAL set\n", *interval);
+	DEBUG_PRINT("Exiting parse_persistent_keepalive with status: success\n");
 	return true;
 err:
 	fprintf(stderr, "Persistent keepalive interval is neither 0/off nor 1-65535: `%s'\n", value);
+	DEBUG_PRINT("Error in parse_persistent_keepalive: Interval is neither 0/off nor 1-65535: `%s'\n", value);
+	DEBUG_PRINT("Exiting parse_persistent_keepalive with status: failure\n");
 	return false;
 }
 
 static bool validate_netmask(struct wgallowedip *allowedip)
 {
+	DEBUG_PRINT("Entering validate_netmask: allowedip: %p\n", allowedip);
 	uint32_t *ip;
 	int last;
 
@@ -320,35 +417,47 @@ static bool validate_netmask(struct wgallowedip *allowedip)
 			ip = (uint32_t *)&allowedip->ip6;
 			break;
 		default:
+			DEBUG_PRINT("Error in validate_netmask: Unknown address family\n");
+			DEBUG_PRINT("Exiting validate_netmask with status: failure\n");
 			return true; /* We don't know how to validate it, so say 'okay'. */
 	}
 
 	for (int i = last; i >= 0; --i) {
 		uint32_t mask = ~0;
 
-		if (allowedip->cidr >= 32 * (i + 1))
+		if (allowedip->cidr >= 32 * (i + 1)) {
 			break;
-		if (allowedip->cidr > 32 * i)
+		}
+		if (allowedip->cidr > 32 * i) {
 			mask >>= (allowedip->cidr - 32 * i);
-		if (ntohl(ip[i]) & mask)
+		}
+		if (ntohl(ip[i]) & mask) {
+			DEBUG_PRINT("Error in validate_netmask: Nonzero host part found\n");
+			DEBUG_PRINT("Exiting validate_netmask with status: failure\n");
 			return false;
+		}
 	}
-
+	DEBUG_PRINT("Netmask validated successfully\n");
+	DEBUG_PRINT("Exiting validate_netmask with status: success\n");
 	return true;
 }
 
 static inline bool parse_allowedips(struct wgpeer *peer, struct wgallowedip **last_allowedip, const char *value)
 {
+	DEBUG_PRINT("Entering parse_allowedips: peer: %p, last_allowedip: %p, value: %s\n", peer, last_allowedip, value);
 	struct wgallowedip *allowedip = *last_allowedip, *new_allowedip;
 	char *mask, *mutable = strdup(value), *sep, *saved_entry;
 
 	if (!mutable) {
 		perror("strdup");
+		DEBUG_PRINT("Exiting parse_allowedips with status: failure\n");
 		return false;
 	}
 	peer->flags |= WGPEER_REPLACE_ALLOWEDIPS;
 	if (!strlen(value)) {
 		free(mutable);
+		DEBUG_PRINT("No allowed IPs to parse\n");
+		DEBUG_PRINT("Exiting parse_allowedips with status: success\n");
 		return true;
 	}
 	sep = mutable;
@@ -364,6 +473,7 @@ static inline bool parse_allowedips(struct wgpeer *peer, struct wgallowedip **la
 			perror("calloc");
 			free(saved_entry);
 			free(mutable);
+			DEBUG_PRINT("Exiting parse_allowedips with status: failure\n");
 			return false;
 		}
 
@@ -371,53 +481,89 @@ static inline bool parse_allowedips(struct wgpeer *peer, struct wgallowedip **la
 			free(new_allowedip);
 			free(saved_entry);
 			free(mutable);
+			DEBUG_PRINT("Exiting parse_allowedips with status: failure\n");
 			return false;
 		}
 
 		if (mask) {
-			if (!char_is_digit(mask[0]))
+			if (!char_is_digit(mask[0])) {
+				DEBUG_PRINT("Error in parse_allowedips: CIDR is not a digit\n");
 				goto err;
+			}
 			cidr = strtoul(mask, &end, 10);
-			if (*end || (cidr > 32 && new_allowedip->family == AF_INET) || (cidr > 128 && new_allowedip->family == AF_INET6))
+			if (*end || (cidr > 32 && new_allowedip->family == AF_INET) || (cidr > 128 && new_allowedip->family == AF_INET6)) {
+				DEBUG_PRINT("Error in parse_allowedips: CIDR value is invalid or out of range\n");
 				goto err;
-		} else if (new_allowedip->family == AF_INET)
+			}
+		} else if (new_allowedip->family == AF_INET) {
 			cidr = 32;
-		else if (new_allowedip->family == AF_INET6)
+		} else if (new_allowedip->family == AF_INET6) {
 			cidr = 128;
-		else
+		} else {
+			DEBUG_PRINT("Error in parse_allowedips: Unsupported address family\n");
 			goto err;
+		}
 		new_allowedip->cidr = cidr;
 
-		if (!validate_netmask(new_allowedip))
+		if (!validate_netmask(new_allowedip)) {
 			fprintf(stderr, "Warning: AllowedIP has nonzero host part: %s/%s\n", ip, mask);
+			DEBUG_PRINT("Warning: AllowedIP has nonzero host part: %s/%s\n", ip, mask);
+		}
 
-		if (allowedip)
+		if (allowedip) {
 			allowedip->next_allowedip = new_allowedip;
-		else
+		} else {
 			peer->first_allowedip = new_allowedip;
+		}
 		allowedip = new_allowedip;
 		free(saved_entry);
 	}
 	free(mutable);
 	*last_allowedip = allowedip;
+	DEBUG_PRINT("Exiting parse_allowedips with status: success\n");
 	return true;
 
 err:
 	free(new_allowedip);
 	free(mutable);
 	fprintf(stderr, "AllowedIP is not in the correct format: `%s'\n", saved_entry);
+	DEBUG_PRINT("Error in parse_allowedips: AllowedIP is not in the correct format: `%s'\n", saved_entry);
 	free(saved_entry);
+	DEBUG_PRINT("Exiting parse_allowedips with status: failure\n");
 	return false;
 }
 
+static inline bool parse_transport(uint8_t *transport, const char *value)
+{
+	DEBUG_PRINT("Entering parse_transport: transport: %p, value: %s\n", transport, value);
+	if (!strcasecmp(value, "tcp")) {
+		*transport = WG_TRANSPORT_TCP;
+		DEBUG_PRINT("Parsed transport as TCP\n");
+		DEBUG_PRINT("Exiting parse_transport with status: success\n");
+		return true;
+	} else if (!strcasecmp(value, "udp")) {
+		*transport = WG_TRANSPORT_UDP;
+		DEBUG_PRINT("Parsed transport as UDP\n");
+		DEBUG_PRINT("Exiting parse_transport with status: success\n");
+		return true;
+	} else {
+		DEBUG_PRINT("Error in parse_transport: Transport protocol is neither tcp nor udp: `%s'\n", value);
+		DEBUG_PRINT("Exiting parse_transport with status: failure\n");
+		return false;
+	}
+}
+
 static bool process_line(struct config_ctx *ctx, const char *line)
 {
+	DEBUG_PRINT("Entering process_line: ctx: %p, line: %s\n", ctx, line);
 	const char *value;
 	bool ret = true;
 
 	if (!strcasecmp(line, "[Interface]")) {
 		ctx->is_peer_section = false;
 		ctx->is_device_section = true;
+		DEBUG_PRINT("Detected [Interface] section\n");
+		DEBUG_PRINT("Exiting process_line with status: success\n");
 		return true;
 	}
 	if (!strcasecmp(line, "[Peer]")) {
@@ -425,73 +571,90 @@ static bool process_line(struct config_ctx *ctx, const char *line)
 
 		if (!new_peer) {
 			perror("calloc");
+			DEBUG_PRINT("Exiting process_line with status: failure\n");
 			return false;
 		}
 		ctx->last_allowedip = NULL;
-		if (ctx->last_peer)
+		if (ctx->last_peer) {
 			ctx->last_peer->next_peer = new_peer;
-		else
+		} else {
 			ctx->device->first_peer = new_peer;
+		}
 		ctx->last_peer = new_peer;
 		ctx->is_peer_section = true;
 		ctx->is_device_section = false;
 		ctx->last_peer->flags |= WGPEER_REPLACE_ALLOWEDIPS;
+		DEBUG_PRINT("Detected [Peer] section\n");
+		DEBUG_PRINT("Exiting process_line with status: success\n");
 		return true;
 	}
 
-#define key_match(key) (value = get_value(line, key "="))
+	#define key_match(key) (value = get_value(line, key "="))
 
 	if (ctx->is_device_section) {
-		if (key_match("ListenPort"))
+		if (key_match("ListenPort")) {
 			ret = parse_port(&ctx->device->listen_port, &ctx->device->flags, value);
-		else if (key_match("FwMark"))
+		} else if (key_match("FwMark")) {
 			ret = parse_fwmark(&ctx->device->fwmark, &ctx->device->flags, value);
-		else if (key_match("PrivateKey")) {
+		} else if (key_match("PrivateKey")) {
 			ret = parse_key(ctx->device->private_key, value);
-			if (ret)
+			if (ret) {
 				ctx->device->flags |= WGDEVICE_HAS_PRIVATE_KEY;
+				DEBUG_PRINT("Parsed PrivateKey successfully. Flag WGDEVICE_HAS_PRIVATE_KEY set\n");
+			}
+		} else if (key_match("Transport")) {
+			ret = parse_transport(&ctx->device->transport, value);
+			ctx->device->flags |= WGDEVICE_HAS_TRANSPORT;
 		} else
 			goto error;
 	} else if (ctx->is_peer_section) {
-		if (key_match("Endpoint"))
+		if (key_match("Endpoint")) {
 			ret = parse_endpoint(&ctx->last_peer->endpoint.addr, value);
-		else if (key_match("PublicKey")) {
+		} else if (key_match("PublicKey")) {
 			ret = parse_key(ctx->last_peer->public_key, value);
-			if (ret)
+			if (ret) {
 				ctx->last_peer->flags |= WGPEER_HAS_PUBLIC_KEY;
-		} else if (key_match("AllowedIPs"))
+				DEBUG_PRINT("Parsed PublicKey successfully. Flag WGPEER_HAS_PUBLIC_KEY set\n");
+			}
+		} else if (key_match("AllowedIPs")) {
 			ret = parse_allowedips(ctx->last_peer, &ctx->last_allowedip, value);
-		else if (key_match("PersistentKeepalive"))
+		} else if (key_match("PersistentKeepalive")) {
 			ret = parse_persistent_keepalive(&ctx->last_peer->persistent_keepalive_interval, &ctx->last_peer->flags, value);
-		else if (key_match("PresharedKey")) {
+		} else if (key_match("PresharedKey")) {
 			ret = parse_key(ctx->last_peer->preshared_key, value);
-			if (ret)
+			if (ret) {
 				ctx->last_peer->flags |= WGPEER_HAS_PRESHARED_KEY;
+				DEBUG_PRINT("Parsed PresharedKey successfully. Flag WGPEER_HAS_PRESHARED_KEY set\n");
+			}
 		} else
 			goto error;
 	} else
 		goto error;
+	DEBUG_PRINT("Exiting process_line with status: %s\n", ret ? "success" : "failure");
 	return ret;
 
-#undef key_match
+	#undef key_match
 
 error:
 	fprintf(stderr, "Line unrecognized: `%s'\n", line);
+	DEBUG_PRINT("Error in process_line: Line unrecognized: `%s'\n", line);
+	DEBUG_PRINT("Exiting process_line with status: failure\n");
 	return false;
 }
 
 bool config_read_line(struct config_ctx *ctx, const char *input)
 {
+	DEBUG_PRINT("Entering config_read_line: ctx: %p, input: %s\n", ctx, input);
 	size_t len, cleaned_len = 0;
 	char *line, *comment;
 	bool ret = true;
 
-	/* This is what strchrnul is for, but that isn't portable. */
 	comment = strchr(input, COMMENT_CHAR);
-	if (comment)
+	if (comment) {
 		len = comment - input;
-	else
+	} else {
 		len = strlen(input);
+	}
 
 	line = calloc(len + 1, sizeof(char));
 	if (!line) {
@@ -501,50 +664,65 @@ bool config_read_line(struct config_ctx *ctx, const char *input)
 	}
 
 	for (size_t i = 0; i < len; ++i) {
-		if (!char_is_space(input[i]))
-			line[cleaned_len++] = input[i];
+		if (!char_is_space(input[i])) {
+		line[cleaned_len++] = input[i];
+		}
 	}
-	if (!cleaned_len)
+	if (!cleaned_len) {
+		DEBUG_PRINT("No non-space characters in line\n");
 		goto out;
+	}
 	ret = process_line(ctx, line);
 out:
 	free(line);
-	if (!ret)
+	if (!ret) {
 		free_wgdevice(ctx->device);
+	}
+	DEBUG_PRINT("Exiting config_read_line with status: %s\n", ret ? "success" : "failure");
 	return ret;
 }
 
 bool config_read_init(struct config_ctx *ctx, bool append)
 {
+	DEBUG_PRINT("Entering config_read_init: ctx: %p, append: %d\n", ctx, append);
 	memset(ctx, 0, sizeof(*ctx));
 	ctx->device = calloc(1, sizeof(*ctx->device));
 	if (!ctx->device) {
 		perror("calloc");
+		DEBUG_PRINT("Exiting config_read_init with status: failure\n");
 		return false;
 	}
-	if (!append)
+	if (!append) {
 		ctx->device->flags |= WGDEVICE_REPLACE_PEERS | WGDEVICE_HAS_PRIVATE_KEY | WGDEVICE_HAS_FWMARK | WGDEVICE_HAS_LISTEN_PORT;
+		DEBUG_PRINT("Flags WGDEVICE_REPLACE_PEERS, WGDEVICE_HAS_PRIVATE_KEY, WGDEVICE_HAS_FWMARK, WGDEVICE_HAS_LISTEN_PORT set\n");
+	}
+	DEBUG_PRINT("Exiting config_read_init with status: success\n");
 	return true;
 }
 
 struct wgdevice *config_read_finish(struct config_ctx *ctx)
 {
+	DEBUG_PRINT("Entering config_read_finish: ctx: %p\n", ctx);
 	struct wgpeer *peer;
 
 	for_each_wgpeer(ctx->device, peer) {
 		if (!(peer->flags & WGPEER_HAS_PUBLIC_KEY)) {
 			fprintf(stderr, "A peer is missing a public key\n");
+			DEBUG_PRINT("Error in config_read_finish: A peer is missing a public key\n");
 			goto err;
 		}
 	}
+	DEBUG_PRINT("Exiting config_read_finish with status: success\n");
 	return ctx->device;
 err:
 	free_wgdevice(ctx->device);
+	DEBUG_PRINT("Exiting config_read_finish with status: failure\n");
 	return NULL;
 }
 
 static char *strip_spaces(const char *in)
 {
+	DEBUG_PRINT("Entering strip_spaces: in: %s\n", in);
 	char *out;
 	size_t t, l, i;
 
@@ -552,42 +730,57 @@ static char *strip_spaces(const char *in)
 	out = calloc(t + 1, sizeof(char));
 	if (!out) {
 		perror("calloc");
+		DEBUG_PRINT("Exiting strip_spaces with status: failure\n");
 		return NULL;
 	}
 	for (i = 0, l = 0; i < t; ++i) {
-		if (!char_is_space(in[i]))
+		if (!char_is_space(in[i])) {
 			out[l++] = in[i];
+		}
 	}
+	DEBUG_PRINT("Exiting strip_spaces with status: success\n");
 	return out;
 }
 
 struct wgdevice *config_read_cmd(const char *argv[], int argc)
 {
+	DEBUG_PRINT("Entering config_read_cmd: argv: %p, argc: %d\n", argv, argc);
 	struct wgdevice *device = calloc(1, sizeof(*device));
 	struct wgpeer *peer = NULL;
 	struct wgallowedip *allowedip = NULL;
 
 	if (!device) {
 		perror("calloc");
+		DEBUG_PRINT("Exiting config_read_cmd with status: failure\n");
 		return false;
 	}
 	while (argc > 0) {
 		if (!strcmp(argv[0], "listen-port") && argc >= 2 && !peer) {
-			if (!parse_port(&device->listen_port, &device->flags, argv[1]))
+			if (!parse_port(&device->listen_port, &device->flags, argv[1])) {
 				goto error;
+			}
 			argv += 2;
 			argc -= 2;
 		} else if (!strcmp(argv[0], "fwmark") && argc >= 2 && !peer) {
-			if (!parse_fwmark(&device->fwmark, &device->flags, argv[1]))
+			if (!parse_fwmark(&device->fwmark, &device->flags, argv[1])) {
 				goto error;
+			}
 			argv += 2;
 			argc -= 2;
 		} else if (!strcmp(argv[0], "private-key") && argc >= 2 && !peer) {
-			if (!parse_keyfile(device->private_key, argv[1]))
+			if (!parse_keyfile(device->private_key, argv[1])) {
 				goto error;
+			}
 			device->flags |= WGDEVICE_HAS_PRIVATE_KEY;
 			argv += 2;
 			argc -= 2;
+		} else if (!strcmp(argv[0], "transport") && argc >= 2 && !peer) {
+			if (!parse_transport(&device->transport, argv[1])) {
+				goto error;
+			}
+			device->flags |= WGDEVICE_HAS_TRANSPORT;
+			argv += 2;
+			argc -= 2;
 		} else if (!strcmp(argv[0], "peer") && argc >= 2) {
 			struct wgpeer *new_peer = calloc(1, sizeof(*new_peer));
 
@@ -596,13 +789,15 @@ struct wgdevice *config_read_cmd(const char *argv[], int argc)
 				perror("calloc");
 				goto error;
 			}
-			if (peer)
+			if (peer) {
 				peer->next_peer = new_peer;
-			else
+			} else {
 				device->first_peer = new_peer;
+			}
 			peer = new_peer;
-			if (!parse_key(peer->public_key, argv[1]))
+			if (!parse_key(peer->public_key, argv[1])) {
 				goto error;
+			}
 			peer->flags |= WGPEER_HAS_PUBLIC_KEY;
 			argv += 2;
 			argc -= 2;
@@ -611,15 +806,17 @@ struct wgdevice *config_read_cmd(const char *argv[], int argc)
 			argv += 1;
 			argc -= 1;
 		} else if (!strcmp(argv[0], "endpoint") && argc >= 2 && peer) {
-			if (!parse_endpoint(&peer->endpoint.addr, argv[1]))
+			if (!parse_endpoint(&peer->endpoint.addr, argv[1])) {
 				goto error;
+			}
 			argv += 2;
 			argc -= 2;
 		} else if (!strcmp(argv[0], "allowed-ips") && argc >= 2 && peer) {
 			char *line = strip_spaces(argv[1]);
 
-			if (!line)
+			if (!line) {
 				goto error;
+			}
 			if (!parse_allowedips(peer, &allowedip, line)) {
 				free(line);
 				goto error;
@@ -628,23 +825,28 @@ struct wgdevice *config_read_cmd(const char *argv[], int argc)
 			argv += 2;
 			argc -= 2;
 		} else if (!strcmp(argv[0], "persistent-keepalive") && argc >= 2 && peer) {
-			if (!parse_persistent_keepalive(&peer->persistent_keepalive_interval, &peer->flags, argv[1]))
+			if (!parse_persistent_keepalive(&peer->persistent_keepalive_interval, &peer->flags, argv[1])) {
 				goto error;
+			}
 			argv += 2;
 			argc -= 2;
 		} else if (!strcmp(argv[0], "preshared-key") && argc >= 2 && peer) {
-			if (!parse_keyfile(peer->preshared_key, argv[1]))
+			if (!parse_keyfile(peer->preshared_key, argv[1])) {
 				goto error;
+			}
 			peer->flags |= WGPEER_HAS_PRESHARED_KEY;
 			argv += 2;
 			argc -= 2;
 		} else {
 			fprintf(stderr, "Invalid argument: %s\n", argv[0]);
+			DEBUG_PRINT("Error in config_read_cmd: Invalid argument: %s\n", argv[0]);
 			goto error;
 		}
 	}
+	DEBUG_PRINT("Exiting config_read_cmd with status: success\n");
 	return device;
 error:
 	free_wgdevice(device);
+	DEBUG_PRINT("Exiting config_read_cmd with status: failure\n");
 	return false;
 }
diff --git a/wireguard-tools/src/containers.h b/wireguard-tools/src/containers.h
index a82e8ddee46a..82e8769eb90f 100644
--- a/wireguard-tools/src/containers.h
+++ b/wireguard-tools/src/containers.h
@@ -71,7 +71,8 @@ enum {
 	WGDEVICE_HAS_PRIVATE_KEY = 1U << 1,
 	WGDEVICE_HAS_PUBLIC_KEY = 1U << 2,
 	WGDEVICE_HAS_LISTEN_PORT = 1U << 3,
-	WGDEVICE_HAS_FWMARK = 1U << 4
+	WGDEVICE_HAS_FWMARK = 1U << 4,
+	WGDEVICE_HAS_TRANSPORT = 1U << 5
 };
 
 struct wgdevice {
@@ -87,6 +88,7 @@ struct wgdevice {
 	uint16_t listen_port;
 
 	struct wgpeer *first_peer, *last_peer;
+	uint8_t transport;
 };
 
 #define for_each_wgpeer(__dev, __peer) for ((__peer) = (__dev)->first_peer; (__peer); (__peer) = (__peer)->next_peer)
diff --git a/wireguard-tools/src/ipc-linux.h b/wireguard-tools/src/ipc-linux.h
index d29c0c5dbf9b..7c8f37898158 100644
--- a/wireguard-tools/src/ipc-linux.h
+++ b/wireguard-tools/src/ipc-linux.h
@@ -3,6 +3,9 @@
  * Copyright (C) 2015-2020 Jason A. Donenfeld <Jason@zx2c4.com>. All Rights Reserved.
  */
 
+#define RUNSTATEDIR "/var/run" // Define RUNSTATEDIR here
+#define SOCK_PATH RUNSTATEDIR "/wireguard/"
+
 #include <stdbool.h>
 #include <stddef.h>
 #include <stdint.h>
@@ -23,6 +26,8 @@
 #include "encoding.h"
 #include "netlink.h"
 
+#include <ctype.h>
+
 #define IPC_SUPPORTS_KERNEL_INTERFACE
 
 #define SOCKET_BUFFER_SIZE (mnl_ideal_socket_buffer_size())
@@ -32,10 +37,308 @@ struct interface {
 	bool is_wireguard;
 };
 
+
+// Hex dump function for raw data
+static void hex_dump(const void *data, size_t size)
+{
+    const unsigned char *byte = (const unsigned char *)data;
+    size_t i, j;
+
+    for (i = 0; i < size; i += 16) {
+        printf("%06zx: ", i);
+        for (j = 0; j < 16; j++) {
+            if (i + j < size)
+                printf("%02x ", byte[i + j]);
+            else
+                printf("   ");
+        }
+        printf(" |");
+        for (j = 0; j < 16; j++) {
+            if (i + j < size)
+                printf("%c", isprint(byte[i + j]) ? byte[i + j] : '.');
+            else
+                printf(" ");
+        }
+        printf("|\n");
+    }
+}
+
+// Routine to parse and print flags with verbose values
+static void print_flags_verbose(uint32_t flags)
+{
+    printf("Flags: 0x%08x (", flags);
+    if (flags & NLM_F_REQUEST) printf("REQUEST ");
+    if (flags & NLM_F_MULTI) printf("MULTI ");
+    if (flags & NLM_F_ACK) printf("ACK ");
+    if (flags & NLM_F_ECHO) printf("ECHO ");
+    if (flags & NLM_F_REPLACE) printf("REPLACE ");
+    if (flags & NLM_F_EXCL) printf("EXCL ");
+    if (flags & NLM_F_CREATE) printf("CREATE ");
+    if (flags & NLM_F_APPEND) printf("APPEND ");
+    printf(")\n");
+}
+
+// Routine to parse and print peer flags with verbose labels
+static void print_peer_flags_verbose(uint32_t flags)
+{
+    printf("Peer Flags: 0x%08x (", flags);
+    if (flags & WGPEER_F_REMOVE_ME) printf("REMOVE_ME ");
+    if (flags & WGPEER_F_REPLACE_ALLOWEDIPS) printf("REPLACE_ALLOWEDIPS ");
+    if (flags & WGPEER_F_UPDATE_ONLY) printf("UPDATE_ONLY ");
+    printf(")\n");
+}
+
+// Functions to print the allowed IP attributes
+static void print_allowedip_attr(const struct nlattr *attr)
+{
+    int type = mnl_attr_get_type(attr);
+
+    switch (type) {
+    case WGALLOWEDIP_A_FAMILY:
+        printf("WGALLOWEDIP_A_FAMILY: %u\n", mnl_attr_get_u16(attr));
+        break;
+    case WGALLOWEDIP_A_IPADDR:
+        printf("WGALLOWEDIP_A_IPADDR: %pIS\n", mnl_attr_get_payload(attr));
+        break;
+    case WGALLOWEDIP_A_CIDR_MASK:
+        printf("WGALLOWEDIP_A_CIDR_MASK: %u\n", mnl_attr_get_u8(attr));
+        break;
+    default:
+        printf("Unknown Allowed IP Attribute Type: %d\n", type);
+        break;
+    }
+}
+
+static void print_peer_allowedips(const struct nlattr *attr)
+{
+    struct nlattr *nested_attr;
+    mnl_attr_for_each_nested(nested_attr, attr) {
+        print_allowedip_attr(nested_attr);
+    }
+}
+
+// Functions to print the peer attributes
+static void print_peer_attr(const struct nlattr *attr)
+{
+    int type = mnl_attr_get_type(attr);
+
+    switch (type) {
+    case WGPEER_A_PUBLIC_KEY:
+        printf("WGPEER_A_PUBLIC_KEY: %*phN\n", mnl_attr_get_payload_len(attr), mnl_attr_get_payload(attr));
+        break;
+    case WGPEER_A_PRESHARED_KEY:
+        printf("WGPEER_A_PRESHARED_KEY: %*phN\n", mnl_attr_get_payload_len(attr), mnl_attr_get_payload(attr));
+        break;
+    case WGPEER_A_FLAGS:
+        printf("WGPEER_A_FLAGS: %u\n", mnl_attr_get_u32(attr));
+        print_peer_flags_verbose(mnl_attr_get_u32(attr));
+        break;
+    case WGPEER_A_ENDPOINT:
+        printf("WGPEER_A_ENDPOINT: %pIS\n", mnl_attr_get_payload(attr));
+        break;
+    case WGPEER_A_PERSISTENT_KEEPALIVE_INTERVAL:
+        printf("WGPEER_A_PERSISTENT_KEEPALIVE_INTERVAL: %u\n", mnl_attr_get_u16(attr));
+        break;
+    case WGPEER_A_LAST_HANDSHAKE_TIME:
+        printf("WGPEER_A_LAST_HANDSHAKE_TIME: %lld.%.9ld\n",
+               (long long)((struct timespec *)mnl_attr_get_payload(attr))->tv_sec,
+               (long)((struct timespec *)mnl_attr_get_payload(attr))->tv_nsec);
+        break;
+    case WGPEER_A_RX_BYTES:
+        printf("WGPEER_A_RX_BYTES: %lu\n", (unsigned long)mnl_attr_get_u64(attr));
+        break;
+    case WGPEER_A_TX_BYTES:
+        printf("WGPEER_A_TX_BYTES: %lu\n", (unsigned long)mnl_attr_get_u64(attr));
+        break;
+    case WGPEER_A_ALLOWEDIPS:
+        printf("WGPEER_A_ALLOWEDIPS (Nested Attributes):\n");
+        print_peer_allowedips(attr);
+        break;
+    default:
+        printf("Unknown Peer Attribute Type: %d\n", type);
+        break;
+    }
+}
+
+// Functions to print the device attributes
+static void print_device_peers(const struct nlattr *attr)
+{
+    struct nlattr *nested_attr;
+    mnl_attr_for_each_nested(nested_attr, attr) {
+        print_peer_attr(nested_attr);
+    }
+}
+
+static void print_device_attr(const struct nlattr *attr)
+{
+    int type = mnl_attr_get_type(attr);
+
+    switch (type) {
+    case WGDEVICE_A_IFINDEX:
+        printf("WGDEVICE_A_IFINDEX: %u\n", mnl_attr_get_u32(attr));
+        break;
+    case WGDEVICE_A_IFNAME:
+        printf("WGDEVICE_A_IFNAME: %s\n", mnl_attr_get_str(attr));
+        break;
+    case WGDEVICE_A_PRIVATE_KEY:
+        printf("WGDEVICE_A_PRIVATE_KEY: %*phN\n", mnl_attr_get_payload_len(attr), mnl_attr_get_payload(attr));
+        break;
+    case WGDEVICE_A_PUBLIC_KEY:
+        printf("WGDEVICE_A_PUBLIC_KEY: %*phN\n", mnl_attr_get_payload_len(attr), mnl_attr_get_payload(attr));
+        break;
+    case WGDEVICE_A_FLAGS:
+        printf("WGDEVICE_A_FLAGS: %u\n", mnl_attr_get_u32(attr));
+        break;
+    case WGDEVICE_A_LISTEN_PORT:
+        printf("WGDEVICE_A_LISTEN_PORT: %u\n", mnl_attr_get_u16(attr));
+        break;
+    case WGDEVICE_A_FWMARK:
+        printf("WGDEVICE_A_FWMARK: %u\n", mnl_attr_get_u32(attr));
+        break;
+    case WGDEVICE_A_PEERS:
+        printf("WGDEVICE_A_PEERS (Nested Attributes):\n");
+        print_device_peers(attr);
+        break;
+    case WGDEVICE_A_TRANSPORT:
+        printf("WGDEVICE_A_TRANSPORT: %u\n", mnl_attr_get_u8(attr));
+        break;
+    default:
+        printf("Unknown Device Attribute Type: %d\n", type);
+        break;
+    }
+}
+
+static void print_netlink_message_verbose(const struct nlmsghdr *nlh)
+{
+    struct nlattr *attr;
+    int rem = 0;
+
+    printf("Verbose Netlink Message:\n");
+    printf("  nlmsg_len: %u\n", nlh->nlmsg_len);
+    printf("  nlmsg_type: %u\n", nlh->nlmsg_type);
+    
+    // Print command
+    switch (nlh->nlmsg_type) {
+    case WG_CMD_GET_DEVICE:
+        printf("  Command: WG_CMD_GET_DEVICE\n");
+        break;
+    case WG_CMD_SET_DEVICE:
+        printf("  Command: WG_CMD_SET_DEVICE\n");
+        break;
+    default:
+        printf("  Unknown Command: %u\n", nlh->nlmsg_type);
+        break;
+    }
+
+    print_flags_verbose(nlh->nlmsg_flags);
+    printf("  nlmsg_seq: %u\n", nlh->nlmsg_seq);
+    printf("  nlmsg_pid: %u\n", nlh->nlmsg_pid);
+    printf("Attributes:\n");
+
+    mnl_attr_for_each(attr, nlh, rem) {
+        switch (nlh->nlmsg_type) {
+        case WG_CMD_GET_DEVICE:
+        case WG_CMD_SET_DEVICE:
+            print_device_attr(attr);
+            break;
+        default:
+            printf("Unknown Netlink Message Type: %u\n", nlh->nlmsg_type);
+            break;
+        }
+    }
+
+    printf("Hex Dump of Netlink Message:\n");
+    hex_dump(nlh, nlh->nlmsg_len);
+}
+
+// Function to print the libmnl formatted netlink message header
+static void print_netlink_header_libmnl(const struct nlmsghdr *nlh)
+{
+    printf("----------------\t------------------\n");
+    printf("|  %.010u  |\t| message length |\n", nlh->nlmsg_len);
+    printf("| %.05u | %c%c%c%c |\t|  type | flags  |\n",
+        nlh->nlmsg_type,
+        nlh->nlmsg_flags & NLM_F_REQUEST ? 'R' : '-',
+        nlh->nlmsg_flags & NLM_F_MULTI ? 'M' : '-',
+        nlh->nlmsg_flags & NLM_F_ACK ? 'A' : '-',
+        nlh->nlmsg_flags & NLM_F_ECHO ? 'E' : '-');
+    printf("|  %.010u  |\t| sequence number|\n", nlh->nlmsg_seq);
+    printf("|  %.010u  |\t|     port ID    |\n", nlh->nlmsg_pid);
+    printf("----------------\t------------------\n");
+}
+
+// Function to print the libmnl formatted netlink message payload
+static void print_netlink_payload_libmnl(const struct nlmsghdr *nlh, size_t extra_header_size)
+{
+    unsigned int i;
+    int rem = 0;
+
+    for (i = sizeof(struct nlmsghdr); i < nlh->nlmsg_len; i += 4) {
+        char *b = (char *)nlh;
+        struct nlattr *attr = (struct nlattr *)(b + i);
+
+        if (nlh->nlmsg_type < NLMSG_MIN_TYPE) {
+            printf("| %.2x %.2x %.2x %.2x  |\t",
+                   0xff & b[i], 0xff & b[i + 1],
+                   0xff & b[i + 2], 0xff & b[i + 3]);
+            printf("|                |\n");
+        } else if (extra_header_size > 0) {
+            extra_header_size -= 4;
+            printf("| %.2x %.2x %.2x %.2x  |\t",
+                   0xff & b[i], 0xff & b[i + 1],
+                   0xff & b[i + 2], 0xff & b[i + 3]);
+            printf("|  extra header  |\n");
+        } else if (rem == 0 && (attr->nla_type & NLA_TYPE_MASK) != 0) {
+            printf("|%.5u|%c%c|%.5u|\t",
+                   attr->nla_len,
+                   attr->nla_type & NLA_F_NESTED ? 'N' : '-',
+                   attr->nla_type & NLA_F_NET_BYTEORDER ? 'B' : '-',
+                   attr->nla_type & NLA_TYPE_MASK);
+            printf("|len |flags| type|\n");
+
+            if (!(attr->nla_type & NLA_F_NESTED)) {
+                rem = NLA_ALIGN(attr->nla_len) -
+                      sizeof(struct nlattr);
+            }
+        } else if (rem > 0) {
+            rem -= 4;
+            printf("| %.2x %.2x %.2x %.2x  |\t",
+                   0xff & b[i], 0xff & b[i + 1],
+                   0xff & b[i + 2], 0xff & b[i + 3]);
+            printf("|      data      |");
+            printf("\t %c %c %c %c\n",
+                   isprint(b[i]) ? b[i] : ' ',
+                   isprint(b[i + 1]) ? b[i + 1] : ' ',
+                   isprint(b[i + 2]) ? b[i + 2] : ' ',
+                   isprint(b[i + 3]) ? b[i + 3] : ' ');
+        }
+    }
+    printf("----------------\t------------------\n");
+}
+
+// Print the netlink message using libmnl format
+static void print_netlink_message_libmnl(const struct nlmsghdr *nlh)
+{
+    print_netlink_header_libmnl(nlh);
+    print_netlink_payload_libmnl(nlh, 0);
+}
+
+// Add a function to print the entire buffer of netlink messages
+static void print_netlink_buffer(const void *buf, size_t len)
+{
+    const struct nlmsghdr *nlh = buf;
+
+    while (mnl_nlmsg_ok(nlh, len)) {
+        print_netlink_message_verbose(nlh);
+        print_netlink_message_libmnl(nlh);
+        nlh = mnl_nlmsg_next(nlh, (int *)&len);
+    }
+}
 static int parse_linkinfo(const struct nlattr *attr, void *data)
 {
 	struct interface *interface = data;
 
+	print_device_attr(attr);
 	if (mnl_attr_get_type(attr) == IFLA_INFO_KIND && !strcmp(WG_GENL_NAME, mnl_attr_get_str(attr)))
 		interface->is_wireguard = true;
 	return MNL_CB_OK;
@@ -45,6 +348,7 @@ static int parse_infomsg(const struct nlattr *attr, void *data)
 {
 	struct interface *interface = data;
 
+	print_device_attr(attr);
 	if (mnl_attr_get_type(attr) == IFLA_LINKINFO)
 		return mnl_attr_parse_nested(attr, parse_linkinfo, data);
 	else if (mnl_attr_get_type(attr) == IFLA_IFNAME)
@@ -58,6 +362,7 @@ static int read_devices_cb(const struct nlmsghdr *nlh, void *data)
 	struct interface interface = { 0 };
 	int ret;
 
+	printf("Entering read_devices_cb\n");
 	ret = mnl_attr_parse(nlh, sizeof(struct ifinfomsg), parse_infomsg, &interface);
 	if (ret != MNL_CB_OK)
 		return ret;
@@ -67,6 +372,7 @@ static int read_devices_cb(const struct nlmsghdr *nlh, void *data)
 		return ret;
 	if (nlh->nlmsg_type != NLMSG_DONE)
 		return MNL_CB_OK + 1;
+	printf("Exiting read_devices_cb\n");
 	return MNL_CB_OK;
 }
 
@@ -81,6 +387,7 @@ static int kernel_get_wireguard_interfaces(struct string_list *list)
 	struct nlmsghdr *nlh;
 	struct ifinfomsg *ifm;
 
+	printf("Entering kernel_get_wireguard_interfaces\n");
 	ret = -ENOMEM;
 	rtnl_buffer = calloc(SOCKET_BUFFER_SIZE, 1);
 	if (!rtnl_buffer)
@@ -136,6 +443,7 @@ cleanup:
 	free(rtnl_buffer);
 	if (nl)
 		mnl_socket_close(nl);
+	printf("Exiting kernel_get_wireguard_interfaces\n");
 	return ret;
 }
 
@@ -148,6 +456,7 @@ static int kernel_set_device(struct wgdevice *dev)
 	struct nlmsghdr *nlh;
 	struct mnlg_socket *nlg;
 
+	printf("Entering kernel_set_device\n");
 	nlg = mnlg_socket_open(WG_GENL_NAME, WG_GENL_VERSION);
 	if (!nlg)
 		return -errno;
@@ -167,6 +476,8 @@ again:
 			mnl_attr_put_u32(nlh, WGDEVICE_A_FWMARK, dev->fwmark);
 		if (dev->flags & WGDEVICE_REPLACE_PEERS)
 			flags |= WGDEVICE_F_REPLACE_PEERS;
+		if (dev->flags & WGDEVICE_HAS_TRANSPORT)
+			mnl_attr_put_u8(nlh, WGDEVICE_A_TRANSPORT, dev->transport);
 		if (flags)
 			mnl_attr_put_u32(nlh, WGDEVICE_A_FLAGS, flags);
 	}
@@ -255,6 +566,11 @@ toobig_peers:
 	mnl_attr_nest_end(nlh, peers_nest);
 	goto send;
 send:
+
+	// Print the netlink message before sending it
+	print_netlink_message_verbose(nlh);
+	print_netlink_message_libmnl(nlh);
+
 	if (mnlg_socket_send(nlg, nlh) < 0) {
 		ret = -errno;
 		goto out;
@@ -270,6 +586,7 @@ send:
 out:
 	mnlg_socket_close(nlg);
 	errno = -ret;
+	printf("Exiting kernel_set_device\n");
 	return ret;
 }
 
@@ -277,6 +594,7 @@ static int parse_allowedip(const struct nlattr *attr, void *data)
 {
 	struct wgallowedip *allowedip = data;
 
+	print_allowedip_attr(attr);
 	switch (mnl_attr_get_type(attr)) {
 	case WGALLOWEDIP_A_UNSPEC:
 		break;
@@ -305,6 +623,7 @@ static int parse_allowedips(const struct nlattr *attr, void *data)
 	struct wgallowedip *new_allowedip = calloc(1, sizeof(*new_allowedip));
 	int ret;
 
+	printf("Entering parse_allowedips\n");
 	if (!new_allowedip) {
 		perror("calloc");
 		return MNL_CB_ERROR;
@@ -320,6 +639,7 @@ static int parse_allowedips(const struct nlattr *attr, void *data)
 		return ret;
 	if (!((new_allowedip->family == AF_INET && new_allowedip->cidr <= 32) || (new_allowedip->family == AF_INET6 && new_allowedip->cidr <= 128)))
 		return MNL_CB_ERROR;
+	printf("Exiting parse_allowedips\n");
 	return MNL_CB_OK;
 }
 
@@ -327,6 +647,7 @@ static int parse_peer(const struct nlattr *attr, void *data)
 {
 	struct wgpeer *peer = data;
 
+	print_peer_attr(attr);
 	switch (mnl_attr_get_type(attr)) {
 	case WGPEER_A_UNSPEC:
 		break;
@@ -373,6 +694,7 @@ static int parse_peer(const struct nlattr *attr, void *data)
 		break;
 	case WGPEER_A_ALLOWEDIPS:
 		return mnl_attr_parse_nested(attr, parse_allowedips, peer);
+		break;
 	}
 
 	return MNL_CB_OK;
@@ -384,6 +706,7 @@ static int parse_peers(const struct nlattr *attr, void *data)
 	struct wgpeer *new_peer = calloc(1, sizeof(*new_peer));
 	int ret;
 
+	printf("Entering parse_peers\n");
 	if (!new_peer) {
 		perror("calloc");
 		return MNL_CB_ERROR;
@@ -399,6 +722,7 @@ static int parse_peers(const struct nlattr *attr, void *data)
 		return ret;
 	if (!(new_peer->flags & WGPEER_HAS_PUBLIC_KEY))
 		return MNL_CB_ERROR;
+	printf("Exiting parse_peers\n");
 	return MNL_CB_OK;
 }
 
@@ -406,6 +730,7 @@ static int parse_device(const struct nlattr *attr, void *data)
 {
 	struct wgdevice *device = data;
 
+	print_device_attr(attr);
 	switch (mnl_attr_get_type(attr)) {
 	case WGDEVICE_A_UNSPEC:
 		break;
@@ -439,6 +764,10 @@ static int parse_device(const struct nlattr *attr, void *data)
 		if (!mnl_attr_validate(attr, MNL_TYPE_U32))
 			device->fwmark = mnl_attr_get_u32(attr);
 		break;
+	case WGDEVICE_A_TRANSPORT:
+		if (!mnl_attr_validate(attr, MNL_TYPE_U8))
+			device->transport = mnl_attr_get_u8(attr);
+		break;
 	case WGDEVICE_A_PEERS:
 		return mnl_attr_parse_nested(attr, parse_peers, device);
 	}
@@ -448,13 +777,17 @@ static int parse_device(const struct nlattr *attr, void *data)
 
 static int read_device_cb(const struct nlmsghdr *nlh, void *data)
 {
-	return mnl_attr_parse(nlh, sizeof(struct genlmsghdr), parse_device, data);
+	printf("Entering read_device_cb\n");
+	int ret = mnl_attr_parse(nlh, sizeof(struct genlmsghdr), parse_device, data);
+	printf("Exiting read_device_cb\n");
+	return ret;
 }
 
 static void coalesce_peers(struct wgdevice *device)
 {
 	struct wgpeer *old_next_peer, *peer = device->first_peer;
 
+	printf("Entering coalesce_peers\n");
 	while (peer && peer->next_peer) {
 		if (memcmp(peer->public_key, peer->next_peer->public_key, sizeof(peer->public_key))) {
 			peer = peer->next_peer;
@@ -471,6 +804,7 @@ static void coalesce_peers(struct wgdevice *device)
 		peer->next_peer = old_next_peer->next_peer;
 		free(old_next_peer);
 	}
+	printf("Exiting coalesce_peers\n");
 }
 
 static int kernel_get_device(struct wgdevice **device, const char *iface)
@@ -521,5 +855,6 @@ out:
 		*device = NULL;
 	}
 	errno = -ret;
+	printf("Exiting kernel_get_device\n");
 	return ret;
 }
diff --git a/wireguard-tools/src/ipc-uapi-unix.h b/wireguard-tools/src/ipc-uapi-unix.h
index aaf60ca69af9..367141a16110 100644
--- a/wireguard-tools/src/ipc-uapi-unix.h
+++ b/wireguard-tools/src/ipc-uapi-unix.h
@@ -14,6 +14,7 @@
 #include <sys/stat.h>
 #include <sys/un.h>
 
+#define RUNSTATEDIR "/var/run" // Define RUNSTATEDIR here --dr to fix build wierdness XXX
 #define SOCK_PATH RUNSTATEDIR "/wireguard/"
 #define SOCK_SUFFIX ".sock"
 
diff --git a/wireguard-tools/src/ipc.c b/wireguard-tools/src/ipc.c
index 1155bd569913..edad5d5a7d1b 100644
--- a/wireguard-tools/src/ipc.c
+++ b/wireguard-tools/src/ipc.c
@@ -6,6 +6,7 @@
 #include <string.h>
 #include <stdlib.h>
 #include <errno.h>
+#include <stdio.h>
 #include "containers.h"
 #include "ipc.h"
 
@@ -15,28 +16,49 @@ struct string_list {
 	size_t cap;
 };
 
+#ifdef DEBUG
+#define DEBUG_PRINT(fmt, args...) fprintf(stderr, fmt, ##args)
+#else
+#define DEBUG_PRINT(fmt, args...) /* Don't do anything in release builds */
+#endif
+
 static int string_list_add(struct string_list *list, const char *str)
 {
+	DEBUG_PRINT("Entering string_list_add\n");
+	
 	size_t len = strlen(str) + 1;
+	DEBUG_PRINT("string_list_add: Adding string '%s' of length %zu\n", str, len);
 
-	if (len == 1)
+	if (len == 1) {
+		DEBUG_PRINT("Exiting string_list_add\n");
 		return 0;
+	}
 
 	if (len >= list->cap - list->len) {
 		char *new_buffer;
 		size_t new_cap = list->cap * 2;
 
+		DEBUG_PRINT("string_list_add: Current capacity %zu is not enough for new string, resizing...\n", list->cap);
+
 		if (new_cap < list->len + len + 1)
 			new_cap = list->len + len + 1;
+
+		DEBUG_PRINT("string_list_add: New capacity will be %zu\n", new_cap);
 		new_buffer = realloc(list->buffer, new_cap);
-		if (!new_buffer)
+		if (!new_buffer) {
+			DEBUG_PRINT("string_list_add: Memory allocation failed: %s\n", strerror(errno));
+			DEBUG_PRINT("Exiting string_list_add\n");
 			return -errno;
+		}
 		list->buffer = new_buffer;
 		list->cap = new_cap;
 	}
 	memcpy(list->buffer + list->len, str, len);
 	list->len += len;
 	list->buffer[list->len] = '\0';
+
+	DEBUG_PRINT("string_list_add: String added. New length is %zu\n", list->len);
+	DEBUG_PRINT("Exiting string_list_add\n");
 	return 0;
 }
 
@@ -54,45 +76,74 @@ static int string_list_add(struct string_list *list, const char *str)
 /* first\0second\0third\0forth\0last\0\0 */
 char *ipc_list_devices(void)
 {
+	DEBUG_PRINT("Entering ipc_list_devices\n");
+
 	struct string_list list = { 0 };
 	int ret;
 
+	DEBUG_PRINT("ipc_list_devices: Listing devices...\n");
+
 #ifdef IPC_SUPPORTS_KERNEL_INTERFACE
 	ret = kernel_get_wireguard_interfaces(&list);
-	if (ret < 0)
+	if (ret < 0) {
+		DEBUG_PRINT("ipc_list_devices: Failed to get kernel interfaces: %d\n", ret);
 		goto cleanup;
+	}
 #endif
 	ret = userspace_get_wireguard_interfaces(&list);
-	if (ret < 0)
+	if (ret < 0) {
+		DEBUG_PRINT("ipc_list_devices: Failed to get userspace interfaces: %d\n", ret);
 		goto cleanup;
+	}
 
 cleanup:
 	errno = -ret;
 	if (errno) {
+		DEBUG_PRINT("ipc_list_devices: Error occurred: %s\n", strerror(errno));
 		free(list.buffer);
+		DEBUG_PRINT("Exiting ipc_list_devices\n");
 		return NULL;
 	}
+	DEBUG_PRINT("Exiting ipc_list_devices\n");
 	return list.buffer ?: strdup("\0");
 }
 
 int ipc_get_device(struct wgdevice **dev, const char *iface)
 {
+	DEBUG_PRINT("Entering ipc_get_device\n");
+	DEBUG_PRINT("ipc_get_device: Getting device for interface '%s'\n", iface);
+
 #ifdef IPC_SUPPORTS_KERNEL_INTERFACE
-	if (userspace_has_wireguard_interface(iface))
+	if (userspace_has_wireguard_interface(iface)) {
+		DEBUG_PRINT("ipc_get_device: Interface '%s' found in userspace\n", iface);
+		DEBUG_PRINT("Exiting ipc_get_device\n");
 		return userspace_get_device(dev, iface);
+	}
+	DEBUG_PRINT("ipc_get_device: Interface '%s' found in kernel space\n", iface);
+	DEBUG_PRINT("Exiting ipc_get_device\n");
 	return kernel_get_device(dev, iface);
 #else
+	DEBUG_PRINT("Exiting ipc_get_device\n");
 	return userspace_get_device(dev, iface);
 #endif
 }
 
 int ipc_set_device(struct wgdevice *dev)
 {
+	DEBUG_PRINT("Entering ipc_set_device\n");
+	DEBUG_PRINT("ipc_set_device: Setting device '%s'\n", dev->name);
+
 #ifdef IPC_SUPPORTS_KERNEL_INTERFACE
-	if (userspace_has_wireguard_interface(dev->name))
+	if (userspace_has_wireguard_interface(dev->name)) {
+		DEBUG_PRINT("ipc_set_device: Interface '%s' found in userspace\n", dev->name);
+		DEBUG_PRINT("Exiting ipc_set_device\n");
 		return userspace_set_device(dev);
+	}
+	DEBUG_PRINT("ipc_set_device: Interface '%s' found in kernel space\n", dev->name);
+	DEBUG_PRINT("Exiting ipc_set_device\n");
 	return kernel_set_device(dev);
 #else
+	DEBUG_PRINT("Exiting ipc_set_device\n");
 	return userspace_set_device(dev);
 #endif
 }
diff --git a/wireguard-tools/src/netlink.h b/wireguard-tools/src/netlink.h
index f9729ee280f1..b7348a5740d0 100644
--- a/wireguard-tools/src/netlink.h
+++ b/wireguard-tools/src/netlink.h
@@ -318,6 +318,11 @@ static void mnl_attr_put(struct nlmsghdr *nlh, uint16_t type, size_t len,
 		memset(mnl_attr_get_payload(attr) + len, 0, pad);
 }
 
+static void mnl_attr_put_u8(struct nlmsghdr *nlh, uint8_t type, uint8_t data)
+{
+	mnl_attr_put(nlh, type, sizeof(uint8_t), &data);
+}
+
 static void mnl_attr_put_u16(struct nlmsghdr *nlh, uint16_t type, uint16_t data)
 {
 	mnl_attr_put(nlh, type, sizeof(uint16_t), &data);
diff --git a/wireguard-tools/src/set.c b/wireguard-tools/src/set.c
index 75560fd8cf62..34544e6de068 100644
--- a/wireguard-tools/src/set.c
+++ b/wireguard-tools/src/set.c
@@ -12,30 +12,50 @@
 #include "ipc.h"
 #include "subcommands.h"
 
+#ifdef DEBUG
+#define DEBUG_PRINT(fmt, args...) fprintf(stderr, fmt, ##args)
+#else
+#define DEBUG_PRINT(fmt, args...) /* Don't do anything in release builds */
+#endif
+
 int set_main(int argc, const char *argv[])
 {
 	struct wgdevice *device = NULL;
 	int ret = 1;
 
+	DEBUG_PRINT("Entering set_main with argc=%d\n", argc);
+	for (int i = 0; i < argc; ++i) {
+		DEBUG_PRINT("argv[%d]: %s\n", i, argv[i]);
+	}
+
 	if (argc < 3) {
-		fprintf(stderr, "Usage: %s %s <interface> [listen-port <port>] [fwmark <mark>] [private-key <file path>] [peer <base64 public key> [remove] [preshared-key <file path>] [endpoint <ip>:<port>] [persistent-keepalive <interval seconds>] [allowed-ips <ip1>/<cidr1>[,<ip2>/<cidr2>]...] ]...\n", PROG_NAME, argv[0]);
+		fprintf(stderr, "Usage: %s %s <interface> [listen-port <port>] [fwmark <mark>] [private-key <file path>] [peer <base64 public key> [remove] [preshared-key <file path>] [endpoint <ip>:<port>] [persistent-keepalive <interval seconds>] [allowed-ips <ip1>/<cidr1>[,<ip2>/<cidr2>]...] [transport tcp/udp]...\n", PROG_NAME, argv[0]);
+		DEBUG_PRINT("Exiting set_main with ret=1 (argc < 3)\n");
 		return 1;
 	}
 
 	device = config_read_cmd(argv + 2, argc - 2);
-	if (!device)
+	if (!device) {
+		DEBUG_PRINT("config_read_cmd returned NULL\n");
 		goto cleanup;
-	strncpy(device->name, argv[1], IFNAMSIZ -  1);
+	}
+	DEBUG_PRINT("config_read_cmd succeeded\n");
+
+	strncpy(device->name, argv[1], IFNAMSIZ - 1);
 	device->name[IFNAMSIZ - 1] = '\0';
+	DEBUG_PRINT("Device name set to %s\n", device->name);
 
 	if (ipc_set_device(device) != 0) {
 		perror("Unable to modify interface");
+		DEBUG_PRINT("ipc_set_device failed\n");
 		goto cleanup;
 	}
+	DEBUG_PRINT("ipc_set_device succeeded\n");
 
 	ret = 0;
 
-cleanup:
+	cleanup:
 	free_wgdevice(device);
+	DEBUG_PRINT("Exiting set_main with ret=%d\n", ret);
 	return ret;
 }
diff --git a/wireguard-tools/src/setconf.c b/wireguard-tools/src/setconf.c
index 1c5b13876ff6..4dc261db4c54 100644
--- a/wireguard-tools/src/setconf.c
+++ b/wireguard-tools/src/setconf.c
@@ -13,6 +13,12 @@
 #include "ipc.h"
 #include "subcommands.h"
 
+#ifdef DEBUG
+#define DEBUG_PRINT(fmt, args...) fprintf(stderr, fmt, ##args)
+#else
+#define DEBUG_PRINT(fmt, args...) /* Don't do anything in release builds */
+#endif
+
 struct pubkey_origin {
 	uint8_t *pubkey;
 	bool from_file;
@@ -22,6 +28,7 @@ static int pubkey_cmp(const void *first, const void *second)
 {
 	const struct pubkey_origin *a = first, *b = second;
 	int ret = memcmp(a->pubkey, b->pubkey, WG_KEY_LEN);
+	DEBUG_PRINT("pubkey_cmp: ret=%d\n", ret);
 	if (ret)
 		return ret;
 	return a->from_file - b->from_file;
@@ -29,17 +36,23 @@ static int pubkey_cmp(const void *first, const void *second)
 
 static bool sync_conf(struct wgdevice *file)
 {
+	DEBUG_PRINT("Entering sync_conf\n");
+
 	struct wgdevice *runtime;
 	struct wgpeer *peer;
 	struct pubkey_origin *pubkeys;
 	size_t peer_count = 0, i = 0;
 
-	if (!file->first_peer)
+	if (!file->first_peer) {
+		DEBUG_PRINT("sync_conf: file->first_peer is NULL\n");
 		return true;
+	}
 
 	for_each_wgpeer(file, peer)
 		++peer_count;
 
+	DEBUG_PRINT("sync_conf: peer_count after file iteration=%zu\n", peer_count);
+
 	if (ipc_get_device(&runtime, file->name) != 0) {
 		perror("Unable to retrieve current interface configuration");
 		return false;
@@ -55,6 +68,8 @@ static bool sync_conf(struct wgdevice *file)
 	for_each_wgpeer(runtime, peer)
 		++peer_count;
 
+	DEBUG_PRINT("sync_conf: peer_count after runtime iteration=%zu\n", peer_count);
+
 	pubkeys = calloc(peer_count, sizeof(*pubkeys));
 	if (!pubkeys) {
 		free_wgdevice(runtime);
@@ -65,18 +80,20 @@ static bool sync_conf(struct wgdevice *file)
 	for_each_wgpeer(file, peer) {
 		pubkeys[i].pubkey = peer->public_key;
 		pubkeys[i].from_file = true;
+		DEBUG_PRINT("sync_conf: added pubkey from file at index %zu\n", i);
 		++i;
 	}
 	for_each_wgpeer(runtime, peer) {
 		pubkeys[i].pubkey = peer->public_key;
 		pubkeys[i].from_file = false;
+		DEBUG_PRINT("sync_conf: added pubkey from runtime at index %zu\n", i);
 		++i;
 	}
 	qsort(pubkeys, peer_count, sizeof(*pubkeys), pubkey_cmp);
 
 	for (i = 0; i < peer_count; ++i) {
 		if (pubkeys[i].from_file)
-			continue;
+		continue;
 		if (i == peer_count - 1 || !pubkeys[i + 1].from_file || memcmp(pubkeys[i].pubkey, pubkeys[i + 1].pubkey, WG_KEY_LEN)) {
 			peer = calloc(1, sizeof(struct wgpeer));
 			if (!peer) {
@@ -91,15 +108,19 @@ static bool sync_conf(struct wgdevice *file)
 			file->first_peer = peer;
 			if (!file->last_peer)
 				file->last_peer = peer;
+			DEBUG_PRINT("sync_conf: added peer to file with public_key=%p\n", pubkeys[i].pubkey);
 		}
 	}
 	free_wgdevice(runtime);
 	free(pubkeys);
+	DEBUG_PRINT("Exiting sync_conf\n");
 	return true;
 }
 
 int setconf_main(int argc, const char *argv[])
 {
+	DEBUG_PRINT("Entering setconf_main: argc=%d, argv[1]=%s, argv[2]=%s\n", argc, argv[1], argv[2]);
+
 	struct wgdevice *device = NULL;
 	struct config_ctx ctx;
 	FILE *config_input = NULL;
@@ -135,9 +156,11 @@ int setconf_main(int argc, const char *argv[])
 	strncpy(device->name, argv[1], IFNAMSIZ - 1);
 	device->name[IFNAMSIZ - 1] = '\0';
 
+	DEBUG_PRINT("setconf_main: device->name=%s\n", device->name);
+
 	if (!strcmp(argv[0], "syncconf")) {
 		if (!sync_conf(device))
-			goto cleanup;
+		goto cleanup;
 	}
 
 	if (ipc_set_device(device) != 0) {
@@ -152,5 +175,7 @@ cleanup:
 		fclose(config_input);
 	free(config_buffer);
 	free_wgdevice(device);
+
+	DEBUG_PRINT("Exiting setconf_main: ret=%d\n", ret);
 	return ret;
 }
diff --git a/wireguard-tools/src/show.c b/wireguard-tools/src/show.c
index 13777cf04280..4677bf5ccad9 100644
--- a/wireguard-tools/src/show.c
+++ b/wireguard-tools/src/show.c
@@ -24,11 +24,19 @@
 #include "encoding.h"
 #include "subcommands.h"
 
+#ifdef DEBUG
+#define DEBUG_PRINT(fmt, args...) fprintf(stderr, fmt, ##args)
+#else
+#define DEBUG_PRINT(fmt, args...) /* Don't do anything in release builds */
+#endif
+
 static int peer_cmp(const void *first, const void *second)
 {
 	time_t diff;
 	const struct wgpeer *a = *(void *const *)first, *b = *(void *const *)second;
 
+	DEBUG_PRINT("Entering peer_cmp\n");
+
 	if (!a->last_handshake_time.tv_sec && !a->last_handshake_time.tv_nsec && (b->last_handshake_time.tv_sec || b->last_handshake_time.tv_nsec))
 		return 1;
 	if (!b->last_handshake_time.tv_sec && !b->last_handshake_time.tv_nsec && (a->last_handshake_time.tv_sec || a->last_handshake_time.tv_nsec))
@@ -40,6 +48,7 @@ static int peer_cmp(const void *first, const void *second)
 		return 1;
 	if (diff > 0)
 		return -1;
+	DEBUG_PRINT("Exiting peer_cmp\n");
 	return 0;
 }
 
@@ -49,13 +58,22 @@ static void sort_peers(struct wgdevice *device)
 	size_t peer_count = 0, i = 0;
 	struct wgpeer *peer, **peers;
 
+	DEBUG_PRINT("Entering sort_peers\n");
+
 	for_each_wgpeer(device, peer)
 		++peer_count;
-	if (!peer_count)
+
+	DEBUG_PRINT("Peer count: %zu\n", peer_count);
+
+	if (!peer_count) {
+		DEBUG_PRINT("Exiting sort_peers - no peers\n");
 		return;
+	}
 	peers = calloc(peer_count, sizeof(*peers));
-	if (!peers)
+	if (!peers) {
+		DEBUG_PRINT("Exiting sort_peers - calloc failed\n");
 		return;
+	}
 	for_each_wgpeer(device, peer)
 		peers[i++] = peer;
 	qsort(peers, peer_count, sizeof(*peers), peer_cmp);
@@ -65,29 +83,38 @@ static void sort_peers(struct wgdevice *device)
 	}
 	peers[peer_count - 1]->next_peer = NULL;
 	free(peers);
+	DEBUG_PRINT("Exiting sort_peers\n");
 }
 
 static char *key(const uint8_t key[static WG_KEY_LEN])
 {
 	static char base64[WG_KEY_LEN_BASE64];
-
+	DEBUG_PRINT("Entering key\n");
 	key_to_base64(base64, key);
+	DEBUG_PRINT("Exiting key\n");
 	return base64;
 }
 
 static const char *maybe_key(const uint8_t maybe_key[static WG_KEY_LEN], bool have_it)
 {
-	if (!have_it)
+	DEBUG_PRINT("Entering maybe_key\n");
+	if (!have_it) {
+		DEBUG_PRINT("Exiting maybe_key - no key\n");
 		return "(none)";
+	}
+	DEBUG_PRINT("Exiting maybe_key\n");
 	return key(maybe_key);
 }
 
 static const char *masked_key(const uint8_t masked_key[static WG_KEY_LEN])
 {
 	const char *var = getenv("WG_HIDE_KEYS");
-
-	if (var && !strcmp(var, "never"))
+	DEBUG_PRINT("Entering masked_key\n");
+	if (var && !strcmp(var, "never")) {
+		DEBUG_PRINT("Exiting masked_key - key shown\n");
 		return key(masked_key);
+	}
+	DEBUG_PRINT("Exiting masked_key - key hidden\n");
 	return "(hidden)";
 }
 
@@ -95,11 +122,15 @@ static char *ip(const struct wgallowedip *ip)
 {
 	static char buf[INET6_ADDRSTRLEN + 1];
 
+	DEBUG_PRINT("Entering ip\n");
+
 	memset(buf, 0, INET6_ADDRSTRLEN + 1);
 	if (ip->family == AF_INET)
 		inet_ntop(AF_INET, &ip->ip4, buf, INET6_ADDRSTRLEN);
 	else if (ip->family == AF_INET6)
 		inet_ntop(AF_INET6, &ip->ip6, buf, INET6_ADDRSTRLEN);
+
+	DEBUG_PRINT("Exiting ip\n");
 	return buf;
 }
 
@@ -111,6 +142,8 @@ static char *endpoint(const struct sockaddr *addr)
 	int ret;
 	socklen_t addr_len = 0;
 
+	DEBUG_PRINT("Entering endpoint\n");
+
 	memset(buf, 0, sizeof(buf));
 	if (addr->sa_family == AF_INET)
 		addr_len = sizeof(struct sockaddr_in);
@@ -121,16 +154,35 @@ static char *endpoint(const struct sockaddr *addr)
 	if (ret) {
 		strncpy(buf, gai_strerror(ret), sizeof(buf) - 1);
 		buf[sizeof(buf) - 1] = '\0';
+		DEBUG_PRINT("Exiting endpoint - getnameinfo failed: %s\n", buf);
 	} else
 		snprintf(buf, sizeof(buf), (addr->sa_family == AF_INET6 && strchr(host, ':')) ? "[%s]:%s" : "%s:%s", host, service);
+
+	DEBUG_PRINT("Exiting endpoint\n");
 	return buf;
 }
 
+static char *transport(const uint32_t transport_val)
+{
+	DEBUG_PRINT("Entering transport\n");
+	if (transport_val == WG_TRANSPORT_UDP) {
+		DEBUG_PRINT("Exiting transport - udp\n");
+		return "udp";
+	} else if (transport_val == WG_TRANSPORT_TCP) {
+		DEBUG_PRINT("Exiting transport - tcp\n");
+		return "tcp";
+	}
+	DEBUG_PRINT("Exiting transport - unknown\n");
+	return "unknown";
+}
+
 static size_t pretty_time(char *buf, const size_t len, unsigned long long left)
 {
 	size_t offset = 0;
 	unsigned long long years, days, hours, minutes, seconds;
 
+	DEBUG_PRINT("Entering pretty_time\n");
+
 	years = left / (365 * 24 * 60 * 60);
 	left = left % (365 * 24 * 60 * 60);
 	days = left / (24 * 60 * 60);
@@ -151,6 +203,7 @@ static size_t pretty_time(char *buf, const size_t len, unsigned long long left)
 	if (seconds)
 		offset += snprintf(buf + offset, len - offset, "%s%llu " TERMINAL_FG_CYAN  "second%s" TERMINAL_RESET, offset ? ", " : "", seconds, seconds == 1 ? "" : "s");
 
+	DEBUG_PRINT("Exiting pretty_time\n");
 	return offset;
 }
 
@@ -160,6 +213,8 @@ static char *ago(const struct timespec64 *t)
 	size_t offset;
 	time_t now = time(NULL);
 
+	DEBUG_PRINT("Entering ago\n");
+
 	if (now == t->tv_sec)
 		strncpy(buf, "Now", sizeof(buf) - 1);
 	else if (now < t->tv_sec)
@@ -170,6 +225,7 @@ static char *ago(const struct timespec64 *t)
 	}
 	buf[sizeof(buf) - 1] = '\0';
 
+	DEBUG_PRINT("Exiting ago\n");
 	return buf;
 }
 
@@ -177,7 +233,11 @@ static char *every(uint16_t seconds)
 {
 	static char buf[1024] = "every ";
 
+	DEBUG_PRINT("Entering every\n");
+
 	pretty_time(buf + strlen("every "), sizeof(buf) - strlen("every ") - 1, seconds);
+
+	DEBUG_PRINT("Exiting every\n");
 	return buf;
 }
 
@@ -185,6 +245,8 @@ static char *bytes(uint64_t b)
 {
 	static char buf[1024];
 
+	DEBUG_PRINT("Entering bytes\n");
+
 	if (b < 1024ULL)
 		snprintf(buf, sizeof(buf), "%u " TERMINAL_FG_CYAN "B" TERMINAL_RESET, (unsigned int)b);
 	else if (b < 1024ULL * 1024ULL)
@@ -196,13 +258,16 @@ static char *bytes(uint64_t b)
 	else
 		snprintf(buf, sizeof(buf), "%.2f " TERMINAL_FG_CYAN "TiB" TERMINAL_RESET, (double)b / (1024 * 1024 * 1024) / 1024);
 
+	DEBUG_PRINT("Exiting bytes\n");
 	return buf;
 }
 
 static const char *COMMAND_NAME;
 static void show_usage(void)
 {
+	DEBUG_PRINT("Entering show_usage\n");
 	fprintf(stderr, "Usage: %s %s { <interface> | all | interfaces } [public-key | private-key | listen-port | fwmark | peers | preshared-keys | endpoints | allowed-ips | latest-handshakes | transfer | persistent-keepalive | dump]\n", PROG_NAME, COMMAND_NAME);
+	DEBUG_PRINT("Exiting show_usage\n");
 }
 
 static void pretty_print(struct wgdevice *device)
@@ -210,6 +275,8 @@ static void pretty_print(struct wgdevice *device)
 	struct wgpeer *peer;
 	struct wgallowedip *allowedip;
 
+	DEBUG_PRINT("Entering pretty_print\n");
+
 	terminal_printf(TERMINAL_RESET);
 	terminal_printf(TERMINAL_FG_GREEN TERMINAL_BOLD "interface" TERMINAL_RESET ": " TERMINAL_FG_GREEN "%s" TERMINAL_RESET "\n", device->name);
 	if (device->flags & WGDEVICE_HAS_PUBLIC_KEY)
@@ -220,6 +287,7 @@ static void pretty_print(struct wgdevice *device)
 		terminal_printf("  " TERMINAL_BOLD "listening port" TERMINAL_RESET ": %u\n", device->listen_port);
 	if (device->fwmark)
 		terminal_printf("  " TERMINAL_BOLD "fwmark" TERMINAL_RESET ": 0x%x\n", device->fwmark);
+	terminal_printf("  " TERMINAL_BOLD "transport" TERMINAL_RESET ": %s\n", transport(device->transport));
 	if (device->first_peer) {
 		sort_peers(device);
 		terminal_printf("\n");
@@ -248,6 +316,8 @@ static void pretty_print(struct wgdevice *device)
 		if (peer->next_peer)
 			terminal_printf("\n");
 	}
+
+	DEBUG_PRINT("Exiting pretty_print\n");
 }
 
 static void dump_print(struct wgdevice *device, bool with_interface)
@@ -255,6 +325,8 @@ static void dump_print(struct wgdevice *device, bool with_interface)
 	struct wgpeer *peer;
 	struct wgallowedip *allowedip;
 
+	DEBUG_PRINT("Entering dump_print\n");
+
 	if (with_interface)
 		printf("%s\t", device->name);
 	printf("%s\t", maybe_key(device->private_key, device->flags & WGDEVICE_HAS_PRIVATE_KEY));
@@ -285,6 +357,8 @@ static void dump_print(struct wgdevice *device, bool with_interface)
 		else
 			printf("off\n");
 	}
+
+	DEBUG_PRINT("Exiting dump_print\n");
 }
 
 static bool ugly_print(struct wgdevice *device, const char *param, bool with_interface)
@@ -292,6 +366,8 @@ static bool ugly_print(struct wgdevice *device, const char *param, bool with_int
 	struct wgpeer *peer;
 	struct wgallowedip *allowedip;
 
+	DEBUG_PRINT("Entering ugly_print with param: %s\n", param);
+
 	if (!strcmp(param, "public-key")) {
 		if (with_interface)
 			printf("%s\t", device->name);
@@ -371,8 +447,11 @@ static bool ugly_print(struct wgdevice *device, const char *param, bool with_int
 	else {
 		fprintf(stderr, "Invalid parameter: `%s'\n", param);
 		show_usage();
+		DEBUG_PRINT("Exiting ugly_print with error\n");
 		return false;
 	}
+
+	DEBUG_PRINT("Exiting ugly_print\n");
 	return true;
 }
 
@@ -380,10 +459,13 @@ int show_main(int argc, const char *argv[])
 {
 	int ret = 0;
 
+	DEBUG_PRINT("Entering show_main with argc: %d\n", argc);
+
 	COMMAND_NAME = argv[0];
 
 	if (argc > 3) {
 		show_usage();
+		DEBUG_PRINT("Exiting show_main - too many arguments\n");
 		return 1;
 	}
 
@@ -392,6 +474,7 @@ int show_main(int argc, const char *argv[])
 
 		if (!interfaces) {
 			perror("Unable to list interfaces");
+			DEBUG_PRINT("Exiting show_main - unable to list interfaces\n");
 			return 1;
 		}
 		ret = !!*interfaces;
@@ -423,24 +506,27 @@ int show_main(int argc, const char *argv[])
 
 		if (argc > 2) {
 			show_usage();
+			DEBUG_PRINT("Exiting show_main - invalid usage\n");
 			return 1;
 		}
 		interfaces = ipc_list_devices();
 		if (!interfaces) {
 			perror("Unable to list interfaces");
+			DEBUG_PRINT("Exiting show_main - unable to list interfaces\n");
 			return 1;
 		}
 		interface = interfaces;
 		for (size_t len = 0; (len = strlen(interface)); interface += len + 1)
 			printf("%s%c", interface, strlen(interface + len + 1) ? ' ' : '\n');
 		free(interfaces);
-	} else if (argc == 2 && (!strcmp(argv[1], "-h") || !strcmp(argv[1], "--help") || !strcmp(argv[1], "help")))
+	} else if (argc == 2 && (!strcmp(argv[1], "-h") || !strcmp(argv[1], "--help") || !strcmp(argv[1], "help"))) {
 		show_usage();
-	else {
+	} else {
 		struct wgdevice *device = NULL;
 
 		if (ipc_get_device(&device, argv[1]) < 0) {
 			perror("Unable to access interface");
+			DEBUG_PRINT("Exiting show_main - unable to access interface\n");
 			return 1;
 		}
 		if (argc == 3) {
@@ -450,5 +536,7 @@ int show_main(int argc, const char *argv[])
 			pretty_print(device);
 		free_wgdevice(device);
 	}
+
+	DEBUG_PRINT("Exiting show_main\n");
 	return ret;
 }
diff --git a/wireguard-tools/src/showconf.c b/wireguard-tools/src/showconf.c
index 62070dc27af2..85598bc14421 100644
--- a/wireguard-tools/src/showconf.c
+++ b/wireguard-tools/src/showconf.c
@@ -18,6 +18,12 @@
 #include "ipc.h"
 #include "subcommands.h"
 
+#ifdef DEBUG
+#define DEBUG_PRINT(fmt, args...) fprintf(stderr, fmt, ##args)
+#else
+#define DEBUG_PRINT(fmt, args...) /* Don't do anything in release builds */
+#endif
+
 int showconf_main(int argc, const char *argv[])
 {
 	char base64[WG_KEY_LEN_BASE64];
@@ -27,45 +33,65 @@ int showconf_main(int argc, const char *argv[])
 	struct wgallowedip *allowedip;
 	int ret = 1;
 
+	DEBUG_PRINT("Entering %s\n", __func__);
+	DEBUG_PRINT("Arguments count: %d\n", argc);
+
 	if (argc != 2) {
 		fprintf(stderr, "Usage: %s %s <interface>\n", PROG_NAME, argv[0]);
+		DEBUG_PRINT("Invalid argument count. Exiting %s with return code %d\n", __func__, 1);
 		return 1;
 	}
 
 	if (ipc_get_device(&device, argv[1])) {
 		perror("Unable to access interface");
+		DEBUG_PRINT("Unable to access interface: %s. Exiting %s with return code %d\n", argv[1], __func__, 1);
 		goto cleanup;
 	}
 
 	printf("[Interface]\n");
-	if (device->listen_port)
+	if (device->listen_port) {
 		printf("ListenPort = %u\n", device->listen_port);
-	if (device->fwmark)
+		DEBUG_PRINT("Device listen port: %u\n", device->listen_port);
+	}
+	if (device->fwmark) {
 		printf("FwMark = 0x%x\n", device->fwmark);
+		DEBUG_PRINT("Device fwmark: 0x%x\n", device->fwmark);
+	}
 	if (device->flags & WGDEVICE_HAS_PRIVATE_KEY) {
 		key_to_base64(base64, device->private_key);
 		printf("PrivateKey = %s\n", base64);
+		DEBUG_PRINT("Device private key: %s\n", base64);
+	}
+	if (device->transport) {
+		printf("TransportMode = %s\n", (device->transport == WG_TRANSPORT_TCP ? "tcp" : "udp"));
+		DEBUG_PRINT("Device transport mode: %s\n", (device->transport == WG_TRANSPORT_TCP ? "tcp" : "udp"));
 	}
 	printf("\n");
+
 	for_each_wgpeer(device, peer) {
 		key_to_base64(base64, peer->public_key);
 		printf("[Peer]\nPublicKey = %s\n", base64);
+		DEBUG_PRINT("Peer public key: %s\n", base64);
+
 		if (peer->flags & WGPEER_HAS_PRESHARED_KEY) {
 			key_to_base64(base64, peer->preshared_key);
 			printf("PresharedKey = %s\n", base64);
+			DEBUG_PRINT("Peer preshared key: %s\n", base64);
 		}
+
 		if (peer->first_allowedip)
-			printf("AllowedIPs = ");
+		printf("AllowedIPs = ");
 		for_each_wgallowedip(peer, allowedip) {
 			if (allowedip->family == AF_INET) {
 				if (!inet_ntop(AF_INET, &allowedip->ip4, ip, INET6_ADDRSTRLEN))
-					continue;
+				continue;
 			} else if (allowedip->family == AF_INET6) {
 				if (!inet_ntop(AF_INET6, &allowedip->ip6, ip, INET6_ADDRSTRLEN))
-					continue;
+				continue;
 			} else
 				continue;
 			printf("%s/%d", ip, allowedip->cidr);
+			DEBUG_PRINT("Allowed IP: %s/%d\n", ip, allowedip->cidr);
 			if (allowedip->next_allowedip)
 				printf(", ");
 		}
@@ -86,18 +112,23 @@ int showconf_main(int argc, const char *argv[])
 					printf("Endpoint = [%s]:%s\n", host, service);
 				else
 					printf("Endpoint = %s:%s\n", host, service);
+				DEBUG_PRINT("Peer endpoint: %s:%s\n", host, service);
 			}
 		}
 
 		if (peer->persistent_keepalive_interval)
 			printf("PersistentKeepalive = %u\n", peer->persistent_keepalive_interval);
+		DEBUG_PRINT("Peer persistent keepalive: %u\n", peer->persistent_keepalive_interval);
 
 		if (peer->next_peer)
-			printf("\n");
+		printf("\n");
 	}
+
 	ret = 0;
 
 cleanup:
+	DEBUG_PRINT("Cleaning up device\n");
 	free_wgdevice(device);
+	DEBUG_PRINT("Exiting %s with return code %d\n", __func__, ret);
 	return ret;
 }
diff --git a/wireguard-tools/src/uapi/linux/linux/wireguard.h b/wireguard-tools/src/uapi/linux/linux/wireguard.h
index 0efd52c3687d..674b069f8f58 100644
--- a/wireguard-tools/src/uapi/linux/linux/wireguard.h
+++ b/wireguard-tools/src/uapi/linux/linux/wireguard.h
@@ -157,6 +157,7 @@ enum wgdevice_attribute {
 	WGDEVICE_A_LISTEN_PORT,
 	WGDEVICE_A_FWMARK,
 	WGDEVICE_A_PEERS,
+	WGDEVICE_A_TRANSPORT_MODE,
 	__WGDEVICE_A_LAST
 };
 #define WGDEVICE_A_MAX (__WGDEVICE_A_LAST - 1)
@@ -180,6 +181,7 @@ enum wgpeer_attribute {
 	WGPEER_A_TX_BYTES,
 	WGPEER_A_ALLOWEDIPS,
 	WGPEER_A_PROTOCOL_VERSION,
+	WGPEER_A_TRANSPORT_MODE,
 	__WGPEER_A_LAST
 };
 #define WGPEER_A_MAX (__WGPEER_A_LAST - 1)
